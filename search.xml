<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Test</title>
    <url>/2024/07/16/Test/</url>
    <content><![CDATA[<h1 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h1><p>大家好啊，今天来给大家看点想看的东西。<em><strong>哇哦！</strong></em><br><br><img src="/shayu.png" alt="shayu"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function">__int128 <span class="title">parseint128</span><span class="params">(<span class="type">const</span> string&amp; x)</span></span>&#123;</span><br><span class="line">    __int128 res = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> sign = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(x[<span class="number">0</span>] == <span class="string">&#x27;-&#x27;</span>) sign = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span>&amp;&amp; c : x)&#123;</span><br><span class="line">        <span class="keyword">if</span>(!<span class="built_in">isdigit</span>(c)) <span class="keyword">throw</span> std::<span class="built_in">invalid_argument</span>(<span class="string">&quot;Invaild argument for __int128\n&quot;</span>);</span><br><span class="line">        res *= <span class="number">10</span>;</span><br><span class="line">        res += c - <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res * sign;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ostream&amp; <span class="keyword">operator</span>&lt;&lt;(ostream&amp; out, <span class="type">const</span> __int128 x)&#123;</span><br><span class="line">    <span class="function">ostream::sentry <span class="title">os</span><span class="params">(out)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(os)&#123;</span><br><span class="line">        <span class="keyword">if</span> (x == std::numeric_limits&lt;__int128&gt;::<span class="built_in">min</span>()) <span class="keyword">return</span> out &lt;&lt; <span class="string">&quot;-170141183460469231731687303715884105728&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span> (x &lt; <span class="number">0</span>) <span class="keyword">return</span> out &lt;&lt; <span class="string">&quot;-&quot;</span> &lt;&lt; -x;</span><br><span class="line">        <span class="keyword">if</span> (x &lt; <span class="number">10</span>) <span class="keyword">return</span> out &lt;&lt; (<span class="type">char</span>)(x + <span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span> out &lt;&lt; x / <span class="number">10</span> &lt;&lt; (<span class="type">char</span>)(x % <span class="number">10</span> + <span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        out.<span class="built_in">setstate</span>(ios::failbit);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br><span class="line">istream&amp; <span class="keyword">operator</span>&gt;&gt;(istream&amp; in, __int128&amp;  x)&#123;</span><br><span class="line">    <span class="function">istream::sentry <span class="title">input</span><span class="params">(in)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(input)&#123;</span><br><span class="line">        string s;</span><br><span class="line">        in &gt;&gt; s;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            x = <span class="built_in">parseint128</span>(s);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">catch</span>(std::invalid_argument&amp; e)&#123;</span><br><span class="line">            in.<span class="built_in">setstate</span>(ios::failbit);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        in.<span class="built_in">setstate</span>(ios::failbit);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> in;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">State</span> &#123;</span><br><span class="line">    Start,</span><br><span class="line">    Int,</span><br><span class="line">    Exp,</span><br><span class="line">    Signed,</span><br><span class="line">    Dot,</span><br><span class="line">    Int_dot,            </span><br><span class="line">    Exp_sign,</span><br><span class="line">    Exp_num,</span><br><span class="line">    Dec,</span><br><span class="line">    Invaild</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">Events</span> &#123;</span><br><span class="line">    digit,</span><br><span class="line">    sign,</span><br><span class="line">    dot,</span><br><span class="line">    expo,</span><br><span class="line">    others</span><br><span class="line">&#125;;</span><br><span class="line">State trans[][<span class="number">6</span>] = &#123;</span><br><span class="line">    &#123;State::Int, State::Signed, State::Dot, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Int, State::Invaild, State::Int_dot, State::Exp, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Exp_num, State::Exp_sign, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Int, State::Invaild, State::Dot, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Int_dot, State::Invaild, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Int_dot, State::Invaild, State::Invaild, State::Exp, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Dec, State::Invaild, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Dec, State::Invaild, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Dec, State::Invaild, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">    &#123;State::Invaild, State::Invaild, State::Invaild, State::Invaild, State::Invaild&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">Events <span class="title">getEvent</span><span class="params">(<span class="type">char</span> c)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(c &gt;= <span class="string">&#x27;0&#x27;</span> &amp;&amp; c &lt;= <span class="string">&#x27;9&#x27;</span>) <span class="keyword">return</span> Events::digit;</span><br><span class="line">    <span class="keyword">if</span>(c == <span class="string">&#x27;+&#x27;</span> || c == <span class="string">&#x27;-&#x27;</span>) <span class="keyword">return</span> Events::sign;</span><br><span class="line">    <span class="keyword">if</span>(c == <span class="string">&#x27;.&#x27;</span>) <span class="keyword">return</span> Events::dot;</span><br><span class="line">    <span class="keyword">if</span>(c == <span class="string">&#x27;e&#x27;</span> || c == <span class="string">&#x27;E&#x27;</span>) <span class="keyword">return</span> Events::expo;</span><br><span class="line">    <span class="keyword">return</span> Events::others;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    string s;</span><br><span class="line">    cin &gt;&gt; s;</span><br><span class="line">    __int128 x = numeric_limits&lt;__int128&gt;::<span class="built_in">lowest</span>();</span><br><span class="line">    cin &gt;&gt; x;</span><br><span class="line">    cout &lt;&lt; x;</span><br><span class="line">    State state = State::Start;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span>&amp;&amp; c : s)&#123;</span><br><span class="line">        Events e = <span class="built_in">getEvent</span>(c);</span><br><span class="line">        state = trans[(<span class="type">int</span>)state][(<span class="type">int</span>)e];</span><br><span class="line">        <span class="keyword">if</span>(state == State::Invaild) cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(state == State::Int || state == State::Int_dot || state == State::Dec || state == State::Start || state == State::Exp_num)&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;true&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>114514</p>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理 （第一节）</title>
    <url>/2024/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86">计算机组成原理</a><ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84">计算机系统体系结构</a></li>
</ul>
</li>
<li><a href="#xxxx">xxxx</a><ul>
<li><a href="#yyy">yyy</a><ul>
<li><a href="#zzz">zzz</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#113">113</a><ul>
<li><a href="#114">114</a></li>
</ul>
</li>
</ul>
<h1 id="计算机组成原理"><a href="#计算机组成原理" class="headerlink" title="计算机组成原理"></a>计算机组成原理</h1><h2 id="计算机系统体系结构"><a href="#计算机系统体系结构" class="headerlink" title="计算机系统体系结构"></a>计算机系统体系结构</h2><p>ARM半字传输 P179</p>
<h1 id="xxxx"><a href="#xxxx" class="headerlink" title="xxxx"></a>xxxx</h1><h2 id="yyy"><a href="#yyy" class="headerlink" title="yyy"></a>yyy</h2><h3 id="zzz"><a href="#zzz" class="headerlink" title="zzz"></a>zzz</h3><h1 id="113"><a href="#113" class="headerlink" title="113"></a>113</h1><h2 id="114"><a href="#114" class="headerlink" title="114"></a>114</h2>]]></content>
      <tags>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统概念</title>
    <url>/2024/07/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<ul>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5">操作系统概念</a><ul>
<li><a href="#%E5%AF%BC%E8%AE%BA">导论</a><ul>
<li><a href="#1-1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD">1-1 操作系统功能</a></li>
<li><a href="#1-2-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%84%E6%88%90">1-2 计算机系统的组成</a><ul>
<li><a href="#1-2-1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C">1-2-1 计算机系统的运行</a></li>
<li><a href="#%E4%B8%AD%E6%96%AD">中断</a><ul>
<li><a href="#%E4%B8%AD%E6%96%AD%E7%9A%84%E8%BD%AC%E7%A7%BB">中断的转移</a><ul>
<li><a href="#%E6%96%B9%E6%B3%95%E4%B8%80">方法一:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#1-2-2-%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">1-2-2 存储结构</a></li>
<li><a href="#1-2-3-io%E7%BB%93%E6%9E%84">1-2-3 io结构</a></li>
</ul>
</li>
<li><a href="#1-3-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84">1-3 计算机系统的体系结构</a><ul>
<li><a href="#1-3-1-%E5%8D%95%E5%A4%84%E7%90%86%E5%99%A8%E7%BB%93%E6%9E%84">1-3-1 单处理器结构</a></li>
<li><a href="#1-3-2-%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E7%BB%93%E6%9E%84">1-3-2 多处理器结构</a></li>
<li><a href="#1-3-3-%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F">1-3-3 集群系统</a></li>
</ul>
</li>
<li><a href="#1-4-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%93%E6%9E%84">1-4 操作系统的结构</a><ul>
<li><a href="#%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E7%B3%BB%E7%BB%9F">多道程序系统</a></li>
<li><a href="#%E5%88%86%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">分时操作系统</a></li>
</ul>
</li>
<li><a href="#1-5-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%89%A7%E8%A1%8C">1-5 操作系统的执行</a><ul>
<li><a href="#1-5-1-%E5%8F%8C%E9%87%8D%E6%A8%A1%E5%BC%8F%E4%B8%8E%E5%A4%9A%E9%87%8D%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%89%A7%E8%A1%8C">1-5-1 双重模式与多重模式的执行</a></li>
<li><a href="#1-5-2-%E5%AE%9A%E6%97%B6%E5%99%A8">1-5-2 定时器</a></li>
</ul>
</li>
<li><a href="#1-6-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86">1-6 进程管理</a><ul>
<li><a href="#%E5%B9%B6%E5%8F%91">并发</a></li>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B4%9F%E8%B4%A3%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%9A%84%E4%BB%A5%E4%B8%8B%E6%B4%BB%E5%8A%A8">操作系统负责进程管理的以下活动：</a></li>
</ul>
</li>
<li><a href="#1-7-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">1-7 内存管理</a><ul>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B4%9F%E8%B4%A3%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%9A%84%E4%BB%A5%E4%B8%8B%E6%B4%BB%E5%8A%A8">操作系统负责内存管理的以下活动：</a></li>
</ul>
</li>
<li><a href="#1-8-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86">1-8 存储管理</a><ul>
<li><a href="#1-8-1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86">1-8-1 文件系统管理</a><ul>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B4%9F%E8%B4%A3%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E7%9A%84%E4%BB%A5%E4%B8%8B%E6%B4%BB%E5%8A%A8">操作系统负责文件管理的以下活动：</a></li>
</ul>
</li>
<li><a href="#1-8-2-%E5%A4%A7%E5%AE%B9%E9%87%8F%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86">1-8-2 大容量存储器管理</a><ul>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B4%9F%E8%B4%A3%E7%A1%AC%E7%9B%98%E7%AE%A1%E7%90%86%E7%9A%84%E4%BB%A5%E4%B8%8B%E6%B4%BB%E5%8A%A8">操作系统负责硬盘管理的以下活动：</a></li>
</ul>
</li>
<li><a href="#1-8-3-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98">1-8-3 高速缓存</a></li>
<li><a href="#1-8-4-io%E7%B3%BB%E7%BB%9F">1-8-4 io系统</a><ul>
<li><a href="#io%E5%AD%90%E7%B3%BB%E7%BB%9F%E5%8C%85%E5%90%AB%E4%BB%A5%E4%B8%8B%E7%BB%84%E4%BB%B6">io子系统包含以下组件：</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#1-9-%E4%BF%9D%E6%8A%A4%E5%92%8C%E5%AE%89%E5%85%A8">1-9 保护和安全</a></li>
<li><a href="#1-10-%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">1-10 内核数据结构</a><ul>
<li><a href="#1-10-1-%E5%88%97%E8%A1%A8%E5%A0%86%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97">1-10-1 列表，堆栈和队列</a></li>
<li><a href="#1-10-2-%E6%A0%91">1-10-2 树</a></li>
<li><a href="#1-10-2-%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E5%92%8C%E5%93%88%E5%B8%8C%E8%A1%A8">1-10-2 哈希函数和哈希表</a></li>
<li><a href="#1-10-3-%E4%BD%8D%E5%9B%BE">1-10-3 位图</a></li>
</ul>
</li>
<li><a href="#1-11-%E8%AE%A1%E7%AE%97%E7%8E%AF%E5%A2%83">1-11 计算环境</a><ul>
<li><a href="#1-11-1-%E4%BC%A0%E7%BB%9F%E7%8E%AF%E5%A2%83">1-11-1 传统环境</a></li>
<li><a href="#1-11-2-%E7%A7%BB%E5%8A%A8%E7%8E%AF%E5%A2%83">1-11-2 移动环境</a></li>
<li><a href="#1-11-3-%E5%88%86%E5%B8%83%E8%AE%A1%E7%AE%97">1-11-3 分布计算</a></li>
<li><a href="#1-11-4-%E5%AE%A2%E6%88%B7%E6%9C%BA-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%A1%E7%AE%97">1-11-4 客户机-服务器计算</a><ul>
<li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%B3%BB%E7%BB%9F%E5%8F%AF%E5%A4%A7%E8%87%B4%E5%88%86%E4%B8%BA%E8%AE%A1%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8">服务器系统可大致分为计算服务器和文件服务器：</a></li>
</ul>
</li>
<li><a href="#1-11-5-%E5%AF%B9%E7%AD%89%E8%AE%A1%E7%AE%97">1-11-5 对等计算</a></li>
<li><a href="#1-11-6-%E8%99%9A%E6%8B%9F%E5%8C%96">1-11-6 虚拟化</a></li>
<li><a href="#1-11-7-%E4%BA%91%E8%AE%A1%E7%AE%97">1-11-7 云计算</a><ul>
<li><a href="#%E4%BA%91%E8%AE%A1%E7%AE%97%E7%B1%BB%E5%9E%8B">云计算类型</a></li>
</ul>
</li>
<li><a href="#1-11-8-%E5%AE%9E%E6%97%B6%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F">1-11-8 实时嵌入式系统</a><ul>
<li><a href="#%E5%AE%9E%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">实时操作系统</a></li>
<li><a href="#%E6%89%B9%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">批处理操作系统</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#1-12-%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">1-12 开源操作系统</a></li>
</ul>
</li>
<li><a href="#2-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84">2 操作系统结构</a><ul>
<li><a href="#2-1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9C%8D%E5%8A%A1">2-1 操作系统的服务</a><ul>
<li><a href="#%E7%94%A8%E4%BA%8E%E6%8F%90%E4%BE%9B%E7%94%A8%E6%88%B7%E5%8A%9F%E8%83%BD%E7%9A%84%E6%9C%8D%E5%8A%A1">用于提供用户功能的服务</a></li>
<li><a href="#%E7%94%A8%E4%BA%8E%E4%BF%9D%E8%AF%81%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87%E7%9A%84%E6%9C%8D%E5%8A%A1">用于保证运行效率的服务</a></li>
</ul>
</li>
<li><a href="#2-2-%E7%94%A8%E6%88%B7%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%95%8C%E9%9D%A2">2-2 用户与操作系统的界面</a><ul>
<li><a href="#2-2-1-%E5%91%BD%E4%BB%A4%E8%A7%A3%E9%87%8A%E7%A8%8B%E5%BA%8F">2-2-1 命令解释程序</a></li>
<li><a href="#2-2-2-%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2">2-2-2 图形用户界面</a></li>
<li><a href="#2-2-3-%E7%95%8C%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9">2-2-3 界面的选择</a></li>
</ul>
</li>
<li><a href="#2-3-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8">2-3 系统调用</a><ul>
<li><a href="#%E6%A0%B9%E6%8D%AEapi%E7%BC%96%E7%A8%8B%E7%9A%84%E5%A5%BD%E5%A4%84">根据api编程的好处</a></li>
<li><a href="#%E5%90%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E7%9A%84%E6%96%B9%E6%B3%95">向操作系统传递参数的方法</a></li>
</ul>
</li>
<li><a href="#2-4-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E7%9A%84%E7%B1%BB%E5%9E%8B">2-4 系统调用的类型</a><ul>
<li><a href="#2-4-1-%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6">2-4-1 进程控制</a><ul>
<li><a href="#windows%E5%92%8Cunix%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E7%9A%84%E7%A4%BA%E4%BE%8B">windows和unix系统调用的示例</a></li>
<li><a href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%92%8C%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6%E7%9A%84%E5%8C%BA%E5%88%AB-%E6%9C%AA%E5%AE%8C">进程控制和作业控制的区别 （未完）</a></li>
</ul>
</li>
<li><a href="#2-4-2-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86">2-4-2 文件管理</a></li>
<li><a href="#2-4-3-%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86">2-4-3 设备管理</a></li>
<li><a href="#2-4-4-%E4%BF%A1%E6%81%AF%E7%BB%B4%E6%8A%A4">2-4-4 信息维护</a></li>
<li><a href="#2-4-5-%E9%80%9A%E4%BF%A1">2-4-5 通信</a><ul>
<li><a href="#%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E6%A8%A1%E5%9E%8B">消息传递模型</a></li>
<li><a href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B">共享内存模型</a></li>
<li><a href="#%E5%AF%B9%E6%AF%94">对比</a></li>
</ul>
</li>
<li><a href="#2-4-6-%E4%BF%9D%E6%8A%A4">2-4-6 保护</a></li>
</ul>
</li>
<li><a href="#2-5-%E7%B3%BB%E7%BB%9F%E7%A8%8B%E5%BA%8F">2-5 系统程序</a><ul>
<li><a href="#%E7%B3%BB%E7%BB%9F%E7%A8%8B%E5%BA%8F%E7%B1%BB%E5%88%AB">系统程序类别</a></li>
</ul>
</li>
<li><a href="#2-6-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0">2-6 操作系统的设计和实现</a><ul>
<li><a href="#2-6-1-%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87">2-6-1 设计目标</a></li>
<li><a href="#2-6-2-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%AD%96%E7%95%A5">2-6-2 机制与策略</a></li>
<li><a href="#2-6-3-%E5%AE%9E%E7%8E%B0">2-6-3 实现</a><ul>
<li><a href="#%E9%87%87%E7%94%A8%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80%E7%BC%96%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">采用高级语言编写操作系统的优缺点</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2-7-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%93%E6%9E%84">2-7 操作系统的结构</a><ul>
<li><a href="#2-7-1-%E7%AE%80%E5%8D%95%E7%BB%93%E6%9E%84%E5%8D%95%E7%89%87%E7%BB%93%E6%9E%84">2-7-1 简单结构（单片结构）</a></li>
<li><a href="#2-7-2-%E5%88%86%E5%B1%82%E6%96%B9%E6%B3%95">2-7-2 分层方法</a></li>
<li><a href="#2-7-3-%E5%BE%AE%E5%86%85%E6%A0%B8-p77">2-7-3 微内核 （P77）</a><ul>
<li><a href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E6%96%B9%E6%B3%95%E7%9A%84%E4%BC%98%E7%82%B9">微内核方法的优点</a></li>
<li><a href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E6%96%B9%E6%B3%95%E7%9A%84%E7%BC%BA%E7%82%B9">微内核方法的缺点</a></li>
</ul>
</li>
<li><a href="#2-7-4-%E6%A8%A1%E5%9D%97">2-7-4 模块</a></li>
<li><a href="#2-7-5-%E6%B7%B7%E5%90%88%E7%B3%BB%E7%BB%9F">2-7-5 混合系统</a></li>
</ul>
</li>
<li><a href="#2-8-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B0%83%E8%AF%95">2-8 操作系统的调试</a><ul>
<li><a href="#2-8-1-%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90">2-8-1 故障分析</a></li>
<li><a href="#2-8-2-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96">2-8-2 性能优化</a></li>
<li><a href="#2-8-3-dtrace">2-8-3 DTrace</a></li>
</ul>
</li>
<li><a href="#2-9-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%94%9F%E6%88%90">2-9 操作系统的生成</a><ul>
<li><a href="#%E7%B3%BB%E7%BB%9F%E7%94%9F%E6%88%90%E5%AE%9A%E4%B9%89">系统生成定义</a></li>
</ul>
</li>
<li><a href="#2-10-%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC">2-10 系统引导</a><ul>
<li><a href="#%E5%BC%95%E5%AF%BC%E7%A8%8B%E5%BA%8F">引导程序</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-%E8%BF%9B%E7%A8%8B">3 进程</a><ul>
<li><a href="#3-1-%E8%BF%9B%E7%A8%8B%E6%A6%82%E5%BF%B5">3-1 进程概念</a><ul>
<li><a href="#3-1-1-%E8%BF%9B%E7%A8%8B">3-1-1 进程</a></li>
<li><a href="#3-1-2-%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81">3-1-2 进程状态</a></li>
<li><a href="#3-1-3-%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97pcb">3-1-3 进程控制块pcb</a></li>
<li><a href="#3-1-4-%E7%BA%BF%E7%A8%8B">3-1-4 线程</a></li>
</ul>
</li>
<li><a href="#3-2-%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6">3-2 进程调度</a><ul>
<li><a href="#3-2-1-%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97">3-2-1 调度队列</a></li>
<li><a href="#3-2-2-%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F">3-2-2 调度程序</a></li>
<li><a href="#3-2-3-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2">3-2-3 上下文切换</a></li>
</ul>
</li>
<li><a href="#3-3-%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C">3-3 进程运行</a><ul>
<li><a href="#3-3-1-%E8%BF%9B%E7%A8%8B%E5%88%9B%E5%BB%BA">3-3-1 进程创建</a></li>
<li><a href="#3-3-2-%E8%BF%9B%E7%A8%8B%E7%BB%88%E6%AD%A2">3-3-2 进程终止</a></li>
</ul>
</li>
<li><a href="#3-4-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1">3-4 进程间通信</a><ul>
<li><a href="#3-4-1-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F">3-4-1 共享内存系统</a></li>
<li><a href="#3-4-2-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E7%B3%BB%E7%BB%9F">3-4-2 消息传递系统</a><ul>
<li><a href="#3-4-2-1-%E5%91%BD%E5%90%8D">3-4-2-1 命名</a><ul>
<li><a href="#%E7%9B%B4%E6%8E%A5%E9%80%9A%E4%BF%A1">直接通信</a></li>
<li><a href="#%E9%97%B4%E6%8E%A5%E9%80%9A%E4%BF%A1">间接通信</a></li>
</ul>
</li>
<li><a href="#3-4-2-2-%E5%90%8C%E6%AD%A5">3-4-2-2 同步</a></li>
<li><a href="#3-4-2-3-%E7%BC%93%E5%AD%98">3-4-2-3 缓存</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-5-ipc%E4%BE%8B%E5%AD%90">3-5 ipc例子</a></li>
<li><a href="#3-6-%E5%AE%A2%E6%88%B7%E6%9C%BA-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%9A%E4%BF%A1">3-6 客户机-服务器通信</a><ul>
<li><a href="#3-6-1-%E5%A5%97%E6%8E%A5%E5%AD%97">3-6-1 套接字</a></li>
<li><a href="#3-6-2-rpc%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8">3-6-2 rpc远程过程调用</a></li>
<li><a href="#3-6-3-%E7%AE%A1%E9%81%93">3-6-3 管道</a><ul>
<li><a href="#3-6-3-1-%E6%99%AE%E9%80%9A%E7%AE%A1%E9%81%93">3-6-3-1 普通管道</a></li>
<li><a href="#3-6-3-2-%E5%91%BD%E5%90%8D%E7%AE%A1%E9%81%93">3-6-3-2 命名管道</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B">4 多线程编程</a><ul>
<li><a href="#4-1-%E6%A6%82%E8%BF%B0">4-1 概述</a><ul>
<li><a href="#4-1-1-%E5%8A%A8%E6%9C%BA">4-1-1 动机</a></li>
<li><a href="#4-1-2-%E4%BC%98%E7%82%B9">4-1-2 优点</a></li>
</ul>
</li>
<li><a href="#4-2-%E5%A4%9A%E6%A0%B8%E7%BC%96%E7%A8%8B">4-2 多核编程</a><ul>
<li><a href="#amdahl%E5%AE%9A%E5%BE%8B">amdahl定律</a></li>
<li><a href="#4-2-1-%E7%BC%96%E7%A8%8B%E4%B8%8A%E7%AD%89%E6%8C%91%E6%88%98">4-2-1 编程上等挑战</a></li>
<li><a href="#4-2-2-%E5%B9%B6%E8%A1%8C%E7%B1%BB%E5%9E%8B">4-2-2 并行类型</a></li>
</ul>
</li>
<li><a href="#4-3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B">4-3 多线程模型</a><ul>
<li><a href="#4-3-1-%E5%A4%9A%E5%AF%B9%E4%B8%80%E6%A8%A1%E5%9E%8B">4-3-1 多对一模型</a></li>
<li><a href="#4-3-2-%E4%B8%80%E5%AF%B9%E4%B8%80%E6%A8%A1%E5%9E%8B">4-3-2 一对一模型</a></li>
<li><a href="#4-3-3-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E6%A8%A1%E5%9E%8B">4-3-3 多对多模型</a><ul>
<li><a href="#%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%B9%B6%E5%8F%91%E6%80%A7%E7%9A%84%E5%BD%B1%E5%93%8D">不同模型对并发性的影响</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-4-%E7%BA%BF%E7%A8%8B%E5%BA%93">4-4 线程库</a><ul>
<li><a href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%88%9B%E5%BB%BA%E7%9A%84%E7%AD%96%E7%95%A5">多线程创建的策略</a></li>
<li><a href="#4-4-1-pthread">4-4-1 pthread</a></li>
<li><a href="#4-4-2-windows%E7%BA%BF%E7%A8%8B">4-4-2 windows线程</a></li>
<li><a href="#4-4-3-java%E7%BA%BF%E7%A8%8B">4-4-3 java线程</a></li>
</ul>
</li>
<li><a href="#4-5-%E9%9A%90%E5%BC%8F%E5%A4%9A%E7%BA%BF%E7%A8%8B">4-5 隐式多线程</a><ul>
<li><a href="#4-5-1-%E7%BA%BF%E7%A8%8B%E6%B1%A0">4-5-1 线程池</a><ul>
<li><a href="#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E6%80%9D%E6%83%B3">线程池的思想</a></li>
</ul>
</li>
<li><a href="#4-5-2-openmp">4-5-2 openmp</a></li>
<li><a href="#4-5-3-%E5%A4%A7%E4%B8%AD%E5%A4%AE%E8%B0%83%E5%BA%A6">4-5-3 大中央调度</a></li>
</ul>
</li>
<li><a href="#4-6-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E9%97%AE%E9%A2%98">4-6 多线程设计问题</a><ul>
<li><a href="#4-6-1-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8fork%E5%92%8Cexec">4-6-1 系统调用fork和exec</a></li>
<li><a href="#4-6-2-%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86">4-6-2 信号处理</a></li>
<li><a href="#4-6-3-%E7%BA%BF%E7%A8%8B%E6%92%A4%E9%94%80">4-6-3 线程撤销</a></li>
<li><a href="#4-6-4-%E7%BA%BF%E7%A8%8B%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8">4-6-4 线程本地存储</a></li>
<li><a href="#4-6-5-%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F%E6%BF%80%E6%B4%BB">4-6-5 调度程序激活</a></li>
</ul>
</li>
<li><a href="#4-7-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BE%8B%E5%AD%90">4-7 操作系统例子</a></li>
</ul>
</li>
<li><a href="#5-%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6">5 进程调度</a><ul>
<li><a href="#5-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">5-1 基本概念</a><ul>
<li><a href="#5-1-1-cpu-io%E6%89%A7%E8%A1%8C%E5%91%A8%E6%9C%9F">5-1-1 cpu-io执行周期</a></li>
<li><a href="#5-1-2-cpu%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F">5-1-2 cpu调度程序</a></li>
<li><a href="#5-1-3-%E6%8A%A2%E5%8D%A0%E8%B0%83%E5%BA%A6">5-1-3 抢占调度</a></li>
<li><a href="#5-1-4-%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F">5-1-4 调度程序</a></li>
</ul>
</li>
<li><a href="#5-2-%E8%B0%83%E5%BA%A6%E5%87%86%E5%88%99">5-2 调度准则</a></li>
<li><a href="#5-3-%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95">5-3 调度算法</a><ul>
<li><a href="#5-3-1-%E5%85%88%E5%88%B0%E5%85%88%E6%9C%8D%E5%8A%A1fcfs">5-3-1 先到先服务FCFS</a></li>
<li><a href="#5-3-2-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6">5-3-2 最短作业优先调度</a></li>
<li><a href="#5-3-3-%E4%BC%98%E5%85%88%E7%BA%A7%E8%B0%83%E5%BA%A6">5-3-3 优先级调度</a></li>
<li><a href="#5-3-4-%E8%BD%AE%E8%BD%AC%E8%B0%83%E5%BA%A6">5-3-4 轮转调度</a></li>
<li><a href="#5-3-5-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97%E8%B0%83%E5%BA%A6">5-3-5 多级队列调度</a></li>
<li><a href="#5-3-6-%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97%E8%B0%83%E5%BA%A6">5-3-6 多级反馈队列调度</a></li>
</ul>
</li>
<li><a href="#5-4-%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6">5-4 线程调度</a><ul>
<li><a href="#5-4-1--%E7%AB%9E%E4%BA%89%E8%8C%83%E5%9B%B4">5-4-1  竞争范围</a></li>
<li><a href="#5-4-2-pthreads%E8%B0%83%E5%BA%A6">5-4-2 pthreads调度</a></li>
</ul>
</li>
<li><a href="#5-5-%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6">5-5 多处理器调度</a><ul>
<li><a href="#5-5-1-%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6%E6%96%B9%E6%B3%95">5-5-1 多处理器调度方法</a></li>
<li><a href="#5-5-2-%E5%A4%84%E7%90%86%E5%99%A8%E4%BA%B2%E5%92%8C%E6%80%A7">5-5-2 处理器亲和性</a></li>
<li><a href="#5-5-3-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">5-5-3 负载均衡</a></li>
<li><a href="#5-5-4-%E5%A4%9A%E6%A0%B8%E5%A4%84%E7%90%86%E5%99%A8">5-5-4 多核处理器</a></li>
</ul>
</li>
<li><a href="#5-6-%E5%AE%9E%E6%97%B6cpu%E8%B0%83%E5%BA%A6">5-6 实时cpu调度</a><ul>
<li><a href="#5-6-1-%E6%9C%80%E5%B0%8F%E5%8C%96%E5%BB%B6%E8%BF%9F">5-6-1 最小化延迟</a></li>
<li><a href="#5-6-2-%E4%BC%98%E5%85%88%E6%9D%83%E8%B0%83%E5%BA%A6">5-6-2 优先权调度</a></li>
<li><a href="#5-6-3-%E5%8D%95%E8%B0%83%E9%80%9F%E7%8E%87%E8%B0%83%E5%BA%A6">5-6-3 单调速率调度</a></li>
<li><a href="#5-6-4-%E6%9C%80%E6%97%A9%E6%88%AA%E6%AD%A2%E6%9C%9F%E9%99%90%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6">5-6-4 最早截止期限优先调度</a></li>
<li><a href="#5-6-5-%E6%AF%94%E4%BE%8B%E5%88%86%E4%BA%AB%E8%B0%83%E5%BA%A6">5-6-5 比例分享调度</a></li>
<li><a href="#5-6-6-posix%E5%AE%9E%E6%97%B6%E8%B0%83%E5%BA%A6">5-6-6 posix实时调度</a></li>
</ul>
</li>
<li><a href="#5-7-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BE%8B%E5%AD%90">5-7 操作系统例子</a></li>
</ul>
</li>
<li><a href="#6-%E5%90%8C%E6%AD%A5">6 同步</a><ul>
<li><a href="#6-1-%E8%83%8C%E6%99%AF">6-1 背景</a></li>
<li><a href="#6-2-%E4%B8%B4%E7%95%8C%E5%8C%BA%E9%97%AE%E9%A2%98">6-2 临界区问题</a><ul>
<li><a href="#%E4%B8%B4%E7%95%8C%E5%8C%BA%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%A6%81%E6%B1%82">临界区问题的解决方案要求</a></li>
</ul>
</li>
<li><a href="#6-3-peterson%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">6-3 peterson解决方案</a></li>
<li><a href="#6-4-%E7%A1%AC%E4%BB%B6%E5%90%8C%E6%AD%A5">6-4 硬件同步</a></li>
<li><a href="#6-5-%E4%BA%92%E6%96%A5%E9%94%81">6-5 互斥锁</a><ul>
<li><a href="#%E5%BF%99%E7%AD%89%E5%BE%85">忙等待</a></li>
</ul>
</li>
<li><a href="#6-6-%E4%BF%A1%E5%8F%B7%E9%87%8F-pv">6-6 信号量-pv</a><ul>
<li><a href="#6-6-1-%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8">6-6-1 信号量的使用</a></li>
<li><a href="#6-6-2-%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E5%AE%9E%E7%8E%B0">6-6-2 信号量的实现</a><ul>
<li><a href="#%E5%85%8B%E6%9C%8D%E5%BF%99%E7%AD%89%E5%BE%85">克服忙等待</a></li>
</ul>
</li>
<li><a href="#6-6-3-%E6%AD%BB%E9%94%81%E5%92%8C%E9%A5%A5%E9%A5%BF">6-6-3 死锁和饥饿</a></li>
<li><a href="#6-6-4-%E4%BC%98%E5%85%88%E7%BA%A7%E5%8F%8D%E8%BD%AC">6-6-4 优先级反转</a></li>
</ul>
</li>
<li><a href="#6-7-%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98">6-7 经典同步问题</a><ul>
<li><a href="#6-7-1-%E6%9C%89%E7%95%8C%E7%BC%93%E5%86%B2%E9%97%AE%E9%A2%98">6-7-1 有界缓冲问题</a></li>
<li><a href="#6-7-2-%E8%AF%BB%E8%80%85-%E4%BD%9C%E8%80%85%E9%97%AE%E9%A2%98">6-7-2 读者-作者问题</a></li>
<li><a href="#6-7-3-%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98">6-7-3 哲学家就餐问题</a></li>
</ul>
</li>
<li><a href="#6-8-%E7%AE%A1%E7%A8%8B">6-8 管程</a><ul>
<li><a href="#6-8-1-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">6-8-1 使用方法</a></li>
<li><a href="#6-8-2-%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98%E7%9A%84%E7%AE%A1%E7%A8%8B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">6-8-2 哲学家就餐问题的管程解决方案</a></li>
<li><a href="#6-8-3-%E9%87%87%E7%94%A8%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E7%AE%A1%E7%A8%8B%E5%AE%9E%E7%8E%B0">6-8-3 采用信号量的管程实现</a></li>
<li><a href="#6-8-4-%E7%AE%A1%E7%A8%8B%E5%86%85%E7%9A%84%E8%BF%9B%E7%A8%8B%E9%87%8D%E5%90%AF">6-8-4 管程内的进程重启</a></li>
</ul>
</li>
<li><a href="#6-9-%E5%90%8C%E6%AD%A5%E4%BE%8B%E5%AD%90">6-9 同步例子</a><ul>
<li><a href="#6-9-1-windows%E5%90%8C%E6%AD%A5">6-9-1 windows同步</a></li>
<li><a href="#6-9-2-linux%E5%90%8C%E6%AD%A5">6-9-2 linux同步</a></li>
<li><a href="#6-9-3-solaris%E5%90%8C%E6%AD%A5">6-9-3 solaris同步</a></li>
<li><a href="#6-9-4-pthreads%E5%90%8C%E6%AD%A5">6-9-4 pthreads同步</a></li>
</ul>
</li>
<li><a href="#6-10-%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%B3%95">6-10 替代方法</a><ul>
<li><a href="#6-10-1-%E4%BA%8B%E5%8A%A1%E5%86%85%E5%AD%98">6-10-1 事务内存</a></li>
<li><a href="#6-10-2-openmp">6-10-2 openmp</a></li>
<li><a href="#6-10-3-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80">6-10-3 函数式编程语言</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-%E6%AD%BB%E9%94%81">7 死锁</a><ul>
<li><a href="#7-1-%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B">7-1 系统模型</a></li>
<li><a href="#7-2-%E6%AD%BB%E9%94%81%E7%89%B9%E5%BE%81">7-2 死锁特征</a><ul>
<li><a href="#7-2-1-%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6">7-2-1 必要条件</a></li>
<li><a href="#7-2-2-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE">7-2-2 资源分配图</a></li>
</ul>
</li>
<li><a href="#7-3-%E6%AD%BB%E9%94%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95">7-3 死锁处理方法</a></li>
<li><a href="#7-4-%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2">7-4 死锁预防</a><ul>
<li><a href="#7-4-1-%E4%BA%92%E6%96%A5">7-4-1 互斥</a></li>
<li><a href="#7-4-2-%E6%8C%81%E6%9C%89%E5%B9%B6%E7%AD%89%E5%BE%85">7-4-2 持有并等待</a></li>
<li><a href="#7-4-3-%E6%97%A0%E6%8A%A2%E5%8D%A0">7-4-3 无抢占</a></li>
<li><a href="#7-4-4-%E5%BE%AA%E7%8E%AF%E7%AD%89%E5%BE%85">7-4-4 循环等待</a><ul>
<li><a href="#%E9%94%81%E7%9A%84%E5%8A%A8%E6%80%81%E8%8E%B7%E5%8F%96%E5%AF%BC%E8%87%B4%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%A4%B1%E6%95%88">锁的动态获取导致的顺序失效</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-5-%E6%AD%BB%E9%94%81%E9%81%BF%E5%85%8D">7-5 死锁避免</a><ul>
<li><a href="#7-5-1-%E5%AE%89%E5%85%A8%E7%8A%B6%E6%80%81">7-5-1 安全状态</a><ul>
<li><a href="#%E5%AE%89%E5%85%A8%E7%8A%B6%E6%80%81%E4%B8%8E%E6%AD%BB%E9%94%81%E7%9A%84%E5%85%B3%E7%B3%BB">安全状态与死锁的关系</a></li>
</ul>
</li>
<li><a href="#7-5-2-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE%E7%AE%97%E6%B3%95">7-5-2 资源分配图算法</a></li>
<li><a href="#7-5-3-%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95">7-5-3 银行家算法</a><ul>
<li><a href="#7-5-3-1-%E5%AE%89%E5%85%A8%E7%AE%97%E6%B3%95">7-5-3-1 安全算法</a></li>
<li><a href="#7-5-3-2-%E8%B5%84%E6%BA%90%E8%AF%B7%E6%B1%82%E7%AE%97%E6%B3%95">7-5-3-2 资源请求算法</a></li>
<li><a href="#7-5-3-3-%E8%AF%B4%E6%98%8E%E7%A4%BA%E4%BE%8B">7-5-3-3 说明示例</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-6-%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B">7-6 死锁检测</a><ul>
<li><a href="#7-6-1-%E6%AF%8F%E7%A7%8D%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B%E9%83%BD%E5%8F%AA%E6%9C%89%E5%8D%95%E4%B8%AA%E5%AE%9E%E4%BE%8B">7-6-1 每种资源类型都只有单个实例</a></li>
<li><a href="#7-6-2-%E6%AF%8F%E7%A7%8D%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B%E5%8F%AF%E6%9C%89%E5%A4%9A%E4%B8%AA%E5%AE%9E%E4%BE%8B">7-6-2 每种资源类型可有多个实例</a></li>
<li><a href="#7-6-3-%E5%BA%94%E7%94%A8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95">7-6-3 应用检测算法</a></li>
</ul>
</li>
<li><a href="#7-7-%E6%AD%BB%E9%94%81%E6%81%A2%E5%A4%8D">7-7 死锁恢复</a><ul>
<li><a href="#7-7-1-%E8%BF%9B%E7%A8%8B%E7%BB%88%E6%AD%A2">7-7-1 进程终止</a></li>
<li><a href="#7-7-2-%E8%B5%84%E6%BA%90%E6%8A%A2%E5%8D%A0">7-7-2 资源抢占</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#8-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5">8 内存管理策略</a><ul>
<li><a href="#8-1-%E8%83%8C%E6%99%AF">8-1 背景</a><ul>
<li><a href="#8-1-1-%E5%9F%BA%E6%9C%AC%E7%A1%AC%E4%BB%B6">8-1-1 基本硬件</a><ul>
<li><a href="#%E9%80%9A%E8%BF%87%E5%9F%BA%E5%9C%B0%E5%9D%80%E5%92%8C%E7%95%8C%E9%99%90%E5%9C%B0%E5%9D%80%E7%9A%84%E5%AE%9E%E7%8E%B0">通过基地址和界限地址的实现</a></li>
</ul>
</li>
<li><a href="#8-1-2-%E5%9C%B0%E5%9D%80%E7%BB%91%E5%AE%9A">8-1-2 地址绑定</a></li>
<li><a href="#8-1-3-%E9%80%BB%E8%BE%91%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%92%8C%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4">8-1-3 逻辑地址空间和物理地址空间</a></li>
<li><a href="#8-1-4-%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD">8-1-4 动态加载</a></li>
<li><a href="#8-1-5-%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%92%8C%E5%85%B1%E4%BA%AB%E5%BA%93">8-1-5 动态链接和共享库</a></li>
</ul>
</li>
<li><a href="#8-2-%E4%BA%A4%E6%8D%A2">8-2 交换</a><ul>
<li><a href="#8-2-1-%E6%A0%87%E5%87%86%E4%BA%A4%E6%8D%A2">8-2-1 标准交换</a></li>
<li><a href="#8-2-2-%E7%A7%BB%E5%8A%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BA%A4%E6%8D%A2">8-2-2 移动系统的交换</a></li>
</ul>
</li>
<li><a href="#8-3-%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D">8-3 连续内存分配</a><ul>
<li><a href="#8-3-1-%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4">8-3-1 内存保护</a></li>
<li><a href="#8-3-2-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D">8-3-2 内存分配</a></li>
<li><a href="#8-3-3-%E7%A2%8E%E7%89%87">8-3-3 碎片</a></li>
</ul>
</li>
<li><a href="#8-4-%E5%88%86%E6%AE%B5">8-4 分段</a><ul>
<li><a href="#8-4-1-%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95">8-4-1 基本方法</a></li>
<li><a href="#8-4-2-%E5%88%86%E6%AE%B5%E7%A1%AC%E4%BB%B6">8-4-2 分段硬件</a></li>
</ul>
</li>
<li><a href="#8-5-%E5%88%86%E9%A1%B5">8-5 分页</a><ul>
<li><a href="#8-5-1-%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95">8-5-1 基本方法</a><ul>
<li><a href="#%E5%88%86%E9%A1%B5%E4%BE%8B%E5%AD%90">分页例子</a></li>
</ul>
</li>
<li><a href="#8-5-2-%E7%A1%AC%E4%BB%B6%E6%94%AF%E6%8C%81">8-5-2 硬件支持</a></li>
<li><a href="#8-5-3-%E4%BF%9D%E6%8A%A4">8-5-3 保护</a></li>
<li><a href="#8-5-4-%E5%85%B1%E4%BA%AB%E9%A1%B5">8-5-4 共享页</a></li>
</ul>
</li>
<li><a href="#8-6-%E9%A1%B5%E8%A1%A8%E7%BB%93%E6%9E%84">8-6 页表结构</a><ul>
<li><a href="#8-6-1-%E5%88%86%E5%B1%82%E5%88%86%E9%A1%B5">8-6-1 分层分页</a><ul>
<li><a href="#%E5%A4%9A%E5%B1%82%E5%88%86%E9%A1%B5%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E8%8A%82%E7%9C%81%E5%86%85%E5%AD%98">多层分页为什么能节省内存*</a></li>
</ul>
</li>
<li><a href="#8-6-2">8-6-2</a></li>
<li><a href="#8-6-3-%E5%80%92%E7%BD%AE%E9%A1%B5%E8%A1%A8">8-6-3 倒置页表</a></li>
<li><a href="#8-6-4-solaris">8-6-4 solaris</a></li>
</ul>
</li>
<li><a href="#8-7-intel-32%E4%B8%8E64%E4%BD%8D%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84">8-7 intel 32与64位体系结构</a><ul>
<li><a href="#ia32">ia32</a></li>
<li><a href="#x86-64">x86-64</a></li>
</ul>
</li>
<li><a href="#arm%E6%9E%B6%E6%9E%84">arm架构</a></li>
</ul>
</li>
<li><a href="#9-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86">9 虚拟内存管理</a><ul>
<li><a href="#9-1-%E8%83%8C%E6%99%AF">9-1 背景</a></li>
<li><a href="#9-2-%E8%AF%B7%E6%B1%82%E8%B0%83%E9%A1%B5">9-2 请求调页</a><ul>
<li><a href="#9-2-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">9-2-1 基本概念</a></li>
<li><a href="#9-2-2-%E8%AF%B7%E6%B1%82%E8%B0%83%E9%A1%B5%E7%9A%84%E6%80%A7%E8%83%BD">9-2-2 请求调页的性能</a></li>
</ul>
</li>
<li><a href="#9-3-%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6">9-3 写时复制</a></li>
<li><a href="#9-4-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4 页面置换</a><ul>
<li><a href="#9-4-1-%E5%9F%BA%E6%9C%AC%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4-1 基本页面置换</a></li>
<li><a href="#9-4-2-fifo%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4-2 fifo页面置换</a><ul>
<li><a href="#belady%E5%BC%82%E5%B8%B8">Belady异常</a></li>
</ul>
</li>
<li><a href="#9-4-3-%E6%9C%80%E4%BC%98%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4-3 最优页面置换</a></li>
<li><a href="#9-4-4-lru%E9%A1%B5%E9%9D%A2%E6%9B%BF%E6%8D%A2">9-4-4 lru页面替换</a><ul>
<li><a href="#%E5%AE%9E%E7%8E%B0lru%E6%9B%BF%E6%8D%A2">实现LRU替换</a></li>
</ul>
</li>
<li><a href="#9-4-5-%E8%BF%91%E4%BC%BClru%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4-5 近似lru页面置换</a><ul>
<li><a href="#9-4-5-1-%E9%A2%9D%E5%A4%96%E5%BC%95%E7%94%A8%E4%BD%8D%E7%AE%97%E6%B3%95">9-4-5-1 额外引用位算法</a></li>
<li><a href="#9-4-5-2-%E7%AC%AC%E4%BA%8C%E6%AC%A1%E6%9C%BA%E4%BC%9A%E7%AE%97%E6%B3%95">9-4-5-2 第二次机会算法</a></li>
<li><a href="#9-4-5-3-%E5%A2%9E%E5%BC%BA%E5%9E%8B%E7%AC%AC%E4%BA%8C%E6%AC%A1%E6%9C%BA%E4%BC%9A%E7%AE%97%E6%B3%95">9-4-5-3 增强型第二次机会算法</a></li>
</ul>
</li>
<li><a href="#9-4-6-%E5%9F%BA%E4%BA%8E%E8%AE%A1%E6%95%B0%E7%9A%84%E9%A1%B5%E9%9D%A2%E6%9B%BF%E6%8D%A2">9-4-6 基于计数的页面替换</a></li>
<li><a href="#9-4-7-%E9%A1%B5%E9%9D%A2%E7%BC%93%E5%86%B2%E7%AE%97%E6%B3%95">9-4-7 页面缓冲算法</a></li>
<li><a href="#9-4-8-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%92%8C%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2">9-4-8 应用程序和页面置换</a></li>
</ul>
</li>
<li><a href="#9-5-%E5%B8%A7%E5%88%86%E9%85%8D">9-5 帧分配</a><ul>
<li><a href="#9-5-1-%E5%B8%A7%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0">9-5-1 帧的最小数</a></li>
<li><a href="#9-5-2-%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95">9-5-2 分配算法</a></li>
<li><a href="#9-5-3-%E5%85%A8%E5%B1%80%E5%88%86%E9%85%8D%E5%92%8C%E5%B1%80%E9%83%A8%E5%88%86%E9%85%8D">9-5-3 全局分配和局部分配</a></li>
<li><a href="#9-5-4-%E9%9D%9E%E5%9D%87%E5%8C%80%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE">9-5-4 非均匀内存访问</a></li>
</ul>
</li>
<li><a href="#9-6-%E7%B3%BB%E7%BB%9F%E6%8A%96%E5%8A%A8">9-6 系统抖动</a><ul>
<li><a href="#9-6-1-%E7%B3%BB%E7%BB%9F%E6%8A%96%E5%8A%A8%E7%9A%84%E5%8E%9F%E5%9B%A0">9-6-1 系统抖动的原因</a></li>
<li><a href="#9-6-2-%E5%B7%A5%E4%BD%9C%E9%9B%86%E6%A8%A1%E5%9E%8B">9-6-2 工作集模型</a></li>
<li><a href="#9-6-3-%E7%BC%BA%E9%A1%B5%E9%94%99%E8%AF%AF%E9%A2%91%E7%8E%87">9-6-3 缺页错误频率</a></li>
</ul>
</li>
<li><a href="#9-7-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6">9-7 内存映射文件</a><ul>
<li><a href="#9-7-1-%E5%9F%BA%E6%9C%AC%E6%9C%BA%E5%88%B6">9-7-1 基本机制</a></li>
<li><a href="#9-7-2-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98windows-api">9-7-2 共享内存windows api</a></li>
<li><a href="#9-7-3-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84io">9-7-3 内存映射i&#x2F;o</a></li>
</ul>
</li>
<li><a href="#9-8-%E5%88%86%E9%85%8D%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98">9-8 分配内核内存</a><ul>
<li><a href="#9-8-1-%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F">9-8-1 伙伴系统</a></li>
<li><a href="#9-8-2-slab%E5%88%86%E9%85%8D">9-8-2 slab分配</a><ul>
<li><a href="#linux%E7%9A%84slob%E5%92%8Cslub">Linux的SLOB和SLUB</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#9-9-%E5%85%B6%E4%BB%96%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">9-9 其他注意事项</a><ul>
<li><a href="#9-9-1-%E9%A2%84%E8%B0%83%E9%A1%B5%E9%9D%A2">9-9-1 预调页面</a></li>
<li><a href="#9-9-2-%E9%A1%B5%E9%9D%A2%E5%A4%A7%E5%B0%8F">9-9-2 页面大小</a></li>
<li><a href="#9-9-3-tlb%E8%8C%83%E5%9B%B4">9-9-3 tlb范围</a></li>
<li><a href="#9-9-4-%E5%80%92%E7%BD%AE%E9%A1%B5%E8%A1%A8">9-9-4 倒置页表</a></li>
<li><a href="#9-9-5-%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84">9-9-5 程序结构</a></li>
<li><a href="#9-9-6-io%E8%81%94%E9%94%81%E4%B8%8E%E9%A1%B5%E9%9D%A2%E9%94%81%E5%AE%9A">9-9-6 i&#x2F;o联锁与页面锁定</a></li>
</ul>
</li>
<li><a href="#9-10-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BE%8B%E5%AD%90">9-10 操作系统例子</a></li>
</ul>
</li>
<li><a href="#10-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">10 文件系统</a><ul>
<li><a href="#10-1-%E6%96%87%E4%BB%B6%E6%A6%82%E5%BF%B5">10-1 文件概念</a><ul>
<li><a href="#10-1-1-%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7">10-1-1 文件属性</a></li>
<li><a href="#10-1-2-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C">10-1-2 文件操作</a></li>
<li><a href="#10-1-3-%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B">10-1-3 文件类型</a></li>
<li><a href="#10-1-4-%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84">10-1-4 文件结构</a></li>
<li><a href="#10-1-5-%E5%86%85%E9%83%A8%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84">10-1-5 内部文件结构</a><ul>
<li><a href="#%E9%80%BB%E8%BE%91%E8%AE%B0%E5%BD%95%E5%92%8C%E7%89%A9%E7%90%86%E8%AE%B0%E5%BD%95">逻辑记录和物理记录</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#10-2-%E8%AE%BF%E9%97%AE%E6%96%B9%E6%B3%95">10-2 访问方法</a><ul>
<li><a href="#10-2-1-%E9%A1%BA%E5%BA%8F%E8%AE%BF%E9%97%AE">10-2-1 顺序访问</a></li>
<li><a href="#10-2-2-%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE">10-2-2 直接访问</a></li>
<li><a href="#10-2-3-%E5%85%B6%E4%BB%96%E8%AE%BF%E9%97%AE%E6%96%B9%E6%B3%95">10-2-3 其他访问方法</a></li>
</ul>
</li>
<li><a href="#10-3-%E7%9B%AE%E5%BD%95%E4%B8%8E%E7%A3%81%E7%9B%98%E7%9A%84%E7%BB%93%E6%9E%84">10-3 目录与磁盘的结构</a><ul>
<li><a href="#10-3-2-%E7%9B%AE%E5%BD%95%E6%A6%82%E8%BF%B0">10-3-2 目录概述</a></li>
<li><a href="#10-3-3-%E5%8D%95%E7%BA%A7%E7%9B%AE%E5%BD%95">10-3-3 单级目录</a></li>
<li><a href="#10-3-4-%E4%B8%A4%E7%BA%A7%E7%9B%AE%E5%BD%95">10-3-4 两级目录</a></li>
<li><a href="#10-3-5-%E6%A0%91%E5%BD%A2%E7%9B%AE%E5%BD%95">10-3-5 树形目录</a></li>
<li><a href="#10-3-6-%E6%97%A0%E7%8E%AF%E5%9B%BE%E7%9B%AE%E5%BD%95">10-3-6 无环图目录</a><ul>
<li><a href="#%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6">共享文件</a></li>
<li><a href="#%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6">删除文件</a></li>
</ul>
</li>
<li><a href="#10-3-7-%E9%80%9A%E7%94%A8%E5%9B%BE%E7%9B%AE%E5%BD%95">10-3-7 通用图目录</a></li>
</ul>
</li>
<li><a href="#10-4-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85">10-4 文件系统安装</a></li>
<li><a href="#10-5-%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB">10-5 文件共享</a><ul>
<li><a href="#10-5-1-%E5%A4%9A%E7%94%A8%E6%88%B7">10-5-1 多用户</a></li>
<li><a href="#10-5-2-%E8%BF%9C%E7%A8%8B%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">10-5-2 远程文件系统</a><ul>
<li><a href="#10-5-2-1-%E5%AE%A2%E6%88%B7%E6%9C%BA-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A8%A1%E5%9E%8B">10-5-2-1 客户机-服务器模型</a></li>
<li><a href="#10-5-2-2-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F">10-5-2-2 分布式信息系统</a></li>
<li><a href="#10-5-2-3-%E6%95%85%E9%9A%9C%E6%A8%A1%E5%BC%8F">10-5-2-3 故障模式</a></li>
</ul>
</li>
<li><a href="#10-5-3-%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%AD%E4%B9%89">10-5-3 一致性语义</a><ul>
<li><a href="#10-5-3-1-unix%E8%AF%AD%E4%B9%89">10-5-3-1 unix语义</a></li>
<li><a href="#10-5-3-2-%E4%BC%9A%E8%AF%9D%E8%AF%AD%E4%B9%89">10-5-3-2 会话语义</a></li>
<li><a href="#10-5-3-3-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E8%AF%AD%E4%B9%89">10-5-3-3 不可变共享文件语义</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#10-6-%E4%BF%9D%E6%8A%A4">10-6 保护</a><ul>
<li><a href="#10-6-1-%E8%AE%BF%E9%97%AE%E7%B1%BB%E5%9E%8B">10-6-1 访问类型</a></li>
<li><a href="#10-6-2-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6">10-6-2 访问控制</a></li>
<li><a href="#10-6-3-%E5%85%B6%E4%BB%96%E4%BF%9D%E6%8A%A4%E6%96%B9%E5%BC%8F">10-6-3 其他保护方式</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#11-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0">11 文件系统实现</a><ul>
<li><a href="#11-1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84">11-1 文件系统结构</a></li>
<li><a href="#11-2-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0">11-2 文件系统实现</a><ul>
<li><a href="#11-2-1-%E6%A6%82%E8%BF%B0">11-2-1 概述</a><ul>
<li><a href="#%E6%9B%B4%E5%AE%8C%E6%95%B4%E7%9A%84open%E8%B0%83%E7%94%A8%E5%9C%A8%E7%B3%BB%E7%BB%9F%E5%86%85%E7%9A%84%E8%BF%87%E7%A8%8B">更完整的open()调用在系统内的过程</a></li>
</ul>
</li>
<li><a href="#11-2-2-%E5%88%86%E5%8C%BA%E5%92%8C%E5%AE%89%E8%A3%85">11-2-2 分区和安装</a></li>
<li><a href="#11-2-3-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">11-2-3 虚拟文件系统</a></li>
</ul>
</li>
<li><a href="#11-3-%E7%9B%AE%E5%BD%95%E5%AE%9E%E7%8E%B0">11-3 目录实现</a><ul>
<li><a href="#11-3-1-%E7%BA%BF%E6%80%A7%E5%88%97%E8%A1%A8">11-3-1 线性列表</a></li>
<li><a href="#11-3-2-%E5%93%88%E5%B8%8C%E8%A1%A8">11-3-2 哈希表</a></li>
</ul>
</li>
<li><a href="#11-4-%E5%88%86%E9%85%8D%E6%96%B9%E6%B3%95">11-4 分配方法</a><ul>
<li><a href="#11-4-1-%E8%BF%9E%E7%BB%AD%E5%88%86%E9%85%8D">11-4-1 连续分配</a></li>
<li><a href="#11-4-2-%E9%93%BE%E6%8E%A5%E5%88%86%E9%85%8D">11-4-2 链接分配</a><ul>
<li><a href="#fat">FAT</a></li>
</ul>
</li>
<li><a href="#11-4-3-%E7%B4%A2%E5%BC%95%E5%88%86%E9%85%8D">11-4-3 索引分配</a></li>
<li><a href="#11-4-4-%E6%80%A7%E8%83%BD">11-4-4 性能</a></li>
</ul>
</li>
<li><a href="#11-5-%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86">11-5 空闲空间管理</a><ul>
<li><a href="#11-5-1-%E4%BD%8D%E5%90%91%E9%87%8F">11-5-1 位向量</a></li>
<li><a href="#11-5-2-%E9%93%BE%E8%A1%A8">11-5-2 链表</a></li>
<li><a href="#11-5-3-%E7%BB%84">11-5-3 组</a></li>
<li><a href="#11-5-4-%E8%AE%A1%E6%95%B0">11-5-4 计数</a></li>
<li><a href="#11-5-5-%E7%A9%BA%E9%97%B4%E5%9B%BE">11-5-5 空间图*</a></li>
</ul>
</li>
<li><a href="#11-6-%E6%95%88%E7%8E%87%E5%92%8C%E6%80%A7%E8%83%BD">11-6 效率和性能</a><ul>
<li><a href="#11-6-1-%E6%95%88%E7%8E%87">11-6-1 效率</a></li>
<li><a href="#11-6-2-%E6%80%A7%E8%83%BD">11-6-2 性能</a></li>
</ul>
</li>
<li><a href="#11-7-%E6%81%A2%E5%A4%8D">11-7 恢复</a><ul>
<li><a href="#11-7-1-%E4%B8%80%E8%87%B4%E6%80%A7%E6%A3%80%E6%9F%A5">11-7-1 一致性检查</a></li>
<li><a href="#11-7-2-%E5%9F%BA%E4%BA%8E%E6%97%A5%E5%BF%97%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">11-7-2 基于日志的文件系统</a></li>
<li><a href="#11-7-3-%E5%85%B6%E4%BB%96%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95">11-7-3 其他解决办法</a></li>
<li><a href="#11-7-4-%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D">11-7-4 备份和恢复</a></li>
</ul>
</li>
<li><a href="#11-8-nfs">11-8 NFS</a><ul>
<li><a href="#11-8-1-%E6%A6%82%E8%BF%B0">11-8-1 概述</a></li>
<li><a href="#11-8-2-%E5%AE%89%E8%A3%85%E5%8D%8F%E8%AE%AE">11-8-2 安装协议</a></li>
<li><a href="#11-8-3-nfs%E5%8D%8F%E8%AE%AE">11-8-3 NFS协议</a></li>
<li><a href="#11-8-4-%E8%B7%AF%E5%BE%84%E5%90%8D%E7%A7%B0%E8%BD%AC%E6%8D%A2">11-8-4 路径名称转换</a></li>
<li><a href="#11-8-5-%E8%BF%9C%E7%A8%8B%E6%93%8D%E4%BD%9C">11-8-5 远程操作</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#12-%E5%A4%A7%E5%AE%B9%E9%87%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">12 大容量存储结构</a><ul>
<li><a href="#12-1-%E5%A4%A7%E5%AE%B9%E9%87%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0">12-1 大容量存储结构概述</a><ul>
<li><a href="#12-1-1-%E7%A3%81%E7%9B%98">12-1-1 磁盘</a></li>
<li><a href="#12-1-2-%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98">12-1-2 固态硬盘</a></li>
<li><a href="#12-1-3-%E7%A3%81%E5%B8%A6">12-1-3 磁带</a><ul>
<li><a href="#%E7%A3%81%E7%9B%98%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6">磁盘传输速度</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#12-2-%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84">12-2 磁盘结构</a></li>
<li><a href="#12-3-%E7%A3%81%E7%9B%98%E9%93%BE%E6%8E%A5">12-3 磁盘链接</a><ul>
<li><a href="#12-3-1-%E4%B8%BB%E6%9C%BA%E8%BF%9E%E6%8E%A5%E5%AD%98%E5%82%A8">12-3-1 主机连接存储</a></li>
<li><a href="#12-3-2-%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E5%AD%98%E5%82%A8">12-3-2 网络连接存储</a></li>
<li><a href="#12-3-3-%E5%AD%98%E5%82%A8%E5%8C%BA%E5%9F%9F%E7%BD%91%E7%BB%9C">12-3-3 存储区域网络</a></li>
</ul>
</li>
<li><a href="#12-4-%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6">12-4 磁盘调度</a><ul>
<li><a href="#12-4-1-fcfs%E8%B0%83%E5%BA%A6">12-4-1 fcfs调度</a></li>
<li><a href="#12-4-2-sstf%E8%B0%83%E5%BA%A6">12-4-2 sstf调度</a></li>
<li><a href="#12-4-3-scan%E8%B0%83%E5%BA%A6">12-4-3 scan调度</a></li>
<li><a href="#c-scan%E8%B0%83%E5%BA%A6">c-scan调度</a></li>
<li><a href="#look%E8%B0%83%E5%BA%A6">look调度</a></li>
<li><a href="#12-4-6-%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%89%E6%8B%A9">12-4-6 磁盘调度算法的选择</a></li>
</ul>
</li>
<li><a href="#12-5-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86">12-5 磁盘管理</a><ul>
<li><a href="#12-5-1-%E7%A3%81%E7%9B%98%E6%A0%BC%E5%BC%8F%E5%8C%96">12-5-1 磁盘格式化</a></li>
<li><a href="#12-5-2-%E5%BC%95%E5%AF%BC%E5%9D%97">12-5-2 引导块</a></li>
<li><a href="#12-5-3-%E5%9D%8F%E5%9D%97">12-5-3 坏块</a></li>
</ul>
</li>
<li><a href="#12-6-%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86">12-6 交换空间管理</a><ul>
<li><a href="#12-6-1-%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BD%BF%E7%94%A8">12-6-1 交换空间的使用</a></li>
<li><a href="#12-6-2-%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4%E4%BD%8D%E7%BD%AE">12-6-2 交换空间位置</a></li>
<li><a href="#12-6-3-%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86%E4%BE%8B%E5%AD%90">12-6-3 交换空间管理例子</a></li>
</ul>
</li>
<li><a href="#12-7-raid%E7%BB%93%E6%9E%84">12-7 raid结构</a><ul>
<li><a href="#12-7-1-%E9%80%9A%E8%BF%87%E5%86%97%E4%BD%99%E6%8F%90%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7">12-7-1 通过冗余提高可靠性</a></li>
<li><a href="#12-7-2-%E9%80%9A%E8%BF%87%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD">12-7-2 通过并行处理提高性能</a></li>
<li><a href="#12-7-3-raid%E7%BA%A7%E5%88%AB">12-7-3 raid级别</a></li>
<li><a href="#12-7-4-raid%E7%BA%A7%E5%88%AB%E9%80%89%E6%8B%A9">12-7-4 raid级别选择</a></li>
<li><a href="#12-7-5-%E6%89%A9%E5%B1%95">12-7-5 扩展</a></li>
<li><a href="#12-7-6-raid%E7%9A%84%E9%97%AE%E9%A2%98">12-7-6 raid的问题</a></li>
</ul>
</li>
<li><a href="#12-8-%E7%A8%B3%E5%AE%9A%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0">12-8 稳定存储实现</a></li>
</ul>
</li>
<li><a href="#13-io%E7%B3%BB%E7%BB%9F">13 i&#x2F;o系统</a><ul>
<li><a href="#13-1-%E6%A6%82%E8%BF%B0">13-1 概述</a></li>
<li><a href="#13-2-io%E7%A1%AC%E4%BB%B6">13-2 i&#x2F;o硬件</a><ul>
<li><a href="#%E7%AB%AF%E5%8F%A3">端口</a><ul>
<li><a href="#io%E7%AB%AF%E5%8F%A3%E5%AF%84%E5%AD%98%E5%99%A8">i&#x2F;o端口寄存器</a></li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BA%BF%E9%93%BE%E6%8E%A5">总线(链接)</a></li>
<li><a href="#%E6%8E%A7%E5%88%B6%E5%99%A8">控制器</a></li>
<li><a href="#13-2-1-%E8%BD%AE%E8%AF%A2">13-2-1 轮询</a></li>
<li><a href="#13-2-2-%E4%B8%AD%E6%96%AD">13-2-2 中断</a><ul>
<li><a href="#%E5%BB%B6%E8%BF%9F%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86">延迟中断处理</a></li>
<li><a href="#%E9%AB%98%E6%95%88%E5%88%86%E9%85%8D%E4%B8%AD%E6%96%AD">高效分配中断</a></li>
<li><a href="#%E5%A4%9A%E7%BA%A7%E4%B8%AD%E6%96%AD">多级中断</a></li>
</ul>
</li>
<li><a href="#13-2-3-%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE">13-2-3 直接内存访问</a></li>
<li><a href="#13-2-4-io%E7%A1%AC%E4%BB%B6%E5%B0%8F%E7%BB%93">13-2-4 i&#x2F;o硬件小结</a></li>
<li><a href="#%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8Fio%E6%8E%A5%E5%8F%A3">应用程序i&#x2F;o接口</a></li>
<li><a href="#13-3-1-%E5%9D%97%E4%B8%8E%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87">13-3-1 块与字符设备</a></li>
<li><a href="#13-3-2-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87">13-3-2 网络设备</a></li>
<li><a href="#13-3-3-%E6%97%B6%E9%92%9F%E4%B8%8E%E5%AE%9A%E6%97%B6%E5%99%A8">13-3-3 时钟与定时器</a></li>
<li><a href="#13-3-4-%E9%9D%9E%E9%98%BB%E5%A1%9E%E4%B8%8E%E5%BC%82%E6%AD%A5io">13-3-4 非阻塞与异步i&#x2F;o</a></li>
<li><a href="#13-3-5-%E5%90%91%E9%87%8Fio">13-3-5 向量i&#x2F;o</a></li>
</ul>
</li>
<li><a href="#13-4-io%E5%AD%90%E7%B3%BB%E7%BB%9F">13-4 i&#x2F;o子系统</a><ul>
<li><a href="#13-4-1-io%E8%B0%83%E5%BA%A6">13-4-1 i&#x2F;o调度</a></li>
<li><a href="#13-4-2-%E7%BC%93%E5%86%B2">13-4-2 缓冲</a></li>
<li><a href="#13-4-3-%E7%BC%93%E5%AD%98">13-4-3 缓存</a></li>
<li><a href="#13-4-4-%E5%81%87%E8%84%B1%E6%9C%BA%E4%B8%8E%E8%AE%BE%E5%A4%87%E4%BF%9D%E7%95%99">13-4-4 假脱机与设备保留</a></li>
<li><a href="#13-4-5-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86">13-4-5 错误处理</a></li>
<li><a href="#io%E4%BF%9D%E6%8A%A4">i&#x2F;o保护</a></li>
<li><a href="#13-4-7-%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">13-4-7 内核数据结构</a></li>
<li><a href="#13-4-8-%E5%86%85%E6%A0%B8io%E5%AD%90%E7%B3%BB%E7%BB%9F%E5%B0%8F%E7%BB%93">13-4-8 内核i&#x2F;o子系统小结</a></li>
</ul>
</li>
<li><a href="#13-5-io%E8%AF%B7%E6%B1%82%E8%BD%AC%E6%88%90%E7%A1%AC%E4%BB%B6%E6%93%8D%E4%BD%9C">13-5 i&#x2F;o请求转成硬件操作</a></li>
<li><a href="#13-6-%E6%B5%81">13-6 流</a></li>
<li><a href="#13-7-%E6%80%A7%E8%83%BD">13-7 性能</a></li>
</ul>
</li>
<li><a href="#14-%E7%B3%BB%E7%BB%9F%E4%BF%9D%E6%8A%A4">14 系统保护</a><ul>
<li><a href="#14-1-%E4%BF%9D%E6%8A%A4%E7%9B%AE%E6%A0%87">14-1 保护目标</a></li>
<li><a href="#14-2-%E4%BF%9D%E6%8A%A4%E5%8E%9F%E5%88%99">14-2 保护原则</a></li>
<li><a href="#14-3-%E4%BF%9D%E6%8A%A4%E5%9F%9F">14-3 保护域</a><ul>
<li><a href="#14-3-1-%E5%9F%9F%E7%BB%93%E6%9E%84">14-3-1 域结构</a></li>
<li><a href="#14-3-2-unix%E4%BE%8B%E5%AD%90">14-3-2 unix例子</a></li>
<li><a href="#14-3-3-multics%E4%BE%8B%E5%AD%90">14-3-3 multics例子</a></li>
</ul>
</li>
<li><a href="#14-4-%E4%BF%9D%E6%8A%A4%E7%9F%A9%E9%98%B5">14-4 保护矩阵</a></li>
<li><a href="#14-5-%E8%AE%BF%E9%97%AE%E7%9F%A9%E9%98%B5%E7%9A%84%E5%AE%9E%E7%8E%B0">14-5 访问矩阵的实现</a><ul>
<li><a href="#14-5-1-%E5%85%A8%E5%B1%80%E8%A1%A8">14-5-1 全局表</a></li>
<li><a href="#14-5-2-%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%AE%BF%E9%97%AE%E5%88%97%E8%A1%A8">14-5-2 对象的访问列表</a></li>
<li><a href="#14-5-3-%E5%9F%9F%E7%9A%84%E8%83%BD%E5%8A%9B%E5%88%97%E8%A1%A8">14-5-3 域的能力列表</a></li>
<li><a href="#14-5-4-%E9%94%81-%E9%92%A5%E5%8C%99%E6%9C%BA%E5%88%B6">14-5-4 锁-钥匙机制</a></li>
<li><a href="#14-5-5-%E6%AF%94%E8%BE%83">14-5-5 比较</a></li>
</ul>
</li>
<li><a href="#14-6-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6">14-6 访问控制</a></li>
<li><a href="#14-7-%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E7%9A%84%E6%92%A4%E5%9B%9E">14-7 访问权限的撤回</a></li>
<li><a href="#14-8-%E5%9F%BA%E4%BA%8E%E8%83%BD%E5%8A%9B%E7%9A%84%E7%B3%BB%E7%BB%9F">14-8 基于能力的系统</a><ul>
<li><a href="#14-8-1-hydra">14-8-1 hydra</a></li>
<li><a href="#14-8-2-%E5%89%91%E6%A1%A5cap%E7%B3%BB%E7%BB%9F">14-8-2 剑桥cap系统</a></li>
</ul>
</li>
<li><a href="#14-9-%E5%9F%BA%E4%BA%8E%E8%AF%AD%E8%A8%80%E7%9A%84%E4%BF%9D%E6%8A%A4">14-9 基于语言的保护</a><ul>
<li><a href="#14-9-1-%E5%9F%BA%E4%BA%8E%E7%BC%96%E8%AF%91%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0">14-9-1 基于编译程序的实现</a></li>
<li><a href="#14-9-2-java%E7%9A%84%E4%BF%9D%E6%8A%A4">14-9-2 java的保护</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#15-%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8">15 系统安全</a><ul>
<li><a href="#15-1-%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98">15-1 安全问题</a></li>
<li><a href="#15-2-%E7%A8%8B%E5%BA%8F%E5%A8%81%E8%83%81">15-2 程序威胁</a><ul>
<li><a href="#15-2-1-%E7%89%B9%E6%B4%9B%E4%BC%8A%E6%9C%A8%E9%A9%AC">15-2-1 特洛伊木马</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<span id="more"></span>

<h1 id="操作系统概念"><a href="#操作系统概念" class="headerlink" title="操作系统概念"></a>操作系统概念</h1><h2 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h2><h3 id="1-1-操作系统功能"><a href="#1-1-操作系统功能" class="headerlink" title="1-1 操作系统功能"></a>1-1 操作系统功能</h3><p>计算机系统可简略分为以下4个组件：  </p>
<ol>
<li>硬件</li>
<li>操作系统</li>
<li>应用程序</li>
<li>用户<br>简单来说, <strong>硬件</strong>如CPU, 内存以及I&#x2F;O设备提供了计算资源. <strong>应用程序</strong>规范了用户使用这些计算资源的方式. <strong>操作系统</strong>作为管理者(<strong>控制程序</strong>)指挥硬件完成任务, 负责协调应用程序的硬件资源调度.<br>对于操作系统而言,其设计目的可分为<strong>使用方便</strong>, <strong>资源利用</strong>, 以及<strong>两者兼顾</strong>的类型.</li>
</ol>
<h3 id="1-2-计算机系统的组成"><a href="#1-2-计算机系统的组成" class="headerlink" title="1-2 计算机系统的组成"></a>1-2 计算机系统的组成</h3><h4 id="1-2-1-计算机系统的运行"><a href="#1-2-1-计算机系统的运行" class="headerlink" title="1-2-1 计算机系统的运行"></a>1-2-1 计算机系统的运行</h4><p>现代通用计算机系统包括一个或多个CPU和若干设备控制器, 由公共总线相连,提供了共享内存的访问. 他们之间可以并发执行, 并竞争访问内存, <strong>为确保有序访问共享内存</strong>, 需要<strong>内存控制器</strong>来协调访问.<br>计算机开始运行时需要运行<strong>引导程序</strong>定位操作系统<strong>内核</strong>并添加到内存.引导程序一般位于计算机<strong>固件</strong>, 如<strong>只读内存(ROM)<strong>或</strong>电可擦可编程只读内存(RPPROM)</strong>. 它负责初始化系统组件, 从CPU寄存器, 设备控制器到内存内容.<br>当<strong>内核被添加到内存</strong>后, 它就为系统和用户提供服务. 此外, <strong>系统程序</strong>也提供一些服务, 他们在启动时被添加到内存, 成为<strong>系统进程</strong>或<strong>系统后台程序</strong>,拥有<strong>和内核一样的生命周期</strong>.</p>
<h4 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h4><p>系统时间通常通过<strong>硬件或软件的中断</strong>来通知. <strong>硬件</strong>可以随时<strong>通过系统总线发送信号</strong>到CPU, 以触发中断. <strong>软件</strong>也可通过执行特别操作即<strong>系统调用(systemcall)</strong>(也称为监督程序调用(monitorcall)), 以<strong>触发中断</strong>.  </p>
<p>当CPU被中断时, 它停止正在做的事并转到指定位置继续执行, 这通常是<strong>中断服务程序的开始地址</strong>. 服务程序执行完毕后, CPU重新执行被中断的计算.  </p>
<h5 id="中断的转移"><a href="#中断的转移" class="headerlink" title="中断的转移"></a>中断的转移</h5><h6 id="方法一"><a href="#方法一" class="headerlink" title="方法一:"></a>方法一:</h6><p>调用通用程序检查终中断信息并调用指定的中断服务程序.  <strong>由于事先定义的中断数量少, 也已使用指针表来快速跳转</strong>. 指针表通常位于低内存地址(前100左右). 存储这些地址的数组叫<strong>中断向量</strong>, 其中储存了<strong>各种设备</strong>的中断处理程序地址. 对于特定中断, 可以<strong>通过唯一的设备号来索引</strong>, 进而提供设备中断服务程序地址.<br>~<br>中断体系结构也应该保存中断指令的地址. 现代体系结构<strong>将返回地址保存在系统堆栈上</strong>. 如果中断程序需要修改处理器状态(如寄存器的值), 则需要保存修改前的状态,并在处理完中断后加载保存到返回地址来回溯先前的处理器状态, 以此避免中断对正在进行的计算的影响.  </p>
<h4 id="1-2-2-存储结构"><a href="#1-2-2-存储结构" class="headerlink" title="1-2-2 存储结构"></a>1-2-2 存储结构</h4><blockquote>
<p><strong>存储定义</strong></p>
<blockquote>
<p>计算机存储的基本单位为比特(bit)或位. 每个字节为8位, 这也是大部分计算机的常用最小储存单位, 大部分计算就机没有移动单个位的指令,但可以移动单个字节. 另一个相对少见的单位时字(word), 单个字由一个及以上的字节组成. 如64位计算机通常使用64位(8字节)的字.</p>
</blockquote>
</blockquote>
<p>由于CPU只能从内存中加载指令,所以运行程序必须在内存中. 大多数程序位于可读写内存,也叫<strong>内存</strong>,即<strong>随机访问内存(RAM)</strong>. 内存通常为<strong>动态随机访问内存(DRAM)</strong>,由半导体技术实现.<br><strong>所有内存都提供字节数组， 每个字节都有自己的地址</strong>. 交互通过了load和save指令进行, load指令将内存字节或字加载到CPU寄存器中, store则将CPU寄存器的内容保存到内存中. 此外, CPU也会自动加载内存指令以方便执行.</p>
<p>在冯·诺依曼体系结构（von Neumann architecture）上执行时，一个典型的指令执行周期是，<strong>首先从内存中获取指令，并存到指令寄存器</strong>（instruction register）。接着，该<strong>指令被解码</strong>，<strong>也可能会从内存中获取操作数据并且存到内部寄存器</strong>。在指令<strong>完成对操作数据的执行后，结果也可存到内存</strong>。注意：内存单元只能看到内存地址的流，而并不知道它们如何产生（通过指令计数器、索引、间接、常量地址或其他方式）或它们是什么样（指令或数据）的地址。相应地，我们<strong>可以忽略程序如何产生内存地址，而只关注由程序运行所生成的地址序列</strong>。</p>
<p>由于内存小且是易失的，大部分计算机都采用外存来扩充存储空间.<br><img src="/./osimg/image-1.png" alt="存储设备层次"><br>上图中固态磁盘以上的都是易失的，以下则为非易失的。</p>
<p><strong>固态磁盘</strong>具有多种类型，一种是将运行时数据存储在大的DRAM数组上, 断电后通过备用电池供电将RAM的内容复制到磁盘中. 另一种是<strong>闪存</strong>, 比DRAM慢,也是非易失的,且无需电源保存内容. 最后一种为<strong>NVRAM</strong>, 也就是具有电池的DRAM, 拥有和DRAM一样的速度. <s>废话</s></p>
<p>当两个储存组件访问速度或传输速率有明显差异时,可以使用<strong>高速缓存</strong>来中转以改善性能. </p>
<h4 id="1-2-3-io结构"><a href="#1-2-3-io结构" class="headerlink" title="1-2-3 io结构"></a>1-2-3 io结构</h4><p>操作系统大部分代码用于I&#x2F;O管理，其对系统的可靠性以及性能有重要影响. </p>
<p>每个通用计算机系统由一个CPU和多个设备控制器组成，它们通过共同总线连在一起。每个设备控制器管理某一特定类型的设备。根据设备控制器的特性，可以允许多个设备与其相连。例如，<strong>小型计算机系统接口（Small Computer System Interface，SCSI）控制器可连接7个或更多的设备</strong>。每个<strong>设备控制器维护一定量的本地缓冲存储和一组特定用途的寄存器</strong>。设备控制器负责在所<strong>控制的外围设备与本地缓冲存储之间进行数据传递</strong>。通常，<strong>操作系统为每个设备控制器提供一个设备驱动程序（device driver）</strong>。该<strong>设备驱动程序负责设备控制器</strong>，并且为操作系统的其他部分<strong>提供统一的设备访问接口</strong>。</p>
<p>开始I&#x2F;O时, <strong>设备驱动程序加载设备控制器的适当寄存器</strong>, 检查寄存器内容来决定下一步操作. 如”从键盘读取一个字符”, 控制器会从设备向本地缓冲区传输数据. 完成传输后, 设备控制器通过<strong>中断</strong>向设备驱动程序通知. 之后, 设备驱动程序返回控制到操作系统. <strong>对于读操作, 数据或其指针会被返回; 而对于其他操作, 设备驱动程序会返回状态信息</strong>.  </p>
<p>然而这种做法仅适用于移动少量数据, 每传输一个字节都需要产生中断, 这会对CPU性能产生很大的浪费. 对于大量数据的移动,我们采用<strong>直接内存访问(Direct Memory Access, DMA)</strong>. 它为I&#x2F;O设备<strong>提前设置好缓冲, 指针和计数器</strong>后, 设备控制器可以<strong>在本地缓冲和内存之间传送整块的数据</strong>, 每块只产生一个中断来告知驱动程序操作已完成. 当设备管理器执行这类操作时, CPU可继续进行其他操作. </p>
<p>有些高端系统采用交换而不是总线结构, 这种方式下多个组件可以同时与对方对话而不需要抢占公共总线. 这时DMA回更加高效.</p>
<p><img src="/osimg/image-2.png" alt="计算机系统工作原理"></p>
<h3 id="1-3-计算机系统的体系结构"><a href="#1-3-计算机系统的体系结构" class="headerlink" title="1-3 计算机系统的体系结构"></a>1-3 计算机系统的体系结构</h3><h4 id="1-3-1-单处理器结构"><a href="#1-3-1-单处理器结构" class="headerlink" title="1-3-1 单处理器结构"></a>1-3-1 单处理器结构</h4><p>略</p>
<h4 id="1-3-2-多处理器结构"><a href="#1-3-2-多处理器结构" class="headerlink" title="1-3-2 多处理器结构"></a>1-3-2 多处理器结构</h4><p>多处理器结构有以下优点：</p>
<ul>
<li>增加吞吐量: </br> N个处理器可以加速处理进程, 但加速比率只会小于N, 因为不同CPU之间的通信需要消耗资源. </li>
<li>规模经济</li>
<li>增加可靠性</li>
</ul>
<p>根据剩余有效硬件按比例继续提供服务的能力称为<strong>适度退化</strong>.  </p>
<p>现在所用的多处理器系统有<strong>两种类型</strong>。有的系统采用<strong>非对称处理（asymmetric multiprocessing）</strong>，即每个处理器都有各自特定的任务。一个<strong>主处理器（boss processor）控制系统，其他处理器或者向主处理器要任务或做预先规定的任务</strong>。这种<strong>方案称为主从关系</strong>。主处理器调度从处理器，并安排工作。</p>
<p>此外，还有一种称为<strong>对称多处理的（Symetric MultiProcessing，SMP）的方案</strong>。此方案中的<strong>处理器全部都能参与到系统的所有任务中</strong>。   </p>
<p><strong>这里的对称和的非对称多处理系统属于一个大类，另一个大类为集群系统，两者组成现在的多处理器系统</strong>。   </p>
<p><img src="/osimg/%E5%AF%B9%E7%A7%B0%E5%A4%9A%E5%A4%84%E7%90%86%E7%BB%93%E6%9E%84.png" alt="对称对处理结构"><br>从上面的结构图可以清楚看出，<strong>每个CPU物理核心都具有独立的私有寄存器和高速缓存</strong>，不过他们都可以共享物理内存。其优缺点分别为：  </p>
<ul>
<li>优点：<br>多个进程可以分别执行，且不会显著影响性能。</li>
<li>缺点：<br>需要<strong>精细的控制I&#x2F;O</strong>，以确保数据有序到达适当的处理器核心。<br>由于CPU之间互相独立，容易出现单核高负载而其他空载的情况导致<strong>利用率低</strong>。为此需要处理器共享一定的数据结构，并且协调好核心间的工作。<strong>（这方面在非对称处理中由于其他处理器需要向主处理器询问任务，协调会更简单）</strong></li>
</ul>
</br>

<p><strong>多处理通过增加CPU来提高计算能力</strong>。<strong>如果CPU集成了内存控制器，那么增加CPU也能增大系统的访问内存</strong>。<br>不论如何，<strong>多处理可使系统的内存访问模型，从均匀内存访问（Uniform Memory Access，UMA）改成非均匀内存访问（Non-Uniform Memory Access，NUMA）</strong>。</p>
<ul>
<li>对UMA，CPU访问RAM的所需时间相同  </li>
<li>而对NUMA，有的内存访问的所需时间更多，这会降低性能。操作系统通过资源管理可以改善NUMA的问题。</li>
</ul>
<p>目前的CPU设计趋势是集成多个计算核到单个芯片，这种多处理器系统称为<strong>多核</strong>。由于<strong>单片通信快于芯片间通信</strong>，多核具有<strong>更好的效能表现，且功耗更低</strong>。  </p>
<h4 id="1-3-3-集群系统"><a href="#1-3-3-集群系统" class="headerlink" title="1-3-3 集群系统"></a>1-3-3 集群系统</h4><p><strong>另一类型的多处理器系统是集群系统（clustered system）</strong>，这种系统将多个CPU组合在一起。集群系统与1.3.2节所述的多处理器系统不同，它<strong>由两个或多个独立系统(或节点)组成</strong>。这样的系统称为<strong>松耦合的(loosely coupled)</strong>. 每个<strong>节点可为单处理器系统或多核系统</strong>。应当注意的是，集群的定义尚未定型，许多商业软件对什么是集群系统有不同的定义，对什么形式的集群更好有不同的理解。<strong>较为公认的定义是，集群计算机共享存储，并且采用LAN（Local Area Network，局域网）连接或更快的内部连接，如InfiniBand</strong>.  </p>
<p><strong>集群可以是对称的，也可以是非对称的</strong>。  </p>
<ul>
<li><strong>非对称集群（asymmetric clustering）</strong>，一台机器处于<strong>热备份</strong>模式（hot-standby mode），而<strong>另一台运行应用程序</strong>。<strong>热备份主机只监视活动服务器</strong>。如果<strong>活动服务器失效</strong>，那么<strong>热备份主机变成活动服务器</strong>。</li>
<li><strong>对称集群（symmetric clustering）</strong>，两个或多个主机<strong>都运行应用程序</strong>，并<strong>互相监视</strong>。由于充分使用现有硬件，当有多个应用程序可供执行时，这种结构<strong>更为高效</strong>, 但并未留出冗余，抵抗风险能力为较弱。</li>
</ul>
<p>此外，还有<strong>并行集群</strong>和<strong>WAN（Wide-Area Network）集群</strong>。并行集群允许多个主机访问同一块共享内存。然而大部分操作系统并不支持，这需要通过专门的软件实现。  </p>
<p><em>并行计算：将一个程序分割为多个部分，将这些部分分配个对该核处理器同时进行</em>  </p>
<p>集群技术发展迅速。有的集群产品支持数十个系统，而且集群节点也可分开数公里之远。<strong>存储域网（Storage-Area Network，SAN）的出现也改进了集群性能</strong>；SAN可让许多系统访问同一存储池。SAN可以存储应用程序和数据，集群软件可将应用程序交给SAN的任何主机来执行。如果主机出错，那么其他主机可以接管过来。<strong>对于数据库集群，数十个主机可以共享同一数据库，从而大大提升了性能和可用性</strong>。图1-8显示了一个集群的通用结构。<br><img src="/osimg/%E9%80%9A%E7%94%A8%E9%9B%86%E7%BE%A4%E7%BB%93%E6%9E%84.png" alt="通用集群结构"></p>
<h3 id="1-4-操作系统的结构"><a href="#1-4-操作系统的结构" class="headerlink" title="1-4 操作系统的结构"></a>1-4 操作系统的结构</h3><p><em><strong>操作系统为程序提供环境</strong></em></p>
<h4 id="多道程序系统"><a href="#多道程序系统" class="headerlink" title="多道程序系统"></a>多道程序系统</h4><p><strong>操作系统最重要的一点是具有多道程序能力</strong>。一般来说，单个程序并不能让CPU和I&#x2F;O设备始终忙碌。单个用户通常具有多个运行程序。<strong>多道程序设计（multiprogramming）通过安排作业（编码与数据）使得CPU总有一个执行作业，从而提高CPU利用率</strong>。  </p>
<p><strong>操作系统在内存中同时保存多个任务</strong>。由于<strong>主存太小</strong>不能容纳所有作业，因此这些作业<strong>首先保存在磁盘的作业池（job pool）上</strong>。该<strong>作业池包括磁盘上的、等待分配内存的所有进程。</strong></p>
<p><strong>内存的作业集为作业池的作业集的子集</strong>，操作系统可以从中选择一个作业执行，当其需要如等待I&#x2F;O的操作时，<strong>非多道程序系统会进入空闲</strong>，而对于多道程序系统， CPU则简单的切换到另一个作业。</p>
<p>多道程序系统提供了一个环境以利用各种系统资源，<strong>但其并未提供用户与计算机的系统交互</strong>。<strong>分时系统（time sharing）（或者说是多任务），是多道程序系统的自然延伸</strong></p>
<h4 id="分时操作系统"><a href="#分时操作系统" class="headerlink" title="分时操作系统"></a>分时操作系统</h4><p>分时系统的特点：</p>
<ol>
<li>CPU依然通过在作业间切换来达到执行多个作业,但其<strong>切换速度很快,用户可以在程序运行期间与其交互</strong></li>
<li><strong>要求计算机是可交互的（且交互操作响应时间短）</strong>, 这需要有如键盘,鼠标或触摸板等输入设备, 系统等待输入的即时结果。这些设备的响应时间应当较短，以给予顺滑的交互体验，通常小于1秒</li>
<li><strong>分时操作系统允许许多用户同时共享一台计算机</strong>。由于分时系统的每个动作或命令往往较短，因而每个用户只需少量CPU时间。随着系统从一个用户<strong>快速切换到另一个用户</strong>，每个<strong>用户都会感到整个系统只为自已所用</strong>，尽管它事实上为许多用户所共享。</li>
<li>分时操作系统采用CPU调度和多道程序设计，<strong>为每个用户提供一小部分的分时计算机资源</strong>。每个用户至少有一个程序在内存中。加载到内存并执行的程序，通常称为<strong>进程（process）</strong>。当遇到需要用户响应的操作时（耗时长），可以快速转到其他任务或其它用户来提高资源利用率。</li>
<li><strong>操作系统必须确保合理的响应时间</strong>。这有时可以通过交换（swapping）来得到，<strong>交换可将进程从磁盘调人内存，也可将进程从内存调到磁盘</strong>。不过，<strong>虚拟内存（virtual memory）是实现合理响应时间的更为常用的一种方法</strong>，虚拟内存允许一个执行作业不必完全在内存中（第9章）。虚拟内存的主要优点是，用户可执行比物理内存（physical memory）大的程序。再者，<strong>它将内存抽象成一个庞大的、统一的存储数组，将用户理解的逻辑内存（logical memory）与真正的物理内存区分开来。这种安排使得程序员不受内存空间的限制</strong>。</li>
</ol>
<p>(另外两种操作系统为 <a href="#%E5%AE%9E%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">实时操作系统</a>和<a href="#%E6%89%B9%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">批处理操作系统</a>)</p>
<p>由于内存有限，操作系统需要进行<strong>作业调度</strong>来确定优先顺序（加载到内存）。在内存中保存多个程序也需要<strong>内存管理</strong>。此外，若有多个任务等待执行，需要系统做出决策，这被称为<strong>CPU调度</strong>（CPU scheduling）。</p>
<h3 id="1-5-操作系统的执行"><a href="#1-5-操作系统的执行" class="headerlink" title="1-5 操作系统的执行"></a>1-5 操作系统的执行</h3><p><strong>现代操作系统是中断驱动（interrupt driven）的</strong>。如果没有进程需要执行，没有I&#x2F;O设备需要服务，而且没有用户需要响应，那么操作系统会静静地<strong>等待某个事件的发生</strong>。<strong>事件总是由中断或陷阱引起的。陷阱（trap）（或异常（exception））是一种软件生成的中断</strong>，或源于出错（如除数为零或无效存储访问），或源于用户程序的特定请求（执行操作系统的某个服务）。这种操作系统的中断特性规定了系统的通用结构。<strong>对于每种中断，操作系统有不同代码段来处理。中断服务程序用于处理中断。</strong></p>
<p>操作系统的正确设计必须确保错误程序（或恶意程序）不会造成其他程序的错误执行。</p>
<h4 id="1-5-1-双重模式与多重模式的执行"><a href="#1-5-1-双重模式与多重模式的执行" class="headerlink" title="1-5-1 双重模式与多重模式的执行"></a>1-5-1 双重模式与多重模式的执行</h4><p>为了确保操作系统的正确运行，<strong>必须区分操作系统代码和用户代码的执行</strong>。大多数计算机系统<strong>采用硬件支持</strong>，以便区分各种执行模式。</p>
<p><strong>至少需要两种单独运行模式</strong>：<strong>用户模式</strong>（user mode）和<strong>内核模式</strong>（kernel mode）（也称为<strong>监视模式</strong>（supervisor mode）、<strong>系统模式</strong>（system mode）或<strong>特权模式</strong>（privileged mode））。<strong>计算机硬件可以通过一个模式位（mode bit）来表示当前模式</strong>：内核模式（0）和用户模式（1）。有了模式位，就可区分为操作系统执行的任务和为用户执行的任务。当计算机系统<strong>执行用户应用时，系统处于用户模式</strong>。然而，当用户应用<strong>通过系统调用，请求操作系统服务时</strong>，<strong>系统必须从用户模式切换到内核模式</strong>，以满足请求，如图1-10所示。</p>
<p><img src="/osimg/%E6%A8%A1%E5%BC%8F%E5%88%87%E6%8D%A2.png" alt="模式切换"></p>
<p>当系统引导时，硬件从内核模式开始。操作系统接着加载，然后开始在用户模式下执行用户程序。一旦有陷阱或中断，硬件会从用户模式切换到内核模式（即将模式位的状态设为0）。因此，每当操作系统能够控制计算机时，它就处于内核模式。在将控制交给用户程序前，系统会切换到用户模式（将模式位设为1）。</p>
<p>双重模式执行提供保护手段，以便防止操作系统和用户程序受到错误用户程序的影响。<strong>这种防护实现为：将可能引起损害的机器指令作为特权指令（privileged instruction），并且硬件只有在内核模式下才允许执行特权指令</strong>。如果在<strong>用户模式下试图执行特权指令</strong>，那么硬件并<strong>不执行该指令</strong>，而是<strong>认为该指令非法，并将其以陷阱形式通知操作系统</strong>。</p>
<p>模式概念可以扩展，从而超过两个，这样CPU在设置和检测模式时，就会用到多个位。<strong>支持虚拟化（virtualization）技术的CPU有一种单独模式，用于表示虚拟机管理器（Virtual Machine Manager，VMM）是否正在控制系统。这种模式的特权要多于用户模式，但少于内核模式。</strong>这种特权模式<strong>可以改变CPU状态，以便创建和管理虚拟机</strong>。有时，不同的内核组件也会使用不同模式。需要注意的是，除了模式外，CPU设计人员也可采用其他方式来区分执行特权。例如，Intel 64系列的CPU有四种特权级别（privilege level）并支持虚拟化，但是没有一个特定的虚拟化模式。</p>
<p>一旦硬件保护到位，就可检测<strong>模式错误。这些错误通常由操作系统处理</strong>。如果一个用户程序出错，如试图执行非法指令或者访问不属于自己的地址空间内存，则通过硬件陷到操作系统。<strong>陷阱如同中断一样，通过中断向量可将控制转到操作系统</strong>。当一个程序出错时，可由操作系统来异常终止。这种情况的处理代码与用户请求的异常终止一样。操作系统会给出一个适当的出错信息，并倒出（dump）程序内存。倒出内存信息通常写到文件，这样用户或程序员可检查它，纠正错误并重新启动程序。  </p>
<h4 id="1-5-2-定时器"><a href="#1-5-2-定时器" class="headerlink" title="1-5-2 定时器"></a>1-5-2 定时器</h4><p>操作系统应该维持控制CPU，防止用户程序陷入死循环，或不调用系统服务并且不将控制返给操作系统。为了实现这一目标，可以使用定时器（timer）。定时器可设置为在指定周期后中断计算机。指定周期可以是固定的（例如，1&#x2F;60s）或可变的（例如，1ms～1s）。可变定时器（variable timer）一般通过一个固定速率的时钟和计数器来实现。<strong>操作系统设置计数器并随时间递减，计数器归零时产生中断将控制转给操作系统，由操作系统决定抛出错误或给用户更长时间</strong>。  </p>
<h3 id="1-6-进程管理"><a href="#1-6-进程管理" class="headerlink" title="1-6 进程管理"></a>1-6 进程管理</h3><p><strong>进程可以通过创建子进程来并发执行</strong></p>
<h4 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h4><p>将一个单位时间分割为多个子区间，在子区间上给程序运行分配时间，这样就实现了单一时间内 “同时运行多个” 程序。</p>
<p><strong>进程为了完成任务，需要一定的资源</strong>，包括CPU时间、内存、文件、I&#x2F;O设备等。这些资源<strong>可以在进程创建时赋予，也可以在执行进程时分配</strong>。除了创建时得到的各种物理和逻辑资源外，<strong>进程还可以接受传输过来的各种初始化数据（输入）</strong>。</p>
<p>需要强调的是，<strong>程序本身不是进程，程序是个被动实体（passive entity），如同存储在磁盘上的文件内容，而进程是个主动实体（active entity）</strong>。<strong>单线程进程</strong>有一个<strong>程序计数器（program counter），指定了下一个所要执行的指令</strong>（第4章讨论线程）。这样一个进程的执行应是顺序的。CPU一个接着一个地执行进程的指令，直至进程完成。再者，<strong>在任何时候，每个进程最多只能执行一条指令</strong>。因此，尽管两个进程可能与同一个程序相关联，然而这两个进程都有各自的执行顺序。<strong>多线程进程有多个程序计数器，每一个指向下一个给定线程需要执行的指令</strong>。  </p>
<p><strong>进程是系统的工作单元</strong>。<strong>系统由多个进程组成，其中有的是操作系统进程（执行系统代码），其他的是用户进程（执行用户代码）</strong>。<strong>所有这些进程都会并发执行，例如通过在单CPU上采用多路复用来实现</strong>。</p>
<h4 id="操作系统负责进程管理的以下活动："><a href="#操作系统负责进程管理的以下活动：" class="headerlink" title="操作系统负责进程管理的以下活动："></a>操作系统负责进程管理的以下活动：</h4><ul>
<li>在CPU上调度进程和线程</li>
<li>创建和删除用户进程和系统进程</li>
<li>挂起和重启进程</li>
<li>提供进程同步机制</li>
<li>提供进程通信机制</li>
</ul>
<h3 id="1-7-内存管理"><a href="#1-7-内存管理" class="headerlink" title="1-7 内存管理"></a>1-7 内存管理</h3><p><strong>如果CPU需要处理磁盘数据，这些数据必须先通过CPU产生的IO调用传播到内存</strong></p>
<h4 id="操作系统负责内存管理的以下活动："><a href="#操作系统负责内存管理的以下活动：" class="headerlink" title="操作系统负责内存管理的以下活动："></a>操作系统负责内存管理的以下活动：</h4><ul>
<li>记录内存的哪部分在被使用以及被谁使用</li>
<li>决定哪些进程（或其部分）会调入或调出内存</li>
<li>根据需要分配和释放内存空间</li>
</ul>
<h3 id="1-8-存储管理"><a href="#1-8-存储管理" class="headerlink" title="1-8 存储管理"></a>1-8 存储管理</h3><p><strong>文件为逻辑存储单元</strong></p>
<h4 id="1-8-1-文件系统管理"><a href="#1-8-1-文件系统管理" class="headerlink" title="1-8-1 文件系统管理"></a>1-8-1 文件系统管理</h4><p>文件是创建者定义的相关信息组合。通常，文件内容为程序（源程序和目标程序）和数据。数据文件可以是数值的、字符的、字符数值的或二进制的等。文件可以没有格式（例如文本文件），或有严格格式（例如固定的域）。显然，文件这一概念是极为广泛的。</p>
<h5 id="操作系统负责文件管理的以下活动："><a href="#操作系统负责文件管理的以下活动：" class="headerlink" title="操作系统负责文件管理的以下活动："></a>操作系统负责文件管理的以下活动：</h5><ul>
<li>创建和删除文件</li>
<li>创建和删除目录，以便组织文件</li>
<li>提供文件和目录的操作原语</li>
<li>映射文件到外存</li>
<li>备份文件到稳定（非易失的）存储介质</li>
</ul>
<p><em>原语，一般是指由若干条指令组成的程序段，用来实现某个特定功能，在执行过程中不可被中断。</em></p>
<h4 id="1-8-2-大容量存储器管理"><a href="#1-8-2-大容量存储器管理" class="headerlink" title="1-8-2 大容量存储器管理"></a>1-8-2 大容量存储器管理</h4><h5 id="操作系统负责硬盘管理的以下活动："><a href="#操作系统负责硬盘管理的以下活动：" class="headerlink" title="操作系统负责硬盘管理的以下活动："></a>操作系统负责硬盘管理的以下活动：</h5><ul>
<li>空闲空间管理</li>
<li>存储空间分配</li>
<li>硬盘调度</li>
</ul>
<p><strong>由于外存使用频繁，因此使用应该高效。计算机运行的最终速度与硬盘子系统的速度和管理该子系统的算法有很大关系。</strong></p>
<h4 id="1-8-3-高速缓存"><a href="#1-8-3-高速缓存" class="headerlink" title="1-8-3 高速缓存"></a>1-8-3 高速缓存</h4><p>高速缓存（caching）有时也简称为缓存，是计算机系统的一条重要原理。<strong>它的工作原理如下：信息通常保存在一个存储系统中（如内存），使用时，它会被临时复制到更快存储系统，即高速缓存</strong>；当<strong>需要特定信息</strong>时，<strong>首先检查它是否处于高速缓存</strong>，如果是，可以直接使用高速缓存的信息，如果否，<strong>就使用位于源地的信息，同时将其复制到高速缓存以便下次再用</strong>。</p>
<p>另外，<strong>可编程的内部寄存器（如索引寄存器）为内存提供高速缓存</strong>。程序员（或编译程序）通过寄存器分配（register关键字）与寄存器替换的算法，决定哪些信息应存在寄存器中而哪些应存在内存中。</p>
<p>部分高速缓存通过硬件实现。</p>
<p><img src="/osimg/%E5%82%A8%E5%AD%98%E6%80%A7%E8%83%BD.png" alt="存储性能"></p>
<p>上图中，上一级的存储器可以视作跟第一级的高速缓存，如内存可以视作硬盘的高速缓存。存储器之间形成了从慢到快的层次结构，<strong>数据在这之间的流动可以是显式的，也可以是隐式的</strong>，这<strong>取决于硬件设计和操作系统的控制软件</strong>。例如, <strong>高速缓存到CPU或寄存器的数据传递，通常通过硬件完成(隐式的)</strong>, 无需操作系统干预。相反, <strong>磁盘到内存的数据传递通常通过操作系统控制(显式的)</strong>. </p>
<p><img src="/osimg/%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB%E4%BE%8B%E5%AD%90.png" alt="整数A从磁盘到寄存器的迁移"></p>
<p>在层次存储结构中，同一数据可能出现在存储系统的不同层次上。例如，位于文件B的整数A需要加1，而文件B位于磁盘。加1操作这样进行：先进行IO操作以将A所在的块调人内存。之后，A被复制到高速缓存和内部寄存器。这样，A的副本出现在多个地方：磁盘上、内存中、高速缓存中、内部寄存器中（见图1-12）。一旦在内部寄存器中执行加法后，A的值在不同存储系统中就会不同。只有在A的新值从内部寄存器写到磁盘时，A的值才会一样。</p>
<p>对于多处理器环境，情况就变得更为复杂，这时每个CPU不仅有自已的内部寄存器，而且还有本地的高速缓存。对于这种环境，A的拷贝可能出现在多个缓存上。<strong>由于多个CPU可以并行执行，应确保位于一个高速缓存的A值的更新，应马上反映到所有其他A所在的高速缓存</strong>。这称为<strong>高速缓存一致性（cache coherence）</strong>，这通常是<strong>硬件问题</strong>(不归操作系统管).   </p>
<h4 id="1-8-4-io系统"><a href="#1-8-4-io系统" class="headerlink" title="1-8-4 io系统"></a>1-8-4 io系统</h4><p><strong>操作系统的目的之一时为用户隐藏具体硬件设备的特性</strong>，I&#x2F;O子系统为用户隐藏了他们本身的特性。</p>
<h5 id="io子系统包含以下组件："><a href="#io子系统包含以下组件：" class="headerlink" title="io子系统包含以下组件："></a>io子系统包含以下组件：</h5><ul>
<li>包括缓冲、高速缓存和假脱机的内存管理组件</li>
<li>设备驱动器的通用接口</li>
<li>特定硬件设备的驱动程序</li>
</ul>
<p>I&#x2F;O系统与数据传输以及外部设备的访问密切关联。</p>
<h3 id="1-9-保护和安全"><a href="#1-9-保护和安全" class="headerlink" title="1-9 保护和安全"></a>1-9 保护和安全</h3><p><strong>通过机制确保只有经过操作系统授权，进程才可使用相应资源，如文件、内存、CPU及其他资源</strong>。例如，内存寻址硬件确保一个进程仅可在自己的地址空间内执行，定时器确保没有进程可以一直占用CPU而不释放它。设备控制寄存器不能被用户访问，因而保护了各种外围设备的完整性。</p>
<p><strong>保护和安全要求系统能够区分所有用户</strong>。大多数的操作系统采用一个列表，以便维护用户名称及其关联<strong>用户标识（User ID，UID）</strong>。按照Windows的说法，这称为安全ID（Secure ID，SID）。这些数字ID对每个用户来说是唯一的，当一个用户登录到系统时，认证阶段确定用户的合适ID。<strong>该用户ID与所有该用户的进程和线程相关联</strong>。当该ID需要为用户可读时，它就会通过用户名称列表而转换成用户名称</p>
<p><strong>用户有时需要升级特权（escalate privilege），来获得某个活动的额外许可</strong>。例如，用户可能需要访问某个受限设备。操作系统提供多种方法，允许升级特权。例如，在UNIX系统中，程序的setuid属性<strong>允许按程序文件所有者的用户ID而不是当前的用户ID来运行该程序</strong>，该进程会按有效UID（effective UID）运行，直至它关掉额外特权或终止。（以管理员身份运行）</p>
<h3 id="1-10-内核数据结构"><a href="#1-10-内核数据结构" class="headerlink" title="1-10 内核数据结构"></a>1-10 内核数据结构</h3><h4 id="1-10-1-列表，堆栈和队列"><a href="#1-10-1-列表，堆栈和队列" class="headerlink" title="1-10-1 列表，堆栈和队列"></a>1-10-1 列表，堆栈和队列</h4><p>列表可能是除数组以外最终要的数据结构。但列表不提供随机访问，查找需要O(n)复杂度。</p>
<p><img src="/osimg/%E9%93%BE%E8%A1%A8%E5%AE%9E%E4%BE%8B.png" alt="几种链表"></p>
<p><strong>堆栈</strong>（stack）作为<strong>有序数据结构</strong>，在增加和删除数据项时采用<strong>后进先出</strong>（Last In First Out，LIFO）的原则，即最后增加到堆栈的项是第一个被删除的。堆栈的项的插入和删除，分别称为压入（push）和弹出（pop）。操作系统在执行函数调用时，经常采用堆栈。<strong>当调用函数时，参数、局部变量及返回地址首先压入堆栈；当从函数调用返回时，会从堆栈上弹出这些项</strong>。</p>
<p>相反，<strong>队列</strong>（queue）作为<strong>有序数据结构</strong>，采用<strong>先进先出</strong>（First in First Out，FIFO）的原则：删除队列的项的顺序与插人的顺序一致。日常生活的队列样例有很多，如商店客户排队等待结账，汽车排队等待信号灯。操作系统的队列也有很多，例如，送交打印机的作业通常按递交顺序来打印。正如第5章所述，<strong>等待CPU的任务通常按队列来组织</strong>。</p>
<h4 id="1-10-2-树"><a href="#1-10-2-树" class="headerlink" title="1-10-2 树"></a>1-10-2 树</h4><p>树（tree）是一种数据结构，可以表示数据层次。树结构的数据值可按父-子关系连接起来。对于一般树（general tree），父结点可有多个子结点。对于二叉树（binary tree），父结点最多可有两个子结点，即左子结点（leftchild）和右子结点（right child）。二叉查找树（binary search tree）还要求对两个子结点进行排序，如左子结点≤右子结点。图1-16为一个二叉查找树的例子。当需要对一个二叉查找树进行查找时，最坏性能为O(n)(退化成链表)。为了纠正这种情况，我们可以通过算法来创建平衡二叉查找树（balanced binary search tree）。这样，包含n个项的树最多只有lgn层，这可确保最坏性能为O(lgn)。在5.7.1节中，我们将会看到，Linux在CPU调度算法中就使用了平衡二叉查找树。</p>
<center> <img src = "./osimg/二叉查找树.png"> </center>

<h4 id="1-10-2-哈希函数和哈希表"><a href="#1-10-2-哈希函数和哈希表" class="headerlink" title="1-10-2 哈希函数和哈希表"></a>1-10-2 哈希函数和哈希表</h4><p><strong>哈希函数</strong>（hash function）将一个数据唯一地映射到数值。该值可用作一个表（通常为数据组）的索引，以快速获得数据。</p>
<p>哈希函数有一潜在问题：两个输入可能产生同样的输出值，即它们会链接到列表的同一位置。<strong>哈希碰撞（hash collision）可以这样处理：在列表位置上可以存放一个链表，以便将具有相同哈希值的所有项链接起来</strong>。当然，碰撞越多，哈希函数的效率越低。</p>
<h4 id="1-10-3-位图"><a href="#1-10-3-位图" class="headerlink" title="1-10-3 位图"></a>1-10-3 位图</h4><p><strong>位图（bitmap）为有n个二进制位的串，可以表示n位的状态</strong>，如：01001表示第1个和第4个资源可用。这种方式对储存的占用非常小，在硬盘中，每个<strong>磁盘块的可用性就可以用位图保存</strong>。</p>
<h3 id="1-11-计算环境"><a href="#1-11-计算环境" class="headerlink" title="1-11 计算环境"></a>1-11 计算环境</h3><h4 id="1-11-1-传统环境"><a href="#1-11-1-传统环境" class="headerlink" title="1-11-1 传统环境"></a>1-11-1 传统环境</h4><h4 id="1-11-2-移动环境"><a href="#1-11-2-移动环境" class="headerlink" title="1-11-2 移动环境"></a>1-11-2 移动环境</h4><h4 id="1-11-3-分布计算"><a href="#1-11-3-分布计算" class="headerlink" title="1-11-3 分布计算"></a>1-11-3 分布计算</h4><h4 id="1-11-4-客户机-服务器计算"><a href="#1-11-4-客户机-服务器计算" class="headerlink" title="1-11-4 客户机-服务器计算"></a>1-11-4 客户机-服务器计算</h4><p><img src="/osimg/%E5%AE%A2%E6%88%B7%E6%9C%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BB%93%E6%9E%84.png" alt="结构"></p>
<h5 id="服务器系统可大致分为计算服务器和文件服务器："><a href="#服务器系统可大致分为计算服务器和文件服务器：" class="headerlink" title="服务器系统可大致分为计算服务器和文件服务器："></a>服务器系统可大致分为计算服务器和文件服务器：</h5><ul>
<li><strong>计算服务器系统</strong><br>客户发送请求以执行操作（如读数据）。相应地，服务器执行操作，并发送结果到客户机。例如，如果一个服务器运行数据库，那么就可响应客户机的数据请求。</li>
<li><strong>文件服务器系统</strong><br>提供文件系统接口，以便客户机可以创建、更新、访问和删除文件。例如，一个Web服务器可以发送文件到运行Web浏览器的客户机。</li>
</ul>
<h4 id="1-11-5-对等计算"><a href="#1-11-5-对等计算" class="headerlink" title="1-11-5 对等计算"></a>1-11-5 对等计算</h4><p><strong>分布式系统的另一结构是对等（Peer-to-Peer，P2P）系统模型</strong>。这个模型并不区分客户机与服务器。所有系统节点都是对等的，每个节点都可作为客户机或服务器，这取决于它是请求还是提供服务。对等系统与传统的客户机一服务器相比有一优点：<strong>在客户机一服务器系统中，服务器是个瓶颈；但是在对等系统中，分布在整个网络内的多个节点都可提供服务</strong>。  </p>
<center> <img src = "./osimg/对等计算结构.png"> </center>

<h4 id="1-11-6-虚拟化"><a href="#1-11-6-虚拟化" class="headerlink" title="1-11-6 虚拟化"></a>1-11-6 虚拟化</h4><p><strong>通过虚拟化，操作系统可以在其他操作系统上运行应用</strong></p>
<p><strong>广义而言，虚拟化技术是一种软件技术，用于实现模拟</strong>。但这种模拟的代价较高，原来系统的机器层指令要被<strong>转换成现有系统的指令，这期间单个指令常常变成多个指令</strong>，导致性能下降。</p>
<p>模拟的一个常见例子是：<strong>一种计算语言不能编译成原机代码，而是要转换成中间形式或按高级形式来执行。这称为解释（interpretation）</strong>。例如，BASIC可编译也可解释，而Java总是解释的。<strong>解释是一种模拟，允许高级语言代码转换成原CPU的指令</strong>；这<strong>不只是模拟CPU，而是创建了一个理论上的虚拟机器，可以直接运行高级语言</strong>。因此，我们能在Java虚拟机上运行Java程序，尽管这种虚拟机只是Java模拟程序。</p>
<p><strong>数据中心常用需虚拟化技术运行和管理计算环境</strong></p>
<p><img src="/./osimg/VMWare%E7%BB%93%E6%9E%84.png" alt="VMWare"></p>
<p>在内核与硬件间加入了虚拟化层，来将指令转换为对应指令。</p>
<h4 id="1-11-7-云计算"><a href="#1-11-7-云计算" class="headerlink" title="1-11-7 云计算"></a>1-11-7 云计算</h4><h5 id="云计算类型"><a href="#云计算类型" class="headerlink" title="云计算类型"></a>云计算类型</h5><ul>
<li><strong>公云</strong>（public cloud）。只要愿意为服务付费就可以使用的云</li>
<li><strong>私云</strong>（private cloud）。公司自己使用自己的云</li>
<li><strong>混合云</strong>（hybrid cloud）。有公云部分也有私云部分的云</li>
<li><strong>软件即服务</strong>（Software as a Service，SaaS）。可通过Internet使用的<strong>应用程序</strong>（如文字处理程序或电子表格程序）(在线软件)</li>
<li><strong>平台即服务</strong>（Platform as a Service，PaaS）。可通过Internet而<strong>为应用程序（如数据库服务器）使用的软件堆栈</strong></li>
<li><strong>基础设施即服务</strong>（Infrastructure as a Service，IaaS）。可通过Internet使用的<strong>服务器或存储（如用于生产数据备份的存储）</strong></li>
</ul>
<center> <img src = "./osimg/cloud计算结构.png"> </center>

<h4 id="1-11-8-实时嵌入式系统"><a href="#1-11-8-实时嵌入式系统" class="headerlink" title="1-11-8 实时嵌入式系统"></a>1-11-8 实时嵌入式系统</h4><p>嵌人式系统差别相当大。有的是通用计算机，具有标准的操作系统如Linux，并运行专用应用程序来实现功能。还有的硬件设备具有专用的嵌入式操作系统，以提供所需功能。此外，还有其他的硬件设备，不采用操作系统，而<strong>采用专用集成电路</strong>（Application Specific Integrated Circuit，ASIC）来执行任务。</p>
<p>嵌入式操作系统几乎总是采用<strong>实时操作系统</strong>。当<strong>处理器执行或数据流动有严格的时间要求</strong>时，就要采用实时操作系统。</p>
<h5 id="实时操作系统"><a href="#实时操作系统" class="headerlink" title="实时操作系统"></a>实时操作系统</h5><ol>
<li>具有明确的，固定的时间约束，处理<strong>必须</strong>在指定时间内完成，否则系统将报错. <strong>(响应快，可靠性高)</strong></li>
</ol>
<h5 id="批处理操作系统"><a href="#批处理操作系统" class="headerlink" title="批处理操作系统"></a>批处理操作系统</h5><ol>
<li>资源利用率高，吞吐量大</li>
<li>交互性差，<strong>一但程序执行开始就不可中断</strong></li>
</ol>
<h3 id="1-12-开源操作系统"><a href="#1-12-开源操作系统" class="headerlink" title="1-12 开源操作系统"></a>1-12 开源操作系统</h3><h2 id="2-操作系统结构"><a href="#2-操作系统结构" class="headerlink" title="2 操作系统结构"></a>2 操作系统结构</h2><h3 id="2-1-操作系统的服务"><a href="#2-1-操作系统的服务" class="headerlink" title="2-1 操作系统的服务"></a>2-1 操作系统的服务</h3><center> <img src = "./osimg/操作系统服务.png"> </center>

<h4 id="用于提供用户功能的服务"><a href="#用于提供用户功能的服务" class="headerlink" title="用于提供用户功能的服务"></a>用于提供用户功能的服务</h4><p>操作系统有一组<strong>用于提供用户功能的服务</strong>：</p>
<ul>
<li><strong>用户界面</strong>：几乎所有操作系统都有<strong>用户界面（User Interface，UI）</strong>。这种界面<strong>可有多种形式</strong>。一种是<strong>命令行界面</strong>（Command-Line Interface，CLI），它采用文本命令，并用某一方法输入（例如，键盘可按一定格式和选项来输入命令）。另一种是<strong>批处理界面</strong>（batch interface），<strong>命令以及控制这些命令的指令可以编成文件以便执行</strong>。最为常用的是<strong>图形用户界面</strong>（Graphical User Interface，GUI）。这种界面是一种视窗系统，它具有通过定位设备控制I&#x2F;O、通过菜单选择、通过键盘输人文本和选择等</li>
<li><strong>程序执行</strong>：<strong>系统应能加载程序到内存，并加以运行</strong>。程序应能结束执行，包括正常或不正常（并给出错误）</li>
<li><strong>I&#x2F;O操作</strong>：程序运行可能需要I&#x2F;O，这些I&#x2F;O可能涉及文件或设备。为了效率和保护，<strong>用户通常不应直接控制I&#x2F;O设备</strong>。因此，操作系统必须提供手段以便执行I&#x2F;O</li>
<li><strong>文件系统操作</strong>: 对用户使用体验十分重要</li>
<li><strong>通信</strong>：<strong>一个进程需要与另一个进程交换信息</strong>。这种通信可能发生在运行于同一台计算机的两个进程之间，也可能发生在运行于通过网络连接的不同计算机的进程之间。通信实现可以<strong>通过共享内存</strong>（shared memory）（两个或多个进程读写共享内存区域），也可以<strong>通过消息交换</strong>（message passing）（符合预先定义格式的信息分组可以通过操作系统在进程之间移动）</li>
<li><strong>错误检测</strong>：操作系统需要不断检测错误和更正错误。<strong>对于每类错误，操作系统必须采取适当动作，确保计算的正确和一致</strong>。有时，它只能停机。也有时，它可以终结出错进程，或者将出错码返给进程以便进程检测或纠正</li>
</ul>
<h4 id="用于保证运行效率的服务"><a href="#用于保证运行效率的服务" class="headerlink" title="用于保证运行效率的服务"></a>用于保证运行效率的服务</h4><ul>
<li><strong>资源分配</strong>：当多个用户或多个作业同时运行时，每个都应分配资源。操作系统管理许多不同类型的资源。有的资源（如CPU周期、内存和文件存储）可能要有特殊的分配代码，而其他资源（如I&#x2F;O设备）可能只需通用的请求和释放代码。例如，为了更好地使用CPU，操作系统需要采用CPU调度算法，以便考虑CPU的速度、要执行的作业、可用寄存器的数量和其他因素。还有一些其他程序可以分配打印机、USB存储器和其他外设</li>
<li><strong>记账</strong>：我们需要记录用户使用资源的类型和数量。这种记录可以用于记账（以便向用户收费），或<strong>统计使用量</strong>。统计使用量对研究人员很有用，<strong>可用于重新配置系统以提高计算服务</strong></li>
<li><strong>保护与安全</strong>：对于保存在多用户或联网的计算机系统的信息，用户可能需要控制信息使用。<strong>当多个独立进程并发执行时，一个进程不应干预其他进程或操作系统本身</strong>。如果一个系统需要保护和安全，那么系统的所有部分都要预防。一条链的强度与其最弱的环节一样。</li>
</ul>
<h3 id="2-2-用户与操作系统的界面"><a href="#2-2-用户与操作系统的界面" class="headerlink" title="2-2 用户与操作系统的界面"></a>2-2 用户与操作系统的界面</h3><p>前面提到了界面可以为命令行，批处理和图形用户界面。这里主要讨论两种基本方案，一种提供<strong>命令行或命令解释程序</strong>（command interpreter）, <strong>允许用户直接输入指令</strong>。另一种允许用户通过GUI交互。</p>
<h4 id="2-2-1-命令解释程序"><a href="#2-2-1-命令解释程序" class="headerlink" title="2-2-1 命令解释程序"></a>2-2-1 命令解释程序</h4><p><strong>有的操作系统内核包括命令解释程序</strong>。其他操作系统，如Windows和UNIX，将命令解释程序当作一个特殊程序，当一个任务开始或用户首次登录时（交互系统），该程序就会运行。对于<strong>具有多个可选命令解释程序的系统，解释程序称为外壳（shell）</strong>。</p>
<p>命令解释程序的<strong>主要功能是获取并执行用户指定的下一条命令</strong>，这有两种常见实现方法：</p>
<ol>
<li><strong>命令解释程序本身包含代码以执行这些命令</strong>。例如，删除文件的命令可让命令解释程序跳转到相应的代码段，以设置参数并执行相应系统调用。对于这种方法, <strong>所能提供命令的数量决定命令解释程序的大小，因为每个命令都要有实现代码</strong>。（体积问题）</li>
<li><strong>通过系统程序实现大多数的命令</strong>，常用于许多操作系统，如UNIX。这样, <strong>命令解释程序不必理解命令，而只要通过命令确定一个文件，以加载到内存并执行</strong>。因此，UNIX删除文件的命令<code>bash rm fuke txt</code><br>会查找名为rm的文件，将该文件加载到内存，并用参数file.txt来执行。与rm命令相关的功能是完全由文件rm的代码决定的。这样，程序员可以通过<strong>创建合适名称的新文件，轻松地向系统增加新命令</strong>。这种命令解释程序可能很小，而且在增加新命令时无需修改。(体积小，更新方便)</li>
</ol>
<h4 id="2-2-2-图形用户界面"><a href="#2-2-2-图形用户界面" class="headerlink" title="2-2-2 图形用户界面"></a>2-2-2 图形用户界面</h4><p>与操作系统交互的第二种方法是，采用用户友好的图形用户界面（GUI）。因此，用户不是通过命令行界面直接输入命令，而是利用桌面（desktop）概念，即采用基于鼠标的视窗和菜单系统。用户移动鼠标，定位指针到屏幕（桌面）上的图标（icon），而这些图标代表程序、文件、目录和系统功能。根据鼠标指针的位置，按下鼠标按钮可以调用程序，选择文件和目录（也称为文件夹（folder）），或打开菜单命令。</p>
<h4 id="2-2-3-界面的选择"><a href="#2-2-3-界面的选择" class="headerlink" title="2-2-3 界面的选择"></a>2-2-3 界面的选择</h4><p>选择命令行界面或GUI主要取决于各人喜好。管理计算机的系统管理员（system administrator）和了解系统很透彻的高级用户（power user）经常使用命令行界面。对他们来说，这样效率更高。事实上，有的系统只有部分功能可通过GUI使用，而其他不常用的功能则通过命令行来使用。再者，<strong>命令行界面对重复性的任务更为容易，其部分原因是它具有可编程的功能</strong>。例如，某个常见任务包括一组命令行步骤，而且这些步骤可编成一个文件，而该文件可像程序一样运行。<strong>这种程序不是编译成可执行代码，而是由命令行界面来解释执行的</strong>。这些<strong>外壳脚本</strong>（shell script）较常用于以命令行为主的系统，如UNIX和Linux。</p>
<p>用户界面可以对系统的不同甚至用户的不同而不同，它<strong>通常不属于操作系统</strong>。从操作系统角度看，无需区分用户程序和系统程序。</p>
<h3 id="2-3-系统调用"><a href="#2-3-系统调用" class="headerlink" title="2-3 系统调用"></a>2-3 系统调用</h3><p><strong>系统调用（system call）提供操作系统服务接口</strong>。</p>
<p>通常，应用程序开发人员<strong>根据应用编程接口（Application Programming Interface，API）来设计程序</strong>。API为方便应用程序员<strong>规定了一组函数</strong>，包括每个函数的输人参数和返回值（程序员所想得到的）。有三组常见API可为应用程序员所用：适用于Windows系统的WindowsAPI、适用于POSIX系统的POSIX API（这包括几乎所有版本的UNIX、Linux和Mac OS X）以及适用于Java虚拟机的Java API。程序员通过操作系统提供的函数库来调用API。对运行于UNIX和Linux的用C语言编写的程序，该库名为libc. <strong>程序员通过操作系统提供的函数库来调用API</strong>。</p>
<p>在后台，<strong>API函数通常为应用程序员调用实际的系统调用</strong>。例如，Windows函数CreateProcess()（显然用于创建一个新进程）实际调用Windows内核的系统调用 NTCreateProcess()。</p>
<h4 id="根据api编程的好处"><a href="#根据api编程的好处" class="headerlink" title="根据api编程的好处"></a>根据api编程的好处</h4><ul>
<li>更好的可移植性，可以在支持同一API的任何系统运行</li>
</ul>
<center> <img src = "./osimg/API_EG.png"> </center>

<p>对大多数的程序设计语言, <strong>运行时支持系统（由编译器直接提供的函数库）提供了系统调用接口(system-call interface)</strong>, 以链接到操作系统的系统调用. <strong>系统调用接口截取API函数的调用，并调用操作系统中的所需系统调用</strong>。通常，每个系统调用都有一个相关数字，而系统调用接口会根据这些数字来建立一个索引列表。系统调用接口就可调用操作系统内核中的所需系统调用，并返回系统调用状态与任何返回值。</p>
<p><strong>系统调用因所用计算机的不同而不同。通常，除了所需的系统调用外，还要提供其他信息</strong>。例如，为了获取输人，可能需要指定作为源的文件或设备以及用于存放输入的内存区域的地址和长度。当然，设备或文件和长度也可以隐含在调用内。</p>
<h4 id="向操作系统传递参数的方法"><a href="#向操作系统传递参数的方法" class="headerlink" title="向操作系统传递参数的方法"></a>向操作系统传递参数的方法</h4><ul>
<li>最简单的是<strong>通过寄存器来传递参数</strong>。不过，有时参数数量会比寄存器多</li>
<li>将<strong>参数存在内存的块或表</strong>中，而块或表的<strong>地址通过寄存器来传递</strong></li>
<li>参数也可通过<strong>程序放在或压入(pushed)到堆栈(stack)</strong>, 并通过操作系统弹出（popped）。</li>
</ul>
<p>有的系统偏爱<strong>块或堆栈方法</strong>，因为这些方法并<strong>不限制传递参数的数量或长度</strong>。</p>
<h3 id="2-4-系统调用的类型"><a href="#2-4-系统调用的类型" class="headerlink" title="2-4 系统调用的类型"></a>2-4 系统调用的类型</h3><p>系统调用大致可分为<strong>六大类</strong>: <strong>进程控制</strong>（process control）, <strong>文件管理</strong>（file manipulation）, <strong>设备管理</strong>（device manipulation）, <strong>信息维护</strong>（information maintenance）, <strong>通信</strong>（communication）和<strong>保护</strong>（protection）。</p>
<center> <img src = "./osimg/系统调用的类型.png"> </center>

<h4 id="2-4-1-进程控制"><a href="#2-4-1-进程控制" class="headerlink" title="2-4-1 进程控制"></a>2-4-1 进程控制</h4><p><strong>执行程序应能正常（end()）或异常（abort()）停止执行</strong>。如果一个系统调用异常停止当前执行的程序，或者程序运行遇到问题并引起错误陷阱，那么有时转储内存到磁盘，并生成错误信息。内存信息转储到磁盘后，可用<strong>调试器</strong>（debugger）来<strong>确定问题原因</strong>（调试器为系统程序，用以帮助程序员发现和纠正错误（bug））. <strong>无论是正常情况还是异常情况，操作系统都应将控制转到调用命令解释程序(Debug时)<strong>。命令解释程序接着读入下个命令。对于交互系统，命令解释程序只是简单读入下个命令，而假定用户会采取合适命令以处理错误。对于GUI系统，弹出窗口可用于提醒用户出错，并请求指引。对于批处理系统，命令解释程序通常终止整个作业，并继续下个作业. <strong>当出现错误时，有的系统可能允许特殊的恢复操作</strong>。如果程序发现输人有错并且想要异常终止，那么它也可能需要</strong>定义错误级别</strong>。错误越严重，错误参数的级别也越高。通过将正常终止的错误级别定义为0，可以把正常和异常终止放在一起处理。命令解释程序或后面的程序可以利用这种错误级别来自动确定下个动作。</p>
<p>执行一个程序的进程或作业可能需要加载（load()）和执行（execute()）另一个程序。这种功能允许命令解释程序来执行一个程序，该命令可以通过用户命令、鼠标点击或批处理命令来给定。一个有趣的问题是：加载程序终止时会将控制返回到哪里？与之相关的问题是：原有程序是否失去或保存了，或者可与新的程序一起并发执行？</p>
<h5 id="windows和unix系统调用的示例"><a href="#windows和unix系统调用的示例" class="headerlink" title="windows和unix系统调用的示例"></a>windows和unix系统调用的示例</h5><p><img src="/./osimg/windows%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%AE%9E%E4%BE%8B.png" alt="Windows 和 UNIX 系统调用的示例"></p>
<p><strong>如果新程序终止时控制返回到现有程序，那么必须保存现有程序的内存映像</strong>。因此，事实上创建了一个机制，以便一个程序调用另一个程序。如果两个程序<strong>并发继续</strong>，那么也就<strong>创建了一个新作业(job)或进程</strong>，以便多道执行。</p>
<p>如果创建了一个新的作业或进程或者一组作业或进程，那么我们<strong>应能控制执行</strong>。这种控制要能判定和重置进程或作业的属性，包括作业的优先级、最大允许执行时间等（get_process_attributes()和set_process_attributes()）。如果发现创建的进程或作业不正确或者不再需要，那么也要能终止它（terminate_process()）。</p>
<p>创建了新的作业或进程后，可能要等待其执行完成，也可能要等待一定时间（wait_time()）。更有可能要等待某个事件的出现（wait_event()）。当<strong>事件出现</strong>时, <strong>作业或进程就会响应</strong>（signal_event()）。</p>
<p>通常，两个或多个进程会共享数据。为了<strong>确保共享数据的完整性</strong>，操作系统通常<strong>提供系统调用，以允许一个进程锁定（lock）共享数据</strong>。这样, <strong>在解锁之前，其他进程不能访问该数据</strong>。通常，这样的系统调用包括acquire_lock()和release_lock()。</p>
<h5 id="进程控制和作业控制的区别-（未完）"><a href="#进程控制和作业控制的区别-（未完）" class="headerlink" title="进程控制和作业控制的区别 （未完）"></a>进程控制和作业控制的区别 （未完）</h5><p>进程和作业控制差异很大，一个涉及单任务系统，另一个涉及多任务系统<br>（PDF P70 MS-DOS &amp; FreeBSD）</p>
<h4 id="2-4-2-文件管理"><a href="#2-4-2-文件管理" class="headerlink" title="2-4-2 文件管理"></a>2-4-2 文件管理</h4><p><strong>不管是文件还是目录，都要能对各种属性的值加以读取或设置</strong>。文件属性包括：文件名、文件类型、保护码、记账信息等。针对这一功能，至少需要两个系统调用一一获取文件属性（getfile_attributes()）和设置文件属性（set_file_attributes()）。有的操作系统还提供其他系统调用，如文件的移动（move()）和复制（copy()）。还有的操作系统通过代码或系统调用来完成这些API的功能。其他的操作系统可能通过系统程序来实现这些功能. <strong>如果系统程序可被其他程序调用，那么这些系统程序也就相当于API</strong>。</p>
<h4 id="2-4-3-设备管理"><a href="#2-4-3-设备管理" class="headerlink" title="2-4-3 设备管理"></a>2-4-3 设备管理</h4><p><strong>操作系统控制的各种资源可看作设备</strong>。有的设备是<strong>物理设备</strong>（如磁盘驱动），而其他的可当作<strong>抽象或虚拟的设备</strong>（如文件）。</p>
<p>进程执行需要一些资源，如内存、磁盘驱动、所需文件等。如果有可用资源，那么系统可以允许请求，并将控制交给用户程序；否则，程序应等待，直到有足够可用的资源为止。</p>
<p>在请求了设备（并得到）后，就能如同对文件一样，对设备进行读（read()）、写（write()）重定位（reposition()）。事实上, <strong>I&#x2F;O设备和文件极为相似</strong>，以至于许多操作系统如UNIX都将这两者组合成文件一设备结构。这样，一组系统调用不但用于文件而且用于设备。有时，I&#x2F;O设备可通过特殊文件名、目录位置或文件属性来辨认。</p>
<h4 id="2-4-4-信息维护"><a href="#2-4-4-信息维护" class="headerlink" title="2-4-4 信息维护"></a>2-4-4 信息维护</h4><p>许多系统调用只不过用于在用户程序与操作系统之间传递信息。例如，大多数操作系统都有一个系统调用，以便返回当前的时间（time()））和日期（date()）。还有的系统调用可以返回系统的其他信息，如当前用户数、操作系统版本、内存或磁盘的可用量等。</p>
<p>还有一组<strong>系统调用帮助调试程序</strong>。许多系统都提供用于<strong>转储内存（dump()）的系统调用</strong>。对于调试，这很有用。程序trace可以列出程序执行时的所有系统调用。甚至微处理器都有一个CPU模式，称为<strong>单步</strong>(single step)，即<strong>CPU每执行一条指令都会产生一个陷阱</strong>。调试器通常可以捕获到这些陷阱。</p>
<p>许多操作系统都提供程序的<strong>时间曲线(time profile)<strong>，用于</strong>表示在特定位置或位置组合上的执行时间</strong>. 时间曲线<strong>需要跟踪功能或固定定时中断</strong>. 当<strong>定时中断出现</strong>时，就会<strong>记录程序计数器</strong>的值。如有足够频繁的定时中断，那么就<strong>可得到花在程序各个部分的时间统计信息</strong>. </p>
<p><strong>操作系统维护所有进程的信息，这些可通过系统调用来访问</strong>. 通常，也可用系统调用重置进程信息（get_process_attributes()和set_process_attributes()）。</p>
<h4 id="2-4-5-通信"><a href="#2-4-5-通信" class="headerlink" title="2-4-5 通信"></a>2-4-5 通信</h4><p>常用模型有两个: <strong>消息传递模型</strong>和<strong>共享内存模型</strong></p>
<h5 id="消息传递模型"><a href="#消息传递模型" class="headerlink" title="消息传递模型"></a>消息传递模型</h5><p>对于<strong>消息传递模型</strong>（message-passing model），通信进程通过相互交换消息来传递信息。进程间的消息交换可以直接进行，也可以通过一个共同邮箱来间接进行。在开始通信前，应先建立连接。应知道另一个通信实体名称，它可能是同一系统的另一个进程，也可能是通过网络相连的另一计算机的进程。每台网络计算机都有一个主机名（host name）。另外，每台主机也都有一个网络标识符，如IP地址。类似地, <strong>每个进程有进程名</strong>（process name），它通常<strong>可转换成标识符，以便操作系统引用</strong>。系统调用get_hostid（）和get_processid（）可以执行这类转换。这些标识符再传给通用系统调用open（）和close（）（由文件系统提供），或专用系统调用open_connection（）和close_connection（），这取决于系统通信模型。接受进程应通过系统调用accept_connection（）来许可通信. <strong>大多数可接受连接的进程为专用的守护进程</strong>（daemon），即<strong>专用系统程序</strong>。它们执行系统调用wait_for_connection（），在<strong>有连接时会被唤醒</strong>。通信源称为<strong>客户机</strong>（client），而接受后台程序称为<strong>服务器</strong>（server），它们通过系统调用read_message（）和write_message（）来交换消息。系统调用close_connection（）终止通信。</p>
<h5 id="共享内存模型"><a href="#共享内存模型" class="headerlink" title="共享内存模型"></a>共享内存模型</h5><p>对于<strong>共享内存模型</strong>（shared-memory model），进程通过系统调用shared_memory_create（）和shared_memory_attach（）创建共享内存，并访问其他进程拥有的内存区域。注意，操作系统<strong>通常需要阻止一个进程访问另一个进程的内存</strong>。共享内存<strong>要求两个或多个进程都同意取消这一限制，这样它们就可通过读写共享区域的数据来交换信息</strong>。这种数据的类型是由这些进程来决定的，而<strong>不受操作系统的控制</strong>. <strong>进程也负责确保不会同时向同一个地方进行写操作(转交给进程确保来确保安全)<strong>。这些机制将在第6章讨论。第4章将讨论进程概念的一种变形，即</strong>线程</strong>（thread），它们<strong>默认共享内存</strong>。</p>
<h5 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h5><ul>
<li>消息传递模型对少量数据来说很好用，因为不需要避免冲突，也更容易实现。</li>
<li>共享内存模型能以内存传输速度在进程中传递数据，因此对于大量数据很有效，但在保护和同步方面有问题。</li>
</ul>
<h4 id="2-4-6-保护"><a href="#2-4-6-保护" class="headerlink" title="2-4-6 保护"></a>2-4-6 保护</h4><p>通常，提供保护的系统调用包括set_permission（）和get_permission（），用于设置资源（如文件和磁盘）权限。系统调用allow_user（）和deny_user（）分别用于允许和拒绝特定用户访问某些资源。</p>
<h3 id="2-5-系统程序"><a href="#2-5-系统程序" class="headerlink" title="2-5 系统程序"></a>2-5 系统程序</h3><p><strong>一组系统程序是现代操作系统的一大特点</strong>，系统程序（system program），也称为<strong>系统工具</strong>（system utility），为程序开发和执行<strong>提供了一个方便的环境</strong>。</p>
<h4 id="系统程序类别"><a href="#系统程序类别" class="headerlink" title="系统程序类别"></a>系统程序类别</h4><ol>
<li><strong>文件管理</strong>：这些程序创建、删除、复制、重新命名、打印、转储、列出、操作文件和目录。</li>
<li><strong>状态信息</strong>：有些程序可从系统那里得到日期、时间、内存或磁盘空间的可用数量、用户数或其他状态信息。有些系统还支持<strong>注册表</strong>(registry)，可用于存储和获取配置信息。</li>
<li><strong>文件修改</strong>：有多个编辑器可以创建和修改位于磁盘或其他存储设备上的文件。也有专用命令，可用于查找文件内容或进行文本转换。</li>
<li><strong>程序语言支持</strong>：常用程序语言（如C、C++、Java和PERL等）的编译程序、汇编程序调试程序和解释程序，通常与操作系统一起提供给用户，或可另外下载。</li>
<li><strong>程序加载与执行</strong>：程序一旦汇编或编译后，要加载到内存才能执行。系统可以<strong>提供绝对加载程序、重定位加载程序、链接编辑器和覆盖式加载程序</strong>。系统还要<strong>提供高级语言或机器语言的调试程序</strong>。</li>
<li><strong>通信</strong>：这些程序提供在进程、用户和计算机系统之间创建虚拟连接的机制。</li>
<li><strong>后台服务</strong>：所有通用系统都有方法，以便在引导时创建一些系统程序的进程。这些进程中，有的执行完任务后就终止，而有的会一直运行到系统停机. <strong>一直运行的系统进程，称为服务（service）、子系统（sub system）或守护进程</strong>。</li>
</ol>
<h3 id="2-6-操作系统的设计和实现"><a href="#2-6-操作系统的设计和实现" class="headerlink" title="2-6 操作系统的设计和实现"></a>2-6 操作系统的设计和实现</h3><h4 id="2-6-1-设计目标"><a href="#2-6-1-设计目标" class="headerlink" title="2-6-1 设计目标"></a>2-6-1 设计目标</h4><p><strong>系统设计的首要问题是，定义目标和规范</strong>。从高层来说，系统设计取决于所选硬件和系统类型：批处理、分时、单用户、多用户、分布式、实时或通用。需求可分为两个基本大类: <strong>用户目标(user goal)和系统目标(system goal)</strong>. </p>
<h4 id="2-6-2-机制与策略"><a href="#2-6-2-机制与策略" class="headerlink" title="2-6-2 机制与策略"></a>2-6-2 机制与策略</h4><p>一个重要原则是<strong>策略（policy）与机制（mechanism）的分离</strong>。机制决定如何做，而策略决定做什么。例如，<a href="#1-5-2-%E5%AE%9A%E6%97%B6%E5%99%A8">定时器</a>是一种保护CPU的机制，但是为某个特定用户应将定时器设置成多长时间，就是一个策略问题。</p>
<p>目标是提供足够的机制，具体用法看实际使用需求。</p>
<h4 id="2-6-3-实现"><a href="#2-6-3-实现" class="headerlink" title="2-6-3 实现"></a>2-6-3 实现</h4><p>Linux和Windows操作系统内核主要用C编写，尽管有小部分是用<strong>汇编语言来编写的用于设备驱动程序与保存和恢复寄存器状态的代码</strong>。</p>
<h5 id="采用高级语言编写操作系统的优缺点"><a href="#采用高级语言编写操作系统的优缺点" class="headerlink" title="采用高级语言编写操作系统的优缺点"></a>采用高级语言编写操作系统的优缺点</h5><ul>
<li>优点：代码编写更快，更为紧凑，更容易理解和调试。另外，编译技术的改进使得只要通过重新编译，就可改善整个操作系统的生成代码。最后，如果用高级语言来编写，操作系统更容易移植（port）到其他硬件。若使用汇编，则可能受硬件影响无法使用，由于指令集不同。</li>
<li>缺点：缺点仅仅在于速度的降低和存储的增加。不过，这对当今的系统已不再是主要问题。虽然汇编语言高手能编写更快、更小的子程序，但是现代编译器能对大程序进行复杂分析并采用高级优化技术生成优秀代码。现代处理器都有很深的流水线和很多功能块，它们要比人类更容易处理复杂的依赖关系。</li>
</ul>
<h3 id="2-7-操作系统的结构"><a href="#2-7-操作系统的结构" class="headerlink" title="2-7 操作系统的结构"></a>2-7 操作系统的结构</h3><p>设计的常用方法是<strong>将系统分成子系统或模块</strong>，而不只是一个<strong>单片系统</strong>（monolithic system）。每个模块都应是<strong>定义明确的部分系统</strong>，且具有定义明确的输入、输出和功能。</p>
<h4 id="2-7-1-简单结构（单片结构）"><a href="#2-7-1-简单结构（单片结构）" class="headerlink" title="2-7-1 简单结构（单片结构）"></a>2-7-1 简单结构（单片结构）</h4><p>即将大量模块集合在同一个功能区</p>
<center> <img src = "./osimg/UNIX系统结构.png"> </center>

<p>内核通过系统调用，可提供文件系统、CPU调度、内存管理和其他操作系统功能。总的来说，这一层里面包含了大量功能。这种单片结构使得UNIX<strong>难以实现与设计</strong>。不过，它有一个<strong>独特的性能优势</strong>：系统调用接口和内核<strong>通信的开销非常小</strong>。</p>
<h4 id="2-7-2-分层方法"><a href="#2-7-2-分层方法" class="headerlink" title="2-7-2 分层方法"></a>2-7-2 分层方法</h4><p>即操作系统分成若干层（级）。最低层（层0）为硬件，最高层（层N）为用户接口。</p>
<center> <img src = "./osimg/分层操作系统.png"> </center>

<p>分层法的<strong>主要优点在于简化了构造和调试</strong>。所选的层次要求每层只能调用更低层的功能（操作）和服务。这种方法简化了系统的调试和验证. <strong>(也导致了多次层间系统调用和传递参数带来的较高开销)</strong></p>
<p>分层法中，每层要为更高层隐藏一定的数据结构、操作和硬件。</p>
<p><strong>分层法的主要难点在于合理定义各层</strong>。由于每层只能利用更低层的功能，因此有必要仔细规划。例如，用于备份存储（虚拟内存算法所用的磁盘空间）的设备驱动程序应位于内存管理程序之下(更底层)，这是因为内存管理需要用到这些功能来备份存储。有些要求并不这么明显。备份存储驱动程序通常在CPU调度器之上，这是因为该驱动需要等待I&#x2F;O完成并且CPU还要进行调度. <strong>不过，对于大型系统，CPU调度器可能拥有所有活动进程的更多信息，以至于不能全部保存在内存中。因此，这些信息需要换入和换出内存，从而要求备份存储驱动程序位于CPU调度器之下</strong>。(内存管理可能也在CPU调度器之下)</p>
<h4 id="2-7-3-微内核-（P77）"><a href="#2-7-3-微内核-（P77）" class="headerlink" title="2-7-3 微内核 （P77）"></a>2-7-3 微内核 （P77）</h4><p><strong>微内核</strong>（micro kernel）技术对内核进行模块化。这种方法构造的操作系统，从<strong>内核中删除所有不必要的部件，而将它们当作系统级与用户级的程序来实现</strong>。这样做的结果是<strong>内核较小</strong>。关于哪些应留在内核内，而哪些可在用户空间内实现，并没有定论。不过，通常微内核<strong>会提供最小的进程与内存管理以及通信功能</strong>。  </p>
<center> <img src = "./osimg/微内核架构.png"> </center>

<p>微内核的主要功能是<strong>为客户端程序和运行在用户空间中的各种服务提供通信</strong>。通信是通过<a href="#%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E6%A8%A1%E5%9E%8B">消息传递</a>（message passing）来提供的。</p>
<h5 id="微内核方法的优点"><a href="#微内核方法的优点" class="headerlink" title="微内核方法的优点"></a>微内核方法的优点</h5><ul>
<li><strong>便于扩展操作系统</strong>：所有新服务可在用户空间内增加，因而并不需要修改内核。当内核确实需要修改时，所做修改也会很小</li>
<li><strong>更好的可移植性</strong>：因为便于拓展和修改</li>
<li><strong>更好的安全性和可靠性</strong>：大多数服务是<strong>作为用户进程</strong>而不是作为内核进程来运行的。如果一个服务出错，那么<strong>操作系统的其他部分并不受影响</strong></li>
</ul>
<h5 id="微内核方法的缺点"><a href="#微内核方法的缺点" class="headerlink" title="微内核方法的缺点"></a>微内核方法的缺点</h5><p>增加了系统功能的开销，微内核的性能会受损。</p>
<p>Windows NT 4.0通过将有些层从用户空间移到内核空间以及更紧密地集成这些层来提高性能。等到Windows XP时，Windows架构更像是单片内核的，而不是微内核的。  </p>
<h4 id="2-7-4-模块"><a href="#2-7-4-模块" class="headerlink" title="2-7-4 模块"></a>2-7-4 模块</h4><p>也许目前操作系统设计的最佳方法是采用<strong>可加载的内核模块</strong>（loadable kernel module）。这里，内核有一组核心组件, <strong>无论在启动或运行时, 内核都可通过模块链入额外服务</strong>. </p>
<p>这种设计的思想是：内核提供核心服务，而其他服务可在内核运行时动态实现。动态链接服务优于直接添加新功能到内核，这是因为对于每次更改，后者都要重新编译内核。例如，可将CPU调度器与内存管理的算法直接建立在内核中，而通过可加载模块，可以支持不同文件系统。  </p>
<p>这种整体系统<strong>类似于一个分层系统</strong>，其中每个内核部分都有已定义的、受保护的接口。但它<strong>比分层系统更加灵活</strong>，这是因为任何模块都可以调用任何其他模块。这种方法<strong>也类似于微内核方法</strong>：主模块只有核心功能，并知道如何加载模块以及如何让模块进行通信. <strong>但它更为有效，因为模块无需调用消息传递来进行通信</strong>。  </p>
<h4 id="2-7-5-混合系统"><a href="#2-7-5-混合系统" class="headerlink" title="2-7-5 混合系统"></a>2-7-5 混合系统</h4><h3 id="2-8-操作系统的调试"><a href="#2-8-操作系统的调试" class="headerlink" title="2-8 操作系统的调试"></a>2-8 操作系统的调试</h3><h4 id="2-8-1-故障分析"><a href="#2-8-1-故障分析" class="headerlink" title="2-8-1 故障分析"></a>2-8-1 故障分析</h4><p>当一个<strong>进程发生故障</strong>时，大多数操作系统*将错误信息写到一个日志文件<strong>（log file），以提醒系统操作员或用户所发生的问题。操作系统也会进行</strong>核心转储**（core dump），即进程内存的捕获，并保存到一个文件以便以后分析。（在计算机早期，内存称为“核心”。）运行程序和核心转储可用调试器来分析，以便程序员分析进程的代码和内存。  </p>
<p>用户级进程代码的调试是一个挑战。由于内核代码多且复杂、硬件控制以及用户级调试工具的缺乏，操作系统的内核调试更为复杂. <strong>内核故障称为崩溃</strong>（crash）。当发生崩溃时，错误信息会保存到一个日志文件，并且<strong>内存状态会保存到一个崩溃转储</strong>（crash dump）。</p>
<p><strong>文件系统代码的内核故障</strong>会使内核在重启前将状态保存到文件系统上而产生风险。因此，一种常见技术是<strong>将内核内存保存到硬盘的某个部分</strong>，而该部分<strong>不包含任何文件系统</strong>。当内核检测到一个不可恢复的错误时，就会将全部内存的内容或至少系统内存的内核部分保存到磁盘区域。当系统启动后，有个进程会收集这个区域的数据，并将它写到文件系统的崩溃转储文件。</p>
<h4 id="2-8-2-性能优化"><a href="#2-8-2-性能优化" class="headerlink" title="2-8-2 性能优化"></a>2-8-2 性能优化</h4><h4 id="2-8-3-DTrace"><a href="#2-8-3-DTrace" class="headerlink" title="2-8-3 DTrace"></a>2-8-3 DTrace</h4><h3 id="2-9-操作系统的生成"><a href="#2-9-操作系统的生成" class="headerlink" title="2-9 操作系统的生成"></a>2-9 操作系统的生成</h3><h4 id="系统生成定义"><a href="#系统生成定义" class="headerlink" title="系统生成定义"></a>系统生成定义</h4><p>对于某个<strong>特定的计算机场所</strong>，应<strong>配置和生成操作系统</strong>，这一过程有时称为<strong>系统生成</strong>(SYStem GENeration, SYSGEN)。</p>
<p>操作系统的发行通常采用磁盘、CD-ROM、DVD-ROM或“ISO”镜像（采用CD-ROM或DVD_ROM格式的文件）。为了生成系统，可以使用一个特殊程序。这个<strong>SYSGEN程序从给定文件读取或询问系统操作员有关硬件系统的特定配置，或直接检测硬件以决定有什么部件</strong>。根据不同的需求，可以选择性的新的添加不同的系统功能。  </p>
<h3 id="2-10-系统引导"><a href="#2-10-系统引导" class="headerlink" title="2-10 系统引导"></a>2-10 系统引导</h3><h4 id="引导程序"><a href="#引导程序" class="headerlink" title="引导程序"></a>引导程序</h4><p><strong>系统引导告诉硬件内核的位置或如何加载内核</strong>，加载内核以启动计算机的过程，称为<strong>系统引导</strong>（booting）。大多数计算机系统都有一小块代码，称之为<strong>引导程序</strong>（bootstrap program）或<strong>引导加载程序</strong>（bootstrap loader）。这段代码<strong>能够定位内核，并加载到内存以开始执行</strong>。有的计算机系统（如PC）采用两个步骤：一个简单引导程序从磁盘上调人一个更复杂的引导程序，而后者再加载内核。</p>
<p><strong>当CPU收到一个重置事件时，例如上电开机或重新启动，指令寄存器会加载某个预先定义的内存位置，并从该位置开始执行。该位置就是初始引导程序所在</strong>。该程序<strong>为只读存储器（Read-Only Memory，ROM）形式</strong>，因为系统启动时RAM处于未知状态。由于不需要初始化和不受计算机病毒的影响，用ROM是很方便的。</p>
<p>引导程序可以完成一系列任务。通常，有一个任务<strong>需要运行诊断程序来确定机器状态</strong>。如果通过诊断，则程序可以继续启动步骤。引导程序也<strong>能初始化系统的所有方面：从CPU寄存器到设备控制器以及内存内容</strong>。最终，它启动操作系统。</p>
<p>若需要更改引导程序，可以采用<strong>可擦可编程只读存储器</strong>（Erasable Programmable Read-Only Memory，EPROM），这是一种只读存储器，但当明确<strong>给定一个命令时就会变为可写的</strong>。所有形式的ROM都是<strong>固件</strong>（firmware），因为它的特性介于硬件与软件之间。通常，固件存在的问题是：执行代码比在RAM中慢. <strong>有些系统将操作系统保存在固件中，而在要执行时将其复制到RAM中，以便执行更快</strong>。</p>
<p>对<strong>大型操作系统</strong>（包括大多数的通用操作系统，如Windows、Mac OS X和UNIX）或经常改变的系统, <strong>引导程序存放在固件上，而操作系统存放在磁盘上</strong>。在这种情况下，引导程序会先进行诊断，然后<strong>从磁盘固定位置（如第0块）读取整块信息到内存</strong>，最后<strong>执行引导块</strong>（boot block）的代码。所有磁盘的引导程序和操作系统本身，通过向磁盘写入新的版本，就可以很容易地改变. <strong>具有引导分区（详见12.5.1节）的磁盘称为引导盘（boot disk）或系统盘（system disk）</strong>。</p>
<h2 id="3-进程"><a href="#3-进程" class="headerlink" title="3 进程"></a>3 进程</h2><h3 id="3-1-进程概念"><a href="#3-1-进程概念" class="headerlink" title="3-1 进程概念"></a>3-1 进程概念</h3><p>在讨论操作系统时，有个问题是关于如何<strong>称呼所有CPU活动</strong>. <strong>处理系统</strong>执行<strong>作业</strong>（job），而<strong>分时系统</strong>使用<strong>用户程序</strong>（user program）或<strong>任务</strong>（task）。还有许多程序的活动类型都相似，可以统称为<strong>进程</strong>。</p>
<h4 id="3-1-1-进程"><a href="#3-1-1-进程" class="headerlink" title="3-1-1 进程"></a>3-1-1 进程</h4><p>进程是执行的程序. <strong>进程不只是程序代码</strong>，程序代码有时<strong>称为文本段</strong>（text section）（或<strong>代码段</strong>（code section））</p>
<p>进程包括：</p>
<ul>
<li><strong>程序计数器</strong>（program counter，PC）的值和处理器<strong>寄存器的内容</strong></li>
<li>进程<strong>堆栈</strong>（stack）（包括临时数据，如函数参数、返回地址和局部变量）和<strong>数据段</strong>（data section）(包括全局变量)</li>
<li>还可能包括<strong>堆</strong>(heap), 是在进程运行时动态分配的内存</li>
</ul>
<p>程序本身不是进程. <strong>程序只是被动（passive）实体</strong>, <strong>进程是活动（active）实体</strong>，具有一个程序计数器用于表示下个执行命令和一组相关资源。</p>
<p>虽然两个进程可以与同一程序相关联，但是当作两个单独的执行序列。就像浏览器的多个副本, <strong>虽然文本段相同，但是数据、堆及堆栈段却不同</strong>。进程<strong>本身也可作为一个环境</strong>，用于执行其他代码, 就像作为一个进程来执行的JVM，会解释所加载Java，并根据代码采取动作（按本机指令来执行）。</p>
<h4 id="3-1-2-进程状态"><a href="#3-1-2-进程状态" class="headerlink" title="3-1-2 进程状态"></a>3-1-2 进程状态</h4><p>进程可能处于以下状态：</p>
<ul>
<li><strong>新的</strong>（new）：进程正在创建。</li>
<li><strong>运行</strong>（running）：指令正在执行</li>
<li><strong>等待</strong>（waiting）：进程等待发生某个事件（如I&#x2F;O完成或收到信号）</li>
<li><strong>就绪</strong>（ready）：进程等待分配处理器</li>
<li><strong>终止</strong>（terminated）：进程已经完成执行</li>
</ul>
<p>一次只能有一个进程在处理器上运行，但可以有多个处于就绪和等待。</p>
<center> <img src = "./osimg/进程状态.png"> </center>

<h4 id="3-1-3-进程控制块pcb"><a href="#3-1-3-进程控制块pcb" class="headerlink" title="3-1-3 进程控制块pcb"></a>3-1-3 进程控制块pcb</h4><p>系统内的每个进程可以用<strong>进程控制块</strong>（Process Control Block, PCB），也称为<strong>任务控制块</strong>（task control block）。</p>
<center> <img src = "./osimg/PCB.png"> </center>

<p>进程控制块包含的信息有：</p>
<ul>
<li><strong>进程状态</strong>（process state）：状态可以包括新的、就绪、运行、等待、停止等</li>
<li><strong>程序计数器</strong>（program counter）：计数器表示进程将要执行的下个指令的地址。</li>
<li><strong>CPU寄存器</strong>（CPU register）：它们包括累加器、索引寄存器、堆栈指针、通用寄存器和其他条件码信息寄存器。在<strong>发生中断时，这些状态信息与程序计数器一起需要保存</strong>，以便进程以后能正确地继续执行</li>
<li><strong>CPU调度信息</strong>（CPU-scheduling information）：这类信息包括进程优先级、调度队列的指针和其他调度参数。</li>
<li><strong>内存管理信息</strong>（memory-management information）：根据操作系统使用的内存系统，这类信息可以包括基地址和界限寄存器的值、页表或段表</li>
<li><strong>记账信息</strong>（accounting information）：这类信息包括CPU时间、实际使用时间、时间期限、记账数据、作业或进程数量等</li>
<li><strong>I&#x2F;O状态信息</strong>（I&#x2F;Ostatus information）：这类信息包括分配给进程的I&#x2F;O设备列表、打开文件列表等</li>
</ul>
<p>PCB可以说是进程相关的这些信息的仓库，随进程不同而不同</p>
<h4 id="3-1-4-线程"><a href="#3-1-4-线程" class="headerlink" title="3-1-4 线程"></a>3-1-4 线程</h4><p>现在的操作系统允许一个进程拥有多个线程，这些<strong>线程的信息也应该被包括在PCB中</strong>。</p>
<h3 id="3-2-进程调度"><a href="#3-2-进程调度" class="headerlink" title="3-2 进程调度"></a>3-2 进程调度</h3><p>多道程序设计的目标是，无论何时都有进程运行，从而最大化CPU利用率。为了达成这个目标，<strong>进程调度器</strong>（process scheduler）选择一个可用进程（可能从多个可用进程集合中）到CPU上执行。</p>
<h4 id="3-2-1-调度队列"><a href="#3-2-1-调度队列" class="headerlink" title="3-2-1 调度队列"></a>3-2-1 调度队列</h4><p><strong>所有进程</strong>在进入系统时, <strong>无论有没有被加载到内存中</strong>，都会被加到<strong>作业队列</strong>（job queue）。内存中的、就绪的、等待运行的进程保存在<strong>就绪队列</strong>（ready queue）上，通常以链表实现. <strong>等待特定I&#x2F;O设备的进程列表</strong>，称为<strong>设备队列</strong>（device queue）（虽然说是设备队列，但其实是进程的队列，里面装的是请求该设备的进程）。每个设备都有自己的设备队列。</p>
<center> <img src = "./osimg/各种队列.png"> </center>

<center> <img src = "./osimg/队列图.png"> </center>

<p>最初，新进程被加到就绪队列；它在就绪队列中等待，直到被选中执行或被分派。当该进程分配到CPU并执行时，以下事件可能发生：</p>
<ul>
<li>进程可能发出I&#x2F;O请求，并被放到I&#x2F;O队列</li>
<li>进程可能创建一个新的子进程，并等待其终止</li>
<li>进程可能由于中断而被强制释放CPU，并被放回到就绪队列</li>
</ul>
<p>对于前面两种情况，进程最终从等待状态切换到就绪状态，并放回到就绪队列。进程重复这一循环直到终止；然后它会从所有队列中删除，其PCB和资源也被释放。</p>
<h4 id="3-2-2-调度程序"><a href="#3-2-2-调度程序" class="headerlink" title="3-2-2 调度程序"></a>3-2-2 调度程序</h4><p>操作系统为了调度必须按一定方式从多个队列中选择进程。进程选择通过适当调度器或调度程序（scheduler）来执行。</p>
<p>通常，对于<strong>批处理系统</strong>，提交的<strong>进程多于可以立即执行</strong>的。这些进程会<strong>被保存到大容量存储设备（通常为磁盘）的缓冲池</strong>，以便以后执行. <strong>长期调度程序</strong>（long-term scheduler）或<strong>作业调度程序</strong>（job scheduler）从该池中<strong>选择进程，加到内存，以便执行</strong>. <strong>短期调度程序</strong>（short-term scheduler）或<strong>CPU调度程序</strong>（CPU scheduler）从准备执行的进程中<strong>选择进程</strong>，并分配CPU。</p>
<p>这两种调度程序的<strong>主要区别是执行频率. 短期调度程序必须经常为CPU选择新的进程</strong>。进程可能执行几毫秒（ms），就会等待I&#x2F;O请求。通常，短期调度程序每100ms至少执行一次。由于执行之间的时间短, <strong>短期调度程序必须快速</strong>。如果花费10ms来确定执行一个运行100ms的进程，那么10&#x2F;（100+10）&#x3D;9%的CPU时间会用在（或浪费在）调度工作上。</p>
<p><strong>长期调度程序执行并不频繁</strong>。长期调度程序控制<strong>多道程序程度</strong>（degree of multiprogramming）（内存中的进程数量）。如果多道程序程度稳定，那么创建进程的平均速度必须等于进程离开系统的平均速度。因此, <strong>只有在进程离开系统时，才需要长期调度程序的调度</strong>。由于执行次数较少间隔长，可以花费多点时间。</p>
<p>长期调度程序进行认真选择。通常，大多数<strong>进程可分为：I&#x2F;O为主或CPU为主</strong>。I&#x2F;O密集型进程（I&#x2F;O-bound process），执行I&#x2F;O比执行计算需要花费更多时间。相反，CPU密集型进程（CPU-boundprocess）很少产生I&#x2F;O请求，而是将更多时间用于执行计算。重要的是, <strong>长期调度程序应该选择I&#x2F;O密集型和CPU密集型的合理进程组合</strong>。</p>
<p>有的操作系统如分时系统，可能引人一个额外的<strong>中期调度程序</strong>, 其核心思想是可<strong>将进程从内存（或从CPU竞争）中移出</strong>，从而<strong>降低多道程序程度</strong>。之后，进程可被重新调入内存，并从中断处继续执行。这种方案称为<strong>交换</strong>（swap）。通过中期调度程序，进程可换出（swap out），并在后来可换入（swap in）。这种方法可以<strong>改善进程组合</strong>，或者由于<strong>内存需求改变导致过度使用内存从而需要释放内存</strong>。</p>
<center> <img src = "./osimg/中期调度.png"> </center>

<h4 id="3-2-3-上下文切换"><a href="#3-2-3-上下文切换" class="headerlink" title="3-2-3 上下文切换"></a>3-2-3 上下文切换</h4><p>切换CPU到另一个进程需要保存当前进程状态和恢复另一个进程的状态，这个任务称为<strong>上下文切换</strong>（context switch）。</p>
<p><strong>中断</strong>导致CPU<strong>从执行当前任务改变到执行内核程序</strong>。当中断发生时，系统<strong>需要保存当前运行在CPU上的进程的上下文</strong>，以便在处理后能够<strong>恢复上下文</strong>，即先挂起进程，再恢复进程. <strong>进程上下文采用进程PCB表示</strong>。通常，通过<strong>执行状态保存</strong>（state save），保存CPU当前状态（包括内核模式和用户模式）；之后, <strong>状态恢复</strong>（state restore）重新开始运行。</p>
<p>上下文切换的速度因机器不同而有所不同，它依赖于内存速度、必须复制的寄存器数量、是否有特殊指令, 上下文切换的时间与也硬件支持密切相关。</p>
<h3 id="3-3-进程运行"><a href="#3-3-进程运行" class="headerlink" title="3-3 进程运行"></a>3-3 进程运行</h3><h4 id="3-3-1-进程创建"><a href="#3-3-1-进程创建" class="headerlink" title="3-3-1 进程创建"></a>3-3-1 进程创建</h4><p>进程在执行过程中可能创建多个新的进程，创建进程称为<strong>父进程</strong>，而新的进程称为<strong>子进程</strong>。每个<strong>新进程可以再创建其他进程</strong>，从而形成<strong>进程树</strong>（process tree）。</p>
<p>当一个进程创建子进程时，该子进程会需要一定的资源。资源可以<strong>直接从操作系统获取</strong>， 也可以<strong>从父进程得到资源子集</strong>。后者限制子进程只能使用父进程的资源，<strong>可以防止创建进程过多导致系统超载</strong>。此外, <strong>父进程也可能向子进程传递初始化数据（或输入）</strong>。</p>
<p>当进程创建新进程时，有两种执行方式：</p>
<ul>
<li>父进程与子进程<strong>并发执行</strong></li>
<li><strong>父进程等待</strong>，直到某个或全部<strong>子进程执行完</strong></li>
</ul>
<p>新进程的地址空间也有两种可能：</p>
<ul>
<li>子进程是父进程的复制品（它具有与父进程同样的程序和数据）</li>
<li>子进程加载另一个新程序</li>
</ul>
<p>UNIX创建新进程的fork()可以赋值父进程的地址空间给新进程，这样使得父进程与子进程能够轻松通信。</p>
<p><em>具体测试实例 P102</em></p>
<h4 id="3-3-2-进程终止"><a href="#3-3-2-进程终止" class="headerlink" title="3-3-2 进程终止"></a>3-3-2 进程终止</h4><p>当进程完成执行最后语句并且通过系统调用 exit() 请求操作系统删除自身时，进程终止。这时，进程可以返回状态值到父进程（通过系统调用wait()）。终止后<strong>所有进程资源，如物理和虚拟内存、打开文件和I&#x2F;O缓冲区等，会由操作系统释放</strong>。</p>
<p>进程通过适当系统调用（如Windows的Terminate-Process（）），可以终止另一进程. <strong>通常，只有终止进程的父进程才能执行这一系统调用</strong>。如果<strong>终止子进程</strong>，则<strong>父进程需要知道这些子进程的标识符</strong>。因此，当一个进程创建新进程时, <strong>新创建进程的标识符要传递到父进程</strong>。</p>
<p>有些系统<strong>不允许子进程在父进程已终止的情况下存在</strong>。这种现象，称为<strong>级联终止</strong>（cascade termination），通常<strong>由操作系统来启动</strong>。</p>
<p>当一个<strong>进程终止</strong>时，操作系统会<strong>释放其资源</strong>。不过，它<strong>位于进程表中的条目还是在的</strong>，直到它的父进程调用wait() ；这是<strong>因为进程表包含了进程的退出状态</strong>。当进程已经终止，但是其父进程尚未调用wait()，这样的进程称为<strong>僵户进程</strong>（zombie process）。所有进程终止时都会过渡到这种状态，但是一般而言僵尸只是短暂存在。一旦父进程调用了wait()，僵尸进程的进程标识符和它在进程表中的条目就会释放。</p>
<h3 id="3-4-进程间通信"><a href="#3-4-进程间通信" class="headerlink" title="3-4 进程间通信"></a>3-4 进程间通信</h3><p>操作系统内的<strong>并发执行进程</strong>可以是<strong>独立的</strong>或也可以是<strong>协作的</strong>。<br>显然，不与任何其他进程共享数据，不受其他进程影响的进程是独立的。<br>其他进程共享数据的，受其他进程影响的进程为协作进程。</p>
<p>提供进程协作环境有许多理由：</p>
<ul>
<li>信息共享（information sharing）：由于多个用户可能对同样的信息感兴趣（例如共享文件），所以应提供环境以允许并发访问这些信息。</li>
<li>计算加速（computation speedup）：如果希望一个特定任务快速运行，那么应将它分成子任务，而每个子任务可以与其他子任务一起并行执行</li>
<li>模块化（modularity）：可能需要按模块化方式构造系统</li>
<li>方便（convenience）：即使单个用户也可能同时执行许多任务</li>
</ul>
<p>协作进程需要有一种<strong>进程间通信（Inter Process Communication，IPC）机制</strong>。有两种基本模型：：<strong>共享内存</strong>（shared memory）和<strong>消息传递</strong>（message passing）。</p>
<center> <img src="./osimg/通信模型.png"> </center>

<p><strong>消息传递对于交换较少数量的数据很有用，因为无需避免冲突</strong>。对于分布式系统，消息传递也比共享内存<strong>更易实现</strong>。<strong>共享内存可以快于消息传递</strong>, 因为共享内存系统仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有访问都可作为常规内存访问，无需借助内核。</p>
<p>对具有多个处理核系统的最新研究表明：在这类系统上，消息传递的性能要优于共享内存. <strong>共享内存会有高速缓存一致性问题</strong>，这是由共享数据在多个高速缓存之间迁移而引起的。随着系统的处理核的数量的日益增加，可能导致消息传递作为IPC的首选机制。</p>
<h4 id="3-4-1-共享内存系统"><a href="#3-4-1-共享内存系统" class="headerlink" title="3-4-1 共享内存系统"></a>3-4-1 共享内存系统</h4><p>P106</p>
<h4 id="3-4-2-消息传递系统"><a href="#3-4-2-消息传递系统" class="headerlink" title="3-4-2 消息传递系统"></a>3-4-2 消息传递系统</h4><p>消息传递系统至少提供两种操作：</p>
<ul>
<li>send(message)</li>
<li>receive(message)</li>
</ul>
<p>如果进程P和Q<strong>需要通信</strong>，那么它们必须互相发送消息和接收消息：它们之间<strong>要有通信链路</strong>（communication link）。</p>
<h5 id="3-4-2-1-命名"><a href="#3-4-2-1-命名" class="headerlink" title="3-4-2-1 命名"></a>3-4-2-1 命名</h5><h6 id="直接通信"><a href="#直接通信" class="headerlink" title="直接通信"></a>直接通信</h6><p>对于<strong>直接通信</strong>（direct communication），需要通信的<strong>每个进程必须明确指定通信的接收者或发送者</strong>，原语send()和receive()定义如下：</p>
<ul>
<li>send(P, message): 向P发送</li>
<li>receive(Q, message): 从P接受</li>
</ul>
<p>这种方案的通信链路具有以下属性</p>
<ul>
<li>需要通信的每对进程之间，自动建立链路。进程仅需知道对方身份就可进行交流</li>
<li>每个链路<strong>只与两个进程相关</strong></li>
<li>每对进程之间<strong>只有一个链路</strong></li>
</ul>
<p>以上为<strong>对称的</strong>寻址，也可以有<strong>非对称的</strong>，即只要发送者指定接收者，而接收者不需要指定发送者</p>
<ul>
<li>send（P，message）：向进程P发送message。</li>
<li>receive（id，message）：从任何进程，接收message，这里变量id被设置成与其通信进程的名称。</li>
</ul>
<p>以上两者的缺点为，更改进程的标识符可能需要分析所有其他进程定义。所有旧的标识符的引用都应找到，以便修改成为新标识符。</p>
<h6 id="间接通信"><a href="#间接通信" class="headerlink" title="间接通信"></a>间接通信</h6><p>在<strong>间接通信</strong>（indirect communication）中，通过邮箱或端口来发送和接收消息。邮箱可以抽象成一个对象，进程可以向其中存放消息，也可从中删除消息。每个邮箱都有唯一标识符. <strong>一个进程可以通过多个不同邮箱与另一个进程通信，但是两个进程只有拥有一个共享邮箱时才能通信</strong>。原语send()和receive()定义如下：</p>
<ul>
<li>send（A，message）：向邮箱A发送message。</li>
<li>receive（A，message）：从邮箱A接收message。</li>
</ul>
<p>对于这种方案，通信链路具有如下特点：</p>
<ul>
<li>只有在两个进程共享一个邮箱时，才能建立通信链路</li>
<li>一个链路<strong>可以与两个或更多进程相关联</strong></li>
<li>两个通信进程之间<strong>可有多个不同链路</strong>，每个链路对应于一个邮箱。</li>
</ul>
<p>若有多个进程关联到同一个邮箱，其中两个以上的邮箱同时接受邮件，但实际上只会有一个收到邮件，具体看系统实现。</p>
<p>邮箱<strong>可以为进程或操作系统拥有</strong>。</p>
<p>如果<strong>邮箱为进程拥有</strong>（即邮箱是进程地址空间的一部分），那么<strong>需要区分所有者</strong>（只能从邮箱接收消息）和使用者（只能向邮箱发送消息）。由于<strong>每个邮箱都有唯一的标识符，所以关于谁能接收发到邮箱的消息没有任何疑问</strong>。当<strong>拥有邮箱的进程终止，那么邮箱消失</strong>。任何进程后来向该邮箱发送消息，都会得知邮箱不再存在。</p>
<p>与此相, <strong>操作系统拥有的邮箱是独立存在的</strong>；它<strong>不属于某个特定进程</strong>。因此，操作系统必须提供机制，以便允许<strong>进程</strong>进行如下操作：</p>
<ul>
<li>创建新的邮箱</li>
<li>通过邮箱发送和接收消息</li>
<li>删除邮箱</li>
</ul>
<p><strong>创建新邮箱的进程默认为邮箱的所有者</strong>，不过，通过系统调用，拥有权和接收特权可以传给其他进程，可以导致每个邮箱具有多个接收者。</p>
<h5 id="3-4-2-2-同步"><a href="#3-4-2-2-同步" class="headerlink" title="3-4-2-2 同步"></a>3-4-2-2 同步</h5><p>消息传递可以是<strong>阻塞（blocking）或非阻塞（nonblocking）</strong>，也称为<strong>同步(synchronous)或异步(asynchronous)</strong>. 当采用阻塞的send（）和receive（）时，生产者-消费者问题的解决就简单了，只要等待接收就行了。</p>
<h5 id="3-4-2-3-缓存"><a href="#3-4-2-3-缓存" class="headerlink" title="3-4-2-3 缓存"></a>3-4-2-3 缓存</h5><p>不管通信是直接的还是间接的，通信进程交换的<strong>消息总是驻留在临时队列中</strong>。简单地讲，队列实现有三种方法：</p>
<ul>
<li><strong>零容量</strong>（zero capacity）：队列的最大长度为0；因此，链路中不能有任何消息处于等待。对于这种情况, <strong>发送者应阻塞，直到接收者接收到消息</strong>。</li>
<li>有限容量（bounded capacity）：队列长度为有限的n；因此，最多只能有n个消息驻留其中。如果<strong>链路已满，那么发送者应阻塞，直到队列空间有可用的为止</strong>。</li>
<li>无限容量（unbounded capacity）：队列长度可以无限，因此，不管多少消息都可在其中等待. <strong>发送者从不阻塞</strong>。</li>
</ul>
<p><strong>零容量情况称为无缓冲的消息系统，其他情况称为自动缓冲的消息系统</strong>。</p>
<h3 id="3-5-ipc例子"><a href="#3-5-ipc例子" class="headerlink" title="3-5 ipc例子"></a>3-5 ipc例子</h3><p>P110</p>
<h3 id="3-6-客户机-服务器通信"><a href="#3-6-客户机-服务器通信" class="headerlink" title="3-6 客户机-服务器通信"></a>3-6 客户机-服务器通信</h3><p>有三种策略：套接字、远程程序调用（RPC）和管道。</p>
<h4 id="3-6-1-套接字"><a href="#3-6-1-套接字" class="headerlink" title="3-6-1 套接字"></a>3-6-1 套接字</h4><p><strong>套接字</strong>（socket）为通信的端点。通过网络通信的<strong>每对进程需要使用一对套接字</strong>，即每个进程各有一个。每个套接字由一个IP地址和一个端口号组成。</p>
<p>使用套接字的通信，虽然常用和高效，但是属于分布式进程之间的一种<strong>低级形式的通信</strong>。一个原因是, <strong>套接字只允许在通信线程之间交换无结构的字节流。客户机或服务器程序需要自己加上数据结构</strong>。下面两小节将介绍两种更高级的通信方法：远程程序调用（RPC）和管道。</p>
<h4 id="3-6-2-rpc远程过程调用"><a href="#3-6-2-rpc远程过程调用" class="headerlink" title="3-6-2 rpc远程过程调用"></a>3-6-2 rpc远程过程调用</h4><p>RPC是最常见的一种远程服务，与IPC不同, <strong>RPC交换的消息有明确的结构</strong>。消息传到RPC服务，RPC服务监听远程系统的端口号; <strong>消息包含用于指定：执行函数的一个标识符以及传递给函数的一些参数</strong>。然后, <strong>函数按要求来执行</strong>，而所有<strong>结果会通过另一消息，传递回到请求者</strong>。<strong>端口</strong>（port）只是一个数字，处于<strong>消息分组头部</strong>。</p>
<p>RPC语义允许客户调用位于远程主机的过程，就如调用本地过程一样。通过客户端提供的<strong>存根</strong>（stub），RPC系统<strong>隐藏通信细节</strong>。通常，对于<strong>每个单独远程过程，都有一个存根</strong>。当<strong>客户调用远程过程时</strong>，RPC系统<strong>调用适当存根</strong>，并且<strong>传递远程过程参数</strong>。这个<strong>存根定位服务器的端口，并且封装（marshal）参数</strong>。封装参数打包参数，以便通过网络传输。然后，存根通过消息传递，向服务器发送一个消息. <strong>服务器的类似存根收到这个消息，并且调用服务器的过程</strong>。如果必要，返回值可通过同样技术传回到客户机。</p>
<p>这还涉及如何<strong>处理客户机和服务器系统的不同数据表示</strong>。有的系统使用内存的<strong>高地址</strong>，以<strong>存储高位字节</strong>（称为<strong>大端结尾</strong>（big-endian））；而其他系统使用内存的<strong>高地址</strong>，以<strong>存储低位字节</strong>（称为<strong>小端结尾</strong>（little-endian））。为了解决这一差异，许多<strong>RPC系统定义一个独立于机器的数据表示</strong>。一种这样的表示称为<strong>外部数据表示</strong>（eXtermnal Data Representation，XDR）。在客户端，参数封装将机器相关数据打包成XDR，再发送到服务器端，服务器端分封XDR数据再转换成机器相关数据交给服务器。</p>
<p>此外，远程调用还可能因网络原因失败。对此有一种解决方案：确保消息执行<strong>正好一次</strong>而不是<strong>最多一次</strong>。</p>
<p><strong>最多一次</strong>可通过为消息添加<strong>时间戳</strong>来实现。服务器保存足够长的<strong>时间戳历史</strong>若其时间戳出现过则被忽略。</p>
<p><strong>正好一次</strong>需要服务器执行<strong>最多一次</strong>的协议，并且<strong>向用户确认</strong>，即对接收到的消息发送ACK。对客户机，应<strong>周期性重发每个RPC调用</strong>，直到收到对应ACK。</p>
<p>最后还有一个问题，由于两者不在同一台机器不共享内存, <strong>无法知道服务器上的端口</strong>。对此，有两种解决方法：</p>
<ul>
<li>绑定信息按固定端口地址的形式预先固定（即<strong>端口号对应特定功能</strong>）</li>
<li>绑定通过交会机制动态进行。通常, <strong>操作系统在一个固定RPC端口</strong>上, <strong>提供交会服务程序或月老</strong>（matchmaker）。客户程序发送一个包括RPC名称的消息到交会服务程序，以便请求所需执行RPC的端口地址。在得到返回的端口号后，RPC调用可以发送到这一端口号，直到进程终止（或服务器崩溃）。这种方式的初始请求需要额外开销，但是比第一种更灵活。</li>
</ul>
<center> <img src="./osimg/RPCMatchmaker.png" > </center>

<h4 id="3-6-3-管道"><a href="#3-6-3-管道" class="headerlink" title="3-6-3 管道"></a>3-6-3 管道</h4><p><strong>管道</strong>（pipe）允许两个进程进行通信。</p>
<h5 id="3-6-3-1-普通管道"><a href="#3-6-3-1-普通管道" class="headerlink" title="3-6-3-1 普通管道"></a>3-6-3-1 普通管道</h5><p>普通管道允许两个进程按标准的生产者一消费者方式进行通信：生产者向管道的<strong>一端(写入端)<strong>写，消费者从管道的</strong>另一端(读出端)读</strong>。因此，普通管道是<strong>单向的</strong>，只允许单向通信。如果需要<strong>双向通信</strong>，那么就要<strong>采用两个管道</strong>，而每个管道向不同方向发送数据。</p>
<p>UNIX系统使用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pipe(<span class="type">int</span> fd[])</span><br></pre></td></tr></table></figure>
<p>创建管道，fd[0]为读出端，fd[1]为写入端。UNIX系统<strong>将管道视为特殊的文件</strong>。</p>
<p><strong>普通管道只能由创建进程所访问</strong>。通常情况下，父进程创建一个管道，并使用它来与其子进程进行通信（该子进程由fork()来创建）。正如3.3.1节所述, <strong>子进程继承了父进程的打开文件</strong>。由于管道是一种特殊类型的文件，因此子进程<strong>也继承了父进程的管道</strong>。</p>
<center> <img src="./osimg/普通管道.png"> </center>

<p>对于Windows系统，普通管道被称为<strong>匿名管道</strong>（anonymous pipe），它们的行为类似于UNIX的管道：它们是<strong>单向的</strong>，通信<strong>进程之间具有父子关系</strong>。对于Windows系统，程序员<strong>需要指定子进程继承的属性</strong>。<br>由于<strong>子进程从管道上读</strong>，父进程应<strong>将子进程的标准输入重定向为管道的读出句柄</strong>。另外，由于<strong>管道为半双工</strong>，需要<strong>禁止子进程继承管道的写入端</strong>。</p>
<center> <img src="./osimg/匿名管道1.png"> </center>
<center> <img src="./osimg/匿名管道2.png"> </center>
<center> <img src="./osimg/匿名管道子.png"> </center>

<h5 id="3-6-3-2-命名管道"><a href="#3-6-3-2-命名管道" class="headerlink" title="3-6-3-2 命名管道"></a>3-6-3-2 命名管道</h5><p>普通管道提供了一个简单机制，允许一对进程通信。然而, <strong>只有当进程相互通信时，普通管道才存在</strong>。对于UNIX和Windows系统，一旦进程已经完成通信并且终止了，那么普通管道就不存在了. <strong>命名管道</strong>提供了一个更强大的通信工具。通信可以是<strong>双向的</strong>，并且<strong>父子关系不是必需的</strong>。当<strong>建立了一个命名管道后，多个进程都可用它通信</strong>. 此外，当<strong>通信进程完成后，命名管道继续存在</strong>。</p>
<p>对于UNIX，命名管道为FIFO, <strong>只支持字节流</strong>，Windows的命名管道支持<strong>字节流和消息流的数据</strong>，且为全双工，还可以为不同的机器提供服务。命名管道通过CreateNamedPipe()创建，客户通过ConnectNamedPipe()链接。</p>
<h2 id="4-多线程编程"><a href="#4-多线程编程" class="headerlink" title="4 多线程编程"></a>4 多线程编程</h2><h3 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4-1 概述"></a>4-1 概述</h3><p><strong>线程是CPU使用的一个基本单元</strong>；它包括线程ID、程序计数器、寄存器组和堆栈。它<strong>与同一进程的其他线程共享代码段、数据段和其他操作系统资源，如打开文件和信号</strong>。但拥有<strong>私有的寄存器和堆栈</strong>。有多个线程的进程可以同时执行多个任务。</p>
<center> <img src="./osimg/单线程多线程.png"> </center>

<h4 id="4-1-1-动机"><a href="#4-1-1-动机" class="headerlink" title="4-1-1 动机"></a>4-1-1 动机</h4><p>想象一下，当服务器需要服务新的用户时，若每服务一个都需要新建进程的话，系统开销会很大，而且是用的还是和原始进程同样的功能，这十分浪费。因此，可以新建线程来代替进程形式作用。</p>
<center> <img src="./osimg/多线程服务器.png"> </center>

<p>线程在远程过程调用（RPC）系统中，也起着至关重要的作用。当一个服务器收到消息时，它使用一个单独线程来处理消息。这<strong>允许服务器处理多个并发请求</strong>。</p>
<h4 id="4-1-2-优点"><a href="#4-1-2-优点" class="headerlink" title="4-1-2 优点"></a>4-1-2 优点</h4><p>多线程编程有以下4点优点：</p>
<ul>
<li><strong>响应性</strong>：如果一个交互程序采用多线程，那么<strong>即使部分阻塞或者执行长操作，它仍可以继续执行</strong>，从而增加对用户的响应程度</li>
<li><strong>资源共享</strong>：线程<strong>默认共享它们所属进程的内存和资源</strong>。代码和数据共享的优点是：它允许一个应用程序在同一地址空间内有多个不同活动线程</li>
<li><strong>经济</strong>：进程创建所需的内存和资源分配非常昂贵。由于线程能够共享它们所属进程的资源，所以<strong>创建和切换线程更加经济</strong></li>
<li><strong>可伸缩性</strong>：对于多处理器体系结构，多线程的优点更大，因为线程可在多处理核上并行运行</li>
</ul>
<h3 id="4-2-多核编程"><a href="#4-2-多核编程" class="headerlink" title="4-2 多核编程"></a>4-2 多核编程</h3><p>考虑一个应用，它有4个线程。对于<strong>单核系统，并发仅仅意味着线程随着时间推移交错执行</strong>，因为处理核只能同一时间执行单个线程。不过，对于<strong>多核系统，并发表示线程能够并行运行</strong>，因为系统<strong>可以为每个核分配一个单独线程</strong>。</p>
<center> <img src="./osimg/单核和多核的线程.png" > </center>

<p><em>并行系统可以<strong>同时执行</strong>多个任务。相比之下，并发系统支持多个任务，允许<strong>所有任务都能取得进展</strong></em></p>
<h4 id="amdahl定律"><a href="#amdahl定律" class="headerlink" title="amdahl定律"></a>amdahl定律</h4><center> <img src="./osimg/amdahl.png"> </center>

<p>此处S表示程序串行部分（按顺序执行）的占比</p>
<h4 id="4-2-1-编程上等挑战"><a href="#4-2-1-编程上等挑战" class="headerlink" title="4-2-1 编程上等挑战"></a>4-2-1 编程上等挑战</h4><h4 id="4-2-2-并行类型"><a href="#4-2-2-并行类型" class="headerlink" title="4-2-2 并行类型"></a>4-2-2 并行类型</h4><p>通常有两种并行类型：</p>
<ul>
<li><strong>数据并行</strong>（data parallelism）注重将数据分布于多个计算核上，并<strong>在每个核上执行相同操作</strong>。如分块解决区间计数</li>
<li><strong>任务并行</strong>（task parallelism）涉及将任务（线程）而不是数据分配到多个计算核。每个<strong>线程都执行一个独特的操作</strong></li>
</ul>
<p>实际上几乎都是混合使用</p>
<h3 id="4-3-多线程模型"><a href="#4-3-多线程模型" class="headerlink" title="4-3 多线程模型"></a>4-3 多线程模型</h3><p>两种不同方法来提供线程支持, <strong>用户层的用户线程</strong>（user thread）或<strong>内核层的内核线程</strong>（kernel thread）:</p>
<ul>
<li><strong>用户线程</strong>: 位于内核之上，它的管理<strong>无需内核支持</strong></li>
<li><strong>内核线程</strong>: 由<strong>操作系统来直接支持与管理</strong></li>
</ul>
<h4 id="4-3-1-多对一模型"><a href="#4-3-1-多对一模型" class="headerlink" title="4-3-1 多对一模型"></a>4-3-1 多对一模型</h4><p>多对一模型映射多个用户级线程到一个内核线程. <strong>线程管理是由用户空间的线程库来完成的，因此效率更高</strong>. 不过，如果<strong>一个线程执行阻塞系统调用，那么整个进程将会阻塞(并发性差)<strong>。再者，因为</strong>任一时间只有一个线程可以访问内核</strong>，所以多个线程<strong>不能并行运行</strong>在多处理核系统上.</p>
<center> <img src="./osimg/多对一.png"> </center>

<h4 id="4-3-2-一对一模型"><a href="#4-3-2-一对一模型" class="headerlink" title="4-3-2 一对一模型"></a>4-3-2 一对一模型</h4><p>一对一模型映射每个用户线程到一个内核线程. 该模型在<strong>一个线程执行阻塞系统调用时，能够允许另一个线程继续执行</strong>，所以它提供了比多对一模型<strong>更好的并发功能</strong>. 唯一<strong>缺点</strong>是，创建一个用户线程就<strong>要创建一个相应的内核线程</strong>。由于创建内核线程的<strong>开销会影响应用程序的性能</strong>，所以这种模型的<strong>大多数实现限制了系统支持的线程数量</strong>.</p>
<center> <img src="./osimg/一对一.png"> </center>

<h4 id="4-3-3-多对多模型"><a href="#4-3-3-多对多模型" class="headerlink" title="4-3-3 多对多模型"></a>4-3-3 多对多模型</h4><p>多对多模型<strong>多路复用(如时分复用，频分复用一类)的</strong>。多个用户级线程到<strong>同样数量或更少数量</strong>的内核线程。</p>
<h5 id="不同模型对并发性的影响"><a href="#不同模型对并发性的影响" class="headerlink" title="不同模型对并发性的影响"></a>不同模型对并发性的影响</h5><ul>
<li><strong>多对一</strong>：内核同一时间只能被同一线程访问且会因为部分线程的阻塞导致其他线程的阻塞，因此并未增加并发性</li>
<li><strong>一对一</strong>：并发性好，但是需要注意不应该创建太多的应用程序线程，因为这将导致更多的内核线程，通常操作系统也会限制线程数</li>
<li><strong>多对多</strong>：并发性好且不受线程数量限制，当一个线程被阻塞时，内核还可以调度其他的线程</li>
</ul>
<center> <img src="./osimg/多对多.png"> </center>

<h3 id="4-4-线程库"><a href="#4-4-线程库" class="headerlink" title="4-4 线程库"></a>4-4 线程库</h3><p><strong>线程库</strong>（thread library）为程序员<strong>提供创建和管理线程的API</strong>。其实现通常有两种：</p>
<ol>
<li>在<strong>用户空间</strong>中提供一个<strong>没有内核支持的库</strong>，这种库的所有代码和数据结构都位于用户空间。这意味着, <strong>调用库内的一个函数只是导致了用户空间内的一个本地函数的调用，而不是系统调用</strong>。</li>
<li>实现由<strong>操作系统直接支持</strong>的内核级的一个库。库内的代码和数据结构位于内核空间。调用<strong>库中的一个API函数通常会导致对内核的系统调用</strong>。</li>
</ol>
<p>对于POSIX和Windows线程，<strong>全局声明</strong>（即在函数之外声明的）的任何数据，可为同一进程的<strong>所有线程共享</strong>. Java因为没有全军变量的概念需要显示安排数据归属。属于某个<strong>函数的本地数据通常位于堆栈</strong>。由于每个<strong>线程都有自己的堆栈，每个线程都有自己的本地数据</strong>。</p>
<h4 id="多线程创建的策略"><a href="#多线程创建的策略" class="headerlink" title="多线程创建的策略"></a>多线程创建的策略</h4><ul>
<li><strong>同步线程</strong>：父线程<strong>创建的线程并发执行工作</strong>，但是父线程在这个工作完成之前无法继续。一旦<strong>每个线程完成了它的工作</strong>，它就会<strong>终止，并与父线程连接</strong>。只有在所有子线程都连接之后，父线程才恢复执行。通常，同步线程涉及线程之间的<strong>大量数据的共享</strong></li>
<li><strong>异步线程</strong>：父线程<strong>创建了一个子线程后</strong>，父线程就<strong>恢复自身的执行</strong>，这样父线程与子线程会<strong>并发执行</strong>。每个线程的运行独立于其他线程，父线程<strong>无需知道子线程何时终止</strong>。由于线程是独立的，所以线程之间通常<strong>很少有数据共享</strong></li>
</ul>
<h4 id="4-4-1-pthread"><a href="#4-4-1-pthread" class="headerlink" title="4-4-1 pthread"></a>4-4-1 pthread</h4><p>P139</p>
<h4 id="4-4-2-windows线程"><a href="#4-4-2-windows线程" class="headerlink" title="4-4-2 windows线程"></a>4-4-2 windows线程</h4><p>P141</p>
<h4 id="4-4-3-java线程"><a href="#4-4-3-java线程" class="headerlink" title="4-4-3 java线程"></a>4-4-3 java线程</h4><p>P142</p>
<h3 id="4-5-隐式多线程"><a href="#4-5-隐式多线程" class="headerlink" title="4-5 隐式多线程"></a>4-5 隐式多线程</h3><p>随着多核处理的日益增多，出现了拥有数百甚至数千线程的应用程序。设计这样的应用程序不是一个简单的任务。针对解决这些困难并且更好支持设计多线程程序，有一种方法是<strong>将多线程的创建与管理交给编译器和运行时库来完成</strong>。这种策略称为<strong>隐式线程</strong>（implicit threading）。</p>
<h4 id="4-5-1-线程池"><a href="#4-5-1-线程池" class="headerlink" title="4-5-1 线程池"></a>4-5-1 线程池</h4><p>以前文的服务器为例，当服务器接到请求，他会创建线程来服务用户，虽然这肯定比创建进程好，但仍然存在一些问题。</p>
<ol>
<li>第一个问题是<strong>创建线程所需的时间多少</strong>，以及线程在<strong>完成工作之后会被丢弃</strong>的事实。要是能继续利用创建好的线程会更好</li>
<li>第二个问题，如果<strong>允许所有并发请求都通过新线程来处理</strong>，那么我们<strong>没有限制系统内的并发执行线程的数量</strong>。无限制的线程<strong>可能耗尽系统资源</strong></li>
</ol>
<p>为了解决问题，一种方法是使用<strong>线程池</strong></p>
<h5 id="线程池的思想"><a href="#线程池的思想" class="headerlink" title="线程池的思想"></a>线程池的思想</h5><ol>
<li>在进程<strong>开始时创建一定数量的线程</strong>，并加到池中以等待工作</li>
<li><strong>收到请求时，它会唤醒池内的一个线程</strong>（如果有可用线程），并将需要服务的请求传递给它</li>
<li>一旦线程<strong>完成了服务</strong>，它会<strong>回到池中再等待工作</strong>。如果池内<strong>没有可用线程</strong>，那么服务器会<strong>等待直到有空线程为止</strong>。期间不创建更多线程，其实也是限制了最大线程数。</li>
</ol>
<p>线程池具有以下优点：</p>
<ul>
<li>用现有线程服务请求比等待创建一个线程<strong>更快</strong></li>
<li><strong>限制了任何时候可用线程的数量</strong>。这对那些不能支持大量并发线程的系统非常重要。</li>
<li>把<strong>执行任务从创建任务的机制中分离出来</strong>，允许我们采用不同策略运行任务。例如，任务可以被安排在某一个时间延迟后执行，或定期执行。</li>
</ul>
<h4 id="4-5-2-openmp"><a href="#4-5-2-openmp" class="headerlink" title="4-5-2 openmp"></a>4-5-2 openmp</h4><p><strong>OpenMP为一组编译指令和API</strong>，用于编写C、C++、Fortran等语言的程序，它<strong>支持共享内存环境下的并行编程</strong>. OpenMP识别<strong>并行区域</strong>（parallel region），即可并行运行的代码块。下面的C程序给出了一个实例</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span>&#123;</span><br><span class="line">  <span class="comment">/*sequentialcode*/</span></span><br><span class="line">  <span class="meta">#<span class="keyword">pragma</span> omp parallel&#123;</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I am a parallel region.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/*sequential code*/</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当OpenMP遇到</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp parallel</span></span><br></pre></td></tr></table></figure>
<p>它会<strong>创建与系统处理核一样多的线程</strong>。因此，对于一个双核系统，会创建两个线程；所有线程，然后<strong>同时执行并行区域</strong>。当每个<strong>线程退出并行区域时，也就终止了</strong>。</p>
<h4 id="4-5-3-大中央调度"><a href="#4-5-3-大中央调度" class="headerlink" title="4-5-3 大中央调度"></a>4-5-3 大中央调度</h4><p><strong>大中央调度</strong>（Grand Central Dispatch，GCD）Apple Mac OS X和iOS操作系统的一种技术，为C语言、API和运行时库的一组扩展，它允许应用程序开发人员将某些代码区段并行运行。像OpenMP一样，GCD<strong>管理大多数的多线程细节</strong>。</p>
<p>GCD为C和C++语言增加了<strong>块</strong>（block）的扩展。每块只是工作的一个独立单元。它用花括号将代码括起来，然后前面加上字符。一个简单例子如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">^&#123;<span class="built_in">printf</span>(<span class="string">&quot;I m a block&quot;</span>);&#125;</span><br></pre></td></tr></table></figure>
<p>通过将这些块放置在<strong>调度队列</strong>（dispatch queue）上，GCD调度块以便执行。当GCD从队列上<strong>移除一块</strong>后，就将<strong>该块分配给线程池内的可用线程</strong>。GCD识别两种类型的调度队列：<strong>串行</strong>（serial）和<strong>并发</strong>（concurrent）。</p>
<p>放置在一个<strong>串行队列</strong>上的块按照先进先出的顺序删除。一旦一个块从队列中被删除，只有它<strong>执行完时，才会从该队列中删除另一个块</strong>。每个<strong>进程都有自已的串行队列</strong>（称为它的主队列（main queue））。开发人员<strong>可以创建属于本进程的其他串行队列</strong>。串行队列用于<strong>确保顺序执行多个任务</strong>。</p>
<p>放置在一个<strong>并行队列</strong>上的块也按照先进先出的顺序删除，但是，可以<strong>同时删除多个块</strong>，因此<strong>允许多个块并行运行</strong>。有三个系统级的并发调度队列，它们的区别是优先级：低、默认和高。优先级近似表示块的相对重要性。</p>
<h3 id="4-6-多线程设计问题"><a href="#4-6-多线程设计问题" class="headerlink" title="4-6 多线程设计问题"></a>4-6 多线程设计问题</h3><h4 id="4-6-1-系统调用fork和exec"><a href="#4-6-1-系统调用fork和exec" class="headerlink" title="4-6-1 系统调用fork和exec"></a>4-6-1 系统调用fork和exec</h4><p>对于多线程程序，系统调用fork()和exec()的语义有所改变。</p>
<p>如果程序内的某个线程调用fork（），那么新进程复制所有线程，或者新进程只有单个线程？有的UNIX系统有<strong>两种形式的fork()<strong>，一种</strong>复制所有线程</strong>，另一种<strong>仅仅复制调用了系统调用fork()的线程</strong>。</p>
<p>系统调用exec()的工作方式与第3章所述方式通常相同。也就是说，如果一个线程调用exec()系统调用, <strong>exec()参数指定的程序将会取代整个进程，包括所有线程</strong>。</p>
<p>这两种形式的fork()使用取决于应用程序。如果分叉之后立即调用exec()，那么没有必要复制所有线程，因为exec()参数指定的程序将会替换整个进程。在这种情况下，仅仅复制调用线程比较合适。不过，如果新的进程在分叉后并不调用exec()，新进程应该复制所有线程。</p>
<h4 id="4-6-2-信号处理"><a href="#4-6-2-信号处理" class="headerlink" title="4-6-2 信号处理"></a>4-6-2 信号处理</h4><p>UNIX<strong>信号</strong>用于通知进程事件已经发生。无论同步还是异步的信号，都遵循以下模式：</p>
<ul>
<li>信号是由<strong>特定事件的发生而产生的</strong></li>
<li>信号<strong>被传递给某个进程</strong></li>
<li>信号<strong>一收到就应处理</strong></li>
</ul>
<p><strong>同步信号发送到由于执行操作导致这个信号的同一进程</strong>, 典型例子为非法访问内存以及被0除。</p>
<p><strong>异步信号发送到另一个进程</strong>，若进程接受来自其他程序产生的信号，该进程异步接收这个信号，如使用ctrl+c终止进程。</p>
<p>单线程程序的信号处理比较简单，信号总是传给进程的。不过，对于多线程程序，信号传递比较复杂，因为一个进程可能具有多个线程。有以下几种可能：</p>
<ul>
<li>传递信号到信号所适用的线程</li>
<li>传递信号到进程内的每个线程</li>
<li>传递信号到进程内的某些线程</li>
<li>规定一个特定线程以接收进程的所有信号</li>
</ul>
<p>信号传递的方法取决于产生信号的类型。例如，同步信号需要传递到产生这一信号的线程，而不是进程的其他线程。不过，对于异步信号，情况就不是那么明显了。</p>
<p>传递信号的标准UNIX函数为</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">kill(<span class="type">int</span> pid <span class="type">int</span> signal)</span><br></pre></td></tr></table></figure>
<p>这个函数指定将一个特定信号（signal）传递到一个进程（pid）. 大多数多线程版的UNIX<strong>允许线程指定它接收什么信号和拒绝什么信号</strong> 。因此，在有些情况下，一个异步信号只能传递给那些不拒绝它的线程. 不过，因为<strong>信号只能处理一次，所以信号通常传到第一个不拒绝它的线程</strong>。</p>
<p>虽然Windows并不显式提供信号支持，但是它们允许通过<strong>异步过程调用</strong>（Asynchronous Procedure Call，APC）来模拟. <strong>APC功能允许用户线程，指定一个函数以便在用户线程收到特定事件通知时能被调用</strong>。正如名称所示，APC与UNIX的异步信号大致相当。不过，UNIX需要面对如何处理多线程环境下的信号，而APC较为简单，因为<strong>APC传给特定线程而非进程</strong>。(相当于每个线程不停检测有没有对应的信号并执行对应函数，以此实现按需执行)</p>
<h4 id="4-6-3-线程撤销"><a href="#4-6-3-线程撤销" class="headerlink" title="4-6-3 线程撤销"></a>4-6-3 线程撤销</h4><p>需要撤销的线程，通常称为<strong>目标线程</strong>（target thread）。目标线程的撤销可以有两种情况:</p>
<ul>
<li><strong>异步撤销</strong>: 一个<strong>线程立即终止目标线程</strong>。</li>
<li><strong>延迟撤销</strong>: <strong>目标线程不断检查它是否应终止</strong>，这允许目标线程有机会有序终止自己。</li>
</ul>
<p>在有些情况下，如<strong>资源已分配给已撤销的线程，或者需要撤销的线程正在更新与其他线程一起共享的数据等，撤销会有困难</strong>。对于异步撤销，这尤其麻烦。通常, <strong>操作系统收回撤销线程的系统资源，但是并不收回所有资源</strong>。因此, <strong>异步撤销线程可能不会释放必要的系统资源</strong>。相反，对于延迟撤销，一个线程指示目标线程会被撤销；不过，仅当目标线程检查到一个标志以确定它是否应该撤销时，撤销才会发生。线程可以执行这个检查：它是否位于安全的撤销点.</p>
<p>对于Pthreads，通过函数pthread_cancel()可以发起线程撤销。目标线程的标识符作为参数传给这个函数。</p>
<p>然而，调用pthread_cancel()只表示有一个请求，以便撤销目标线程; <strong>实际撤销取决于如何设置目标线程以便处理请求</strong>。Pthreads支持三种撤销模式。每个模式定义为一个状态和一个类型，如下表所示。线程可以通过API设置撤销状态和类型。</p>
<center> <img src="./osimg/线程撤销模式.png"> </center>

<p><strong>缺省撤销类型为延迟撤销</strong>。这样，只有当线程到达<strong>撤销点</strong>（cancellation point）时，才会发生撤销。建立撤销点的一种技术是，调用函数pthread_testcancel()。如果有一个<strong>撤销请求处于等待</strong>，那么就会调用称为<strong>清理处理程序（cleanup handler）的函数</strong>。在线程终止前，这个函数允许释放它可能获得的任何资源。</p>
<h4 id="4-6-4-线程本地存储"><a href="#4-6-4-线程本地存储" class="headerlink" title="4-6-4 线程本地存储"></a>4-6-4 线程本地存储</h4><p>同一进程的线程共享进程的数据。然而，在某些情况下，每个<strong>线程可能需要它自己的某些数据</strong>。我们称这种数据为<strong>线程本地存储</strong>（Thread-Local Storage，TLS）。</p>
<p>TLS与局部变量容易混淆。然而，局部变量只在单个函数调用时才可见；而TLS数据在多个函数调用时都可见。在某些方面，TLS类似于静态（static）数据。不同的是，TLS数据是每个线程独特的。</p>
<h4 id="4-6-5-调度程序激活"><a href="#4-6-5-调度程序激活" class="headerlink" title="4-6-5 调度程序激活"></a>4-6-5 调度程序激活</h4><p>多线程编程需要考虑的最后一个问题涉及<strong>内核与线程库间的通信</strong>，4.3.3节讨论的<strong>多对多和双层模型可能需要这种通信</strong>。这种协调<strong>允许动态调整内核线程的数量，以便确保最优性能</strong>。</p>
<p>许多系统在实现多对多或双层模型时，在用户和内核线程之间增加一个轻量级进程（LightWeight Process, LWP）. <strong>对于用户级线程库，LWP表现为虚拟处理器以便应用程序调度并运行用户线程</strong>.每个LWP与一个内核线程相连，而<strong>只有内核线程才能通过操作系统调度以便运行于物理处理器</strong>。如果<strong>内核线程阻塞</strong>（如在等待一个I&#x2F;O操作结束时）LWP也会阻塞。这个链的上面，连到<strong>LWP的用户级线程也会阻塞</strong>。</p>
<center> <img src="./osimg/LWP.png"> </center>

<p>为了运行高效，每个应用程序可能需要一定数量的LWP。通常，每个<strong>并发的、阻塞的系统调用需要一个LWP</strong>。例如，假设有5个不同的文件读请求可能同时发生，就需要5个LWP，因为每个都需要等待内核I&#x2F;O的完成。如果进程只有4个LWP，那么第5个请求必须等待一个LWP从内核中返回。</p>
<p>用户线程库与内核之间的一种通信方案称为<strong>调度器激活</strong>（scheduler activation）。它工作如下：</p>
<p><strong>内核提供一组虚拟处理器（LWP）给应用程序</strong>，而<strong>应用程序可以调度用户线程到任何一个可用虚拟处理器</strong>。此外，内核应将有关特定事件通知应用程序。这个步骤称为<strong>回调</strong>（upcall），它由<strong>线程库通过回调处理程序</strong>（upcall handler）来处理。当一个应用程序的<strong>线程要阻塞时，一个触发回调的事件会发生</strong>。在这种情况下，<strong>内核向应用程序发出一个回调，通知它有一个线程将会阻塞并且标识特定线程</strong>。然后, <strong>内核分配一个新的虚拟处理器给应用程序</strong>。应用程序在这个<strong>新的虚拟处理器上运行回调处理程序</strong>，它<strong>保存阻塞线程的状态，并释放阻塞线程运行的虚拟处理器</strong>。接着，回调处理程序<strong>调度另一个适合在新的虚拟处理器上运行的线程</strong>，当<strong>阻塞线程等待的事件发生</strong>时, <strong>内核向线程库发出另一个回调</strong>，通知它<strong>先前阻塞的线程现在有资格运行</strong>了。该<strong>事件的回调处理程序也需要一个虚拟处理器</strong>，内核<strong>可能分配一个新的虚拟处理器，或抢占一个用户线程并在其虚拟处理器上运行回调处理程序</strong>。在非阻塞线程有资格运行后，应用程序在可用虚拟处理器上运行符合条件的线程。</p>
<h3 id="4-7-操作系统例子"><a href="#4-7-操作系统例子" class="headerlink" title="4-7 操作系统例子"></a>4-7 操作系统例子</h3><p>P150</p>
<h2 id="5-进程调度"><a href="#5-进程调度" class="headerlink" title="5 进程调度"></a>5 进程调度</h2><h3 id="5-1-基本概念"><a href="#5-1-基本概念" class="headerlink" title="5-1 基本概念"></a>5-1 基本概念</h3><h4 id="5-1-1-cpu-io执行周期"><a href="#5-1-1-cpu-io执行周期" class="headerlink" title="5-1-1 cpu-io执行周期"></a>5-1-1 cpu-io执行周期</h4><p>进程执行包括<strong>周期</strong>（cycle）进行CPU执行和I&#x2F;O等待。进程在这两个状态之间不断交替。进程<strong>执行从CPU执行</strong>（CPU burst）开始，之后<strong>I&#x2F;O执行</strong>（I&#x2F;O burst）</p>
<center> <img src="./osimg/交替执行.png"> </center>

<p><strong>I&#x2F;O密集型程序通常具有大量短CPU执行</strong>. <strong>CPU密集型程序可能只有少量长CPU执行</strong>。对于选择合适的CPU调度算法，这种分布是很重要的。</p>
<h4 id="5-1-2-cpu调度程序"><a href="#5-1-2-cpu调度程序" class="headerlink" title="5-1-2 cpu调度程序"></a>5-1-2 cpu调度程序</h4><p>每当CPU空闲时，操作系统就应从就绪队列(在内存中)中选择一个进程来执行. <strong>进程选择采用短期调度程序（short-term scheduler）或CPU调度程序</strong>。</p>
<p>就绪队列不必是FIFO，他可以有多种实现。在概念上，就绪队列内的所有进程都要排队以便等待在CPU上运行. **队列内的记录通常为进程控制块(ProcessControl Block，PCB)**。</p>
<h4 id="5-1-3-抢占调度"><a href="#5-1-3-抢占调度" class="headerlink" title="5-1-3 抢占调度"></a>5-1-3 抢占调度</h4><p>需要进行CPU调度的情况可分为以下四种:</p>
<ul>
<li>进程从运行状态切换到等待状态， 如I&#x2F;O请求，或wait()调用以便等待一个子进程的终止</li>
<li>进程从运行状态切换到就绪状态, 如，出现中断</li>
<li>进程从等待状态切换到就绪状态，如，I&#x2F;O完成</li>
<li>进程终止</li>
</ul>
<p>**对于第1种和第4种情况(进程退出执行)**，除了调度没有选择。一个新进程（如果就绪队列有一个进程存在）必须被选择执行。不过，对于第2种和第3种情况，还是有选择的</p>
<p>如果调度<strong>只能发生在第1种和第4种情况下(进程执行完毕或必须退出)<strong>，则调度方案称为</strong>非抢占的</strong>（nonpreemptive）或<strong>协作的</strong>（cooperative）；否则，调度方案称为<strong>抢占的</strong>（preemptive）。在<strong>非抢占调度</strong>下，一旦某个<strong>进程分配到CPU，该进程就会一直使用CPU，直到它终止或切换到等待状态</strong>。(就绪状态不行)</p>
<p>不过，当多个进程共享数据时，抢占调度可能导致竞争情况。若一个进程正在更新数据而另一个进程抢占了它并且读数据，那么此时数据处于不一致的状态。</p>
<p>此外，若是处理系统调用时，内核可能为进程而忙于某个活动。这些活动可能涉及改变重要的内核数据（如I&#x2F;O队列）。这时被抢占会导致严重问题. <strong>因此, 在进行上下文切换时应等待系统调用完成</strong>。遗憾的是，这种方案虽然简单，当对实时计算支持较差。</p>
<p>中断几乎出现在任何时候，所以<strong>受中断影响的代码段应被保护</strong>，进入时禁用中断而在退出时启用中断。重要的是，要注意禁用中断的代码段并不经常发生，而且常常只有少量指令。</p>
<h4 id="5-1-4-调度程序"><a href="#5-1-4-调度程序" class="headerlink" title="5-1-4 调度程序"></a>5-1-4 调度程序</h4><p><strong>调度程序是一个模块</strong>，用来将CPU控制交给由<strong>短期调度程序选择的进程</strong>。这个功能包括：</p>
<ul>
<li>切换上下文</li>
<li>切换到用户模式</li>
<li>转到用户程序的合适位置，以便重新启动程序</li>
</ul>
<p>调度程序应尽可能快，因为在每次进程切换时都要使用. <strong>调度程序停止一个进程而启动另一个所需的时间称为调度延迟</strong>（dispatch latency）。</p>
<h3 id="5-2-调度准则"><a href="#5-2-调度准则" class="headerlink" title="5-2 调度准则"></a>5-2 调度准则</h3><p>不同的情境下有不同的需求，因此调度准则也不同，这些准则包括：</p>
<ul>
<li><strong>CPU使用率</strong>：应使CPU尽可能地忙碌</li>
<li><strong>吞吐量</strong>：它是在<strong>一个时间单元内进程完成的数量</strong>。对于长进程，吞吐量可能为每小时一个进程；对于短进程，吞吐量可能为每秒十个进程</li>
<li><strong>周转时间</strong>：从一个特定进程的角度来看，一个重要准则是运行这个进程需要多长时间。从<strong>进程提交到进程完成的时间段称为周转时间</strong>，包括等待进入内存、在就绪队列中等待、在CPU上执行和I&#x2F;O执行</li>
<li><strong>等待时间</strong>：CPU调度算法并<strong>不影响进程运行和执行I&#x2F;O的时间</strong>，它只影响进程在就绪队列中因等待所需的时间. <strong>等待时间为在就绪队列中等待所花时间之和</strong>。</li>
<li><strong>响应时间</strong>：对于交互系统，周转时间不是最佳准则. <strong>从提交请求到产生第一响应的时间。这种时间称为响应时间</strong>，是开始响应所需的时间，而<strong>非输出响应所需的时间</strong>。周转时间通常受输出设备速度的限制。</li>
</ul>
<p>最大化CPU使用率和吞吐量，并且最小化周转时间、等待时间和响应时间，这是可取的.<strong>在大多数情况下，优化的是平均值</strong>。然而，在<strong>有些情况下，优化的是最小值或最大值</strong>，而不是平均值。例如，为了保证所有用户都能得到好的服务，可能要使最大响应时间最小。</p>
<h3 id="5-3-调度算法"><a href="#5-3-调度算法" class="headerlink" title="5-3 调度算法"></a>5-3 调度算法</h3><h4 id="5-3-1-先到先服务FCFS"><a href="#5-3-1-先到先服务FCFS" class="headerlink" title="5-3-1 先到先服务FCFS"></a>5-3-1 先到先服务FCFS</h4><p>是最简单的CPU调度，缺点是<strong>平均等待时间往往很长</strong>. 此外，FCFS是<strong>非抢占的</strong>，这会导致部分进程占用很长的CPU时间。例如一个CPU密集程序和一堆I&#x2F;O密集型程序一起，CPU密集型程序会占用很长的CPU时间，其他的进程都必须等待CPU释放，这种情况也被称为<strong>护航效果</strong>。</p>
<h4 id="5-3-2-最短作业优先调度"><a href="#5-3-2-最短作业优先调度" class="headerlink" title="5-3-2 最短作业优先调度"></a>5-3-2 最短作业优先调度</h4><p><strong>最短作业优先</strong>（Shortest-Job-First，SJF）调度算法, 更确切地说是<strong>最短下次CPU执行</strong>（shortest-next-CPU-burst）算法。。当<strong>CPU变为空闲时，它会被赋给具有最短CPU执行的进程</strong>。如果两个进程具有同样长度的CPU执行，那么可以由FCFS来处理。</p>
<p>可以证明<strong>SJF是最优的</strong>，唯一的难点在于如何预知下一个CPU执行的长度。</p>
<p><strong>下次CPU执行通常预测为以前CPU执行的测量长度的指数平均</strong>（exponential average）。我们可以按下面的公式来计算指数平均。设t为第n个CPU执行长度，设tn+1为下次CPU执行预测值。因此，对于α，0≤α≤1，定义</p>
<center> <img src="./osimg/SJF.png"> </center>

<p>值t,包括最近信息，而t存储了过去历史。参数α控制最近和过去历史在预测中的权重。</p>
<p>替换展开可得</p>
<center> <img src="./osimg/SJF1.png"> </center>

<p>因为0≤α≤1，可知对以前历史的依赖越来越低。在计算中遇到的<strong>数据都来自于同一进程</strong>。</p>
<p><strong>SJF算法可以是抢占的或非抢占的</strong>。新进程的下次CPU执行，与当前运行进程的尚未完成的CPU执行相比，可能还要小. <strong>抢占SJF算法会抢占当前运行进程</strong>，而<strong>非抢占SJF算法会允许当前运行进程以先完成CPU执行</strong>。抢占SJF调度有时称为<strong>最短剩余时间优先</strong>。</p>
<h4 id="5-3-3-优先级调度"><a href="#5-3-3-优先级调度" class="headerlink" title="5-3-3 优先级调度"></a>5-3-3 优先级调度</h4><p>SJF算法是通用优先级调度（priority-scheduling）算法的一个特例。每个进程都有一个优先级与其关联，而具有<strong>最高优先级的进程会分配到CPU。具有相同优先级的进程按FCFS顺序调度</strong>。SJF算法是一个简单的优先级算法，其优先级（p）为下次（预测的）CPU执行的倒数。CPU执行越长，则优先级越小；反之亦然。</p>
<p><strong>优先级的定义可以分为内部的或外部的</strong>。</p>
<p>内部定义的优先级采用一些测量数据来计算进程优先级。例如，时限、内存要求、打开文件数量和平均I&#x2F;O执行时间与平均CPU执行之比等，都可用于计算优先级。</p>
<p>外部定义的优先级采用操作系统之外的准则，如进程重要性、用于支付使用计算机的费用类型和数量、赞助部门、其他因素（通常为政治）等。</p>
<p><strong>优先调度可以是抢占的或非抢占的</strong>。当一个进程到达就绪队列时，比较它的优先级与当前运行进程的优先级。如果<strong>新到达进程的优先级高于当前运行进程的优先级</strong>，那么<strong>抢占优先级调度算法就会抢占CPU</strong>. <strong>非抢占优先级调度算法只是将新的进程加到就绪队列的头部</strong>。</p>
<p>优先级调度算法的一个主要问题是<strong>无穷阻塞</strong>（indefinite blocking）或<strong>饥饿</strong>（starvation）. <strong>就绪运行但是等待CPU的进程可以认为是阻塞的</strong>。优先级调度算法可让某个<strong>低优先级进程无穷等待</strong>CPU。对于一个超载的计算机系统，稳定的更高优先级的进程流可以阻止低优先级的进程获得CPU。</p>
<p>低优先级进程的无穷等待问题的解决方案之一是<strong>老化</strong>（aging）。老化<strong>逐渐增加在系统中等待很长时间的进程的优先级</strong>。</p>
<h4 id="5-3-4-轮转调度"><a href="#5-3-4-轮转调度" class="headerlink" title="5-3-4 轮转调度"></a>5-3-4 轮转调度</h4><p><strong>轮转</strong>（Round-Robin，RR）调度算法是<strong>专门为分时系统设计</strong>的。它类似于FCFS调度，但是<strong>增加了抢占</strong>以切换进程。将一个<strong>较小时间单元定义为时间量（timequantum）或时间片</strong>（timeslice）。时间片的大小通常为10～100ms。就绪队列作为循环队列。CPU<strong>调度程序循环整个就绪队列</strong>，为每个进程<strong>分配不超过一个时间片的CPU</strong>。</p>
<p>若执行时间小于一个时间片，那么执行完毕后立即执行下一个。</p>
<p>若执行时间大于单个时间片，触发定时器中断并加到就绪队列尾。</p>
<p>采用RR策略的<strong>平均等待时间通常较长</strong></p>
<p>如果就绪队列有n个进程，并且时间片为q，那么<strong>每个进程会得到1&#x2F;n的CPU时间</strong>，而且每次分得的时间不超过g个时间单元。每个<strong>进程等待获得下一个CPU时间片的时间不会超过（n-1）q个时间单元</strong>.</p>
<p><strong>RR算法的性能很大程度取决于时间片的大小</strong>。在一种极端情况下，如果时间片很大，那么RR算法与FCFS算法一样。相反，如果时间片很小（如1ms），那么RR算法可以导致大量的上下文切换, 从而降低性能. <strong>因此，我们希望时间片长度远大于上下文切换时间</strong>。</p>
<p><strong>周转时间也依赖于时间片大小</strong>。随着时间片大小的增加，进程的平均周转时间不一定会改善。一般情况下，如果<strong>大多数进程能在一个时间片内完成，那么平均周转时间会改善</strong>. 例如，假设有三个进程，都需要10个时间单元。如果时间片为1个时间单元，那么平均周转时间为29；如果时间片为10，那么平均周转时间会降为20. （三个进程由于时刻0提交）</p>
<p>根据经验，<strong>80%的CPU执行都应该小于时间片</strong>。</p>
<h4 id="5-3-5-多级队列调度"><a href="#5-3-5-多级队列调度" class="headerlink" title="5-3-5 多级队列调度"></a>5-3-5 多级队列调度</h4><p><strong>多级队列</strong>（multi level queue）调度算法<strong>将就绪队列分成多个单独队列</strong>。根据进程属性，如内存大小、进程优先级、进程类型等，一个进程永久分到一个队列。每个<strong>队列有自己的调度算法</strong>。例如，可有两个队列分别用于前台进程和后台进程。前台队列可以采用RR算法调度，而后台队列可以采用FCFS算法调度。</p>
<p><strong>多级队列调度是抢占的</strong>，高优先级的队列会抢占正在进行的低优先级进程。</p>
<center> <img src="./osimg/多级队列.png"> </center>

<p>还有可能在<strong>队列之间划分不同比例的CPU时间</strong>, 例如将一个时间片的80%分给前台进程. <strong>不同优先级进程之间采用RR算发调度, 相同的使用FCFS调度</strong>。</p>
<h4 id="5-3-6-多级反馈队列调度"><a href="#5-3-6-多级反馈队列调度" class="headerlink" title="5-3-6 多级反馈队列调度"></a>5-3-6 多级反馈队列调度</h4><p>在使用<strong>多级队列调度算法时，进程进入系统时被永久地分配到某个队列</strong>. 这种设置的<strong>优点是调度开销低，缺点是不够灵活</strong>。</p>
<p>相反, <strong>多级反馈队列</strong>（multi level feedback queue）调度算法<strong>允许进程在队列之间迁移</strong>。这种想法是，根据不同CPU执行的特点来区分进程。如果进程<strong>使用过多的CPU时间，那么它会被移到更低的优先级队列</strong>。这种方案将IO密集型和交互进程放在更高优先级队列上。此外，在<strong>较低优先级队列中等待过长的进程会被移到更高优先级队列</strong>。这种形式的老化<strong>阻止饥饿的发生</strong>。</p>
<center> <img src="./osimg/多级反馈队列.png"> </center>

<p>这种调度算法将<strong>给那些CPU执行不超过8ms的进程最高优先级</strong>。这类进程可以很快得到CPU，完成CPU执行，并且处理下个I&#x2F;O执行。所需<strong>超过8ms但不超过24ms的进程</strong>也会很快得以服务，但是它们的<strong>优先级要低一点</strong>。长进程会自动沉人队列2，在队列0和1不用CPU周期时按FCFS服务。</p>
<p>通常，多级反馈队列调度程序可由下列参数来定义：</p>
<ul>
<li>队列数量</li>
<li>每个队列的调度算法</li>
<li>何时升级到更高优先级队列的方法</li>
<li>何时降级到更低优先级队列的方法</li>
<li>确定进程在需要服务时将会进人哪个队列的方法</li>
</ul>
<p>多级反馈队列调度程序的定义使其成为<strong>最通用的CPU调度算法</strong>。通过配置，它能适应所设计的特定系统。遗憾的是，由于<strong>需要一些方法来选择参数以定义最佳的调度程序，所以它也是最复杂的算法</strong>。</p>
<h3 id="5-4-线程调度"><a href="#5-4-线程调度" class="headerlink" title="5-4 线程调度"></a>5-4 线程调度</h3><p>在支持线程的操作系统上, <strong>内核级线程（而不是进程）才是操作系统所调度</strong>的. <strong>用户级线程是由线程库来管理的</strong>，而内核并不知道它们. <strong>用户级线程为了运行在CPU上，最终应映射到相关的内核级线程</strong>，但是这种映射可能不是直接的，可能采用轻量级进程（LWP）。</p>
<h4 id="5-4-1-竞争范围"><a href="#5-4-1-竞争范围" class="headerlink" title="5-4-1  竞争范围"></a>5-4-1  竞争范围</h4><p><strong>用户级和内核级线程之间的一个区别在于它们是如何调度的</strong>。对于<strong>实现多对一（4.3.1节）和多对多（4.3.3节）模型的系统线程库会调度用户级线程</strong>，以便在可用LWP上运行。这种方案称为<strong>进程竞争范围</strong>（Process-Contention Scope，PCS），因为竞争CPU是发生在同一进程的线程之间。（当我们说线程库将用户线程调度到可用LWP时，并不意味着线程真实运行在一个CPU上。这会需要操作系统调度内核线程到物理CPU。）</p>
<p><strong>图中多个线程可连接到相同LWP，每个LWP下链接内核进程，实际相当于一对一模型</strong>。</p>
<center> <img src="./osimg/LWPS.gif"> </center>

<p>为了决定哪个<strong>内核级线程调度到一个处理器上</strong>，内核采用<strong>系统竞争范围</strong>（System-ContentionScope，SCS）。采用SCS调度来竞争CPU，发生在系统内的所有线程之间。采用一对一模型（4.3.2节）的系统，如Windows、Linux和Solaris，只采用SCS调度。</p>
<p>通常情况下, <strong>PCS采用优先级调度并且通常时抢占的</strong>, 用户级线程的优先级是由程序员设置的，并不是由线程库调整的，尽管有些线程库可能允许程序员改变线程的优先级。不过，在具有相同优先级的线程之间，没有时间分片的保证。</p>
<h4 id="5-4-2-pthreads调度"><a href="#5-4-2-pthreads调度" class="headerlink" title="5-4-2 pthreads调度"></a>5-4-2 pthreads调度</h4><p>P170</p>
<h3 id="5-5-多处理器调度"><a href="#5-5-多处理器调度" class="headerlink" title="5-5 多处理器调度"></a>5-5 多处理器调度</h3><p>对多个CPU的系统，则可以考虑<strong>负载均衡</strong>（load sharing）</p>
<p>注意，即使同构多处理器，有时也有一些<strong>调度限制</strong>。假设有一个系统，它有<strong>一个I&#x2F;O设备与其某个处理器通过私有总线相连</strong>。希望使用该设备的进程<strong>应调度到该处理器上运行</strong>。</p>
<h4 id="5-5-1-多处理器调度方法"><a href="#5-5-1-多处理器调度方法" class="headerlink" title="5-5-1 多处理器调度方法"></a>5-5-1 多处理器调度方法</h4><p>第一种为<strong>非对称多处理</strong>，让<strong>一个处理器（主服务器）处理所有调度决定、I&#x2F;O处理以及其他系统活动</strong>，其他的处理器只执行用户代码。只有一个处理器访问系统数据结构，减少了数据共享的需要。</p>
<p>第二种方法是使用<strong>对称多处理</strong>（Symmetric MultiProcessing，SMP），即<strong>每个处理器自我调度</strong>。所有<strong>进程</strong>可能处于一个<strong>共同的就绪队列中</strong>，或<strong>每个处理器都有它自已的私有就绪进程队列</strong>。不管如何，调度这样进行: <strong>每个处理器的调度程序都检查共同就绪队列，以便选择执行一个进程</strong>。如果多个处理器试图访问和更新一个共同的数据结构，那么每个处理器必须仔细编程。必须确保两个处理器不会选择同一进程，而且进程不会从队列中丢失。</p>
<h4 id="5-5-2-处理器亲和性"><a href="#5-5-2-处理器亲和性" class="headerlink" title="5-5-2 处理器亲和性"></a>5-5-2 处理器亲和性</h4><p>考虑一下，当一个进程运行在一个特定处理器上时缓存会发生些什么。</p>
<p>进程最近访问的数据<strong>更新了处理器的缓存</strong>。结果，进程的<strong>后续内存访问通常通过缓存来满足</strong>。现在考虑一下，如果进程<strong>移到其他处理器</strong>上则会发生什么。第一个处理器缓存的内容应设为无效，第二个处理器缓存应重新填充。由于<strong>缓存的无效或重新填充的代价高</strong>，大多数SMP系统试<strong>图避免将进程从一个处理器移到另一个处理器</strong>，而是试图让一个进程运行在同一个处理器上。这称为<strong>处理器亲和性</strong>（processor affinity），即一个进程对它运行的处理器具有亲和性。</p>
<p>当一个操作系统<strong>试图保持但不保证进程运行在同一处理器上</strong>时，这种情况称为<strong>软亲和性</strong>（soft affinity）。相反，有的系统<strong>提供系统调用以便支持硬亲和性</strong>（hard affinity），从而<strong>允许某个进程运行在某个处理器子集</strong>上。</p>
<p><strong>系统的内存架构可以影响处理器的亲和性</strong>。非统一内存访问（Non-UniformMemoryAccess，NUMA）的一种架构，其中一个CPU访问内存的某些部分会比其他部分更快。如果<strong>操作系统的CPU调度和内存分配算法一起工作</strong>，那么当一个<strong>进程分配到一个特定的亲和处理器时，它应分配到同板上的内存</strong>。</p>
<center> <img src="./osimg/NUMACPU.png" > </center>

<h4 id="5-5-3-负载均衡"><a href="#5-5-3-负载均衡" class="headerlink" title="5-5-3 负载均衡"></a>5-5-3 负载均衡</h4><p>对于有些系统（它们的<strong>处理器具有私有的可执行进程的队列</strong>）, <strong>负载平衡是必需的</strong>；而对于<strong>具有公共队列的系统</strong>, <strong>负载平衡通常没有必要</strong>，因为一旦处理器空闲，它立刻从公共队列中取走一个可执行进程.</p>
<p>负载平衡通常有两种方法：<strong>推迁移</strong>（push migration）和<strong>拉迁移</strong>（pull migration）。推迁移和拉迁移<strong>不必相互排斥</strong>，事实上，在负载平衡系统中它们<strong>常被并行实现</strong>, 也就是说，一个处理器可以同时推和拉，这样可以改变单一处理器有重负荷任务而系统中又存在多个任务时。</p>
<p>同时，负载平衡往往会<strong>抵消处理器亲和性的好处</strong>，因为涉及任务在处理器间的迁移。两种方案没有谁是更好的之分，因此，在某些系统中，空闲的处理器总是会从非空闲的处理器中拉进程；而在其他系统中，只有当不平衡达到一定程度后才会移动进程。</p>
<h4 id="5-5-4-多核处理器"><a href="#5-5-4-多核处理器" class="headerlink" title="5-5-4 多核处理器"></a>5-5-4 多核处理器</h4><p>多核处理器的调度问题可能更为复杂。研究人员发现，当一个处理器访问内存时，它<strong>花费大量时间等待所需数据</strong>。这种情况称为<strong>内存停顿</strong>（memory stall），它的发生原因多种多样，如<strong>高速缓存未命中</strong>（访问数据不在高速缓冲里）</p>
<p>许多最近的硬件设计都采用了<strong>多线程的处理器核</strong>，即<strong>每个核会分配到两个（或多个）硬件线程</strong>。这样，如果一个线程停顿而等待内存，该核可以切换到另一个线程。</p>
<center> <img src="./osimg/多线程多核.png" > </center>

<p><strong>处理器核的多线程</strong>有两种方法: <strong>粗粒度</strong>（coarse-grained）和<strong>细粒度</strong>（fine-grainded）的多线程。</p>
<ul>
<li><strong>粗粒度</strong>: 线程<strong>一直在处理器上执行</strong>，直到一个长延迟事件（如内存停顿）发生。由于长<strong>延迟事件造成的延迟</strong>，处理器应<strong>切换到另一个线程来开始执行</strong>。然而，线程之间的<strong>切换成本是高</strong>的，因为在另一个线程可以在处理器核上开始执行之前，应<strong>刷新指令流水线</strong>。一旦这个新的线程开始执行，它会开始用指令来填充流水线</li>
<li><strong>细粒度</strong>: 多线程在更细的粒度级别上(通常在<strong>指令周期的边界</strong>上)<strong>切换线程</strong>。而且，细粒度系统的<strong>架构设计有线程切换的逻辑</strong>。因此，线程之间的<strong>切换成本很小</strong>。</li>
</ul>
<p><strong>注意，一个多线程多核处理器实际需要两个不同级别的调度</strong>.</p>
<p>一个级别的调度决策由<strong>操作系统做出</strong>，用于<strong>选择哪个软件线程运行在哪个硬件线程</strong>（逻辑处理器）。系统可对此选择任何调度算法。</p>
<p>另一个级别的调度<strong>指定每个核如何决定运行哪个硬件线程</strong>，也可此采用RR等算法。</p>
<h3 id="5-6-实时cpu调度"><a href="#5-6-实时cpu调度" class="headerlink" title="5-6 实时cpu调度"></a>5-6 实时cpu调度</h3><p>实时操作系统的CPU调度问题有些特殊. 一般来说，我们可以区分软实时系统和硬实时系统。<strong>软实时系统</strong>（soft real-time system）不保证会调度关键实时进程；而只保证这类进程会优先于非关键进程。硬<strong>实时系统</strong>（hard real-time system）有更严格的要求。一个任务应在它的截止期限之前完成；在截止期限之后完成，与没有完成，是完全一样的</p>
<h4 id="5-6-1-最小化延迟"><a href="#5-6-1-最小化延迟" class="headerlink" title="5-6-1 最小化延迟"></a>5-6-1 最小化延迟</h4><p>系统等待一个<strong>实时事件的发生</strong>, 当一个事件发生时，系统<strong>应尽快地响应和服务它</strong>。从<strong>事件发生到事件得到服务(响应并解决)的这段时间称为事件延迟</strong>(event latency)</p>
<p>两种类型的延迟影响实时系统的性能：<strong>中断延迟和调度延迟</strong>。</p>
<p><strong>中断延迟</strong>（interrupt latency）是从<strong>CPU收到中断到中断处理程序开始的时间</strong>. 当一个中断发生时，操作系统应先完成正在执行的指令，再确定发生中断的类型。然后，它应保存当前进程的状态，再采用特定的中断服务程序（Interrupt Service Routine，ISR）来处理中断。执行这些任务需要的总时间为中断延迟。</p>
<center> <img src="./osimg/事件和中断延迟.png" > </center>

<p><strong>影响中断延迟的一个重要因素是：在更新内核数据结构时中断可能会被禁用的时间量</strong>. 因此对于实时操作系统要求中断禁用的时间应非常短。</p>
<p><strong>调度延迟</strong>是<strong>调度程序从停止一个进程到启动另一个进程所需的时间量</strong>。实时操作系统通过提供<strong>抢占式内核来最小化调度延迟</strong></p>
<center> <img src="./osimg/调度延迟.png" > </center>

<p>其中，<strong>冲突阶段</strong>（conflict phase）有<strong>两个部分</strong>：</p>
<ul>
<li>抢占在内核中运行的任何进程</li>
<li>释放高优先级进程所需的、低优先级进程占有的资源。</li>
</ul>
<h4 id="5-6-2-优先权调度"><a href="#5-6-2-优先权调度" class="headerlink" title="5-6-2 优先权调度"></a>5-6-2 优先权调度</h4><p>即基于优先级的抢占式调度，多级队列，多级反馈，抢占式SJF等</p>
<p><strong>提供抢占的、基于优先级的调度程序仅保证软实时功能</strong>。硬实时系统应进一步保证实时任务应在截止期限内得到服务，做出这样的保证需要附加的调度特征。</p>
<p>进程任务的特征有分析可得，首先，这些<strong>进程</strong>是<strong>周期性的</strong>（periodic）。也就是说，它们定期需要CPU。一旦周期性进程获得CPU，它<strong>具有固定的处理时间t、CPU应处理的截止期限d和周期p</strong>。处理时间、截止期限和周期三者之间的关系为：0≤t≤d≤p。周期任务的速率（rate）为1&#x2F;p。</p>
<center> <img src="./osimg/周期任务.png" > </center>

<p>硬实时系统调度算法需要<strong>进程可能应向调度器公布其截止期限要求</strong>。调度程序做两件事之一：它承认进程，保证进程完成；如果它不能保证任务能在截止期限前得以服务，拒绝请求，即准入控制。</p>
<h4 id="5-6-3-单调速率调度"><a href="#5-6-3-单调速率调度" class="headerlink" title="5-6-3 单调速率调度"></a>5-6-3 单调速率调度</h4><p>应用于实时系统的<strong>抢占的，静态优先级调度算法，需要尽量固定的周期和执行时长</strong>。之所以是静态优先级是由于所有进程的周期已知，可按1&#x2F;p得到全局优先级。之后任何任务的执行都按照那个任务类的优先级安排，即使出现抢占中断导致剩下一个很短的CPU执行，依旧要按对应任务的优先级运行。</p>
<p>我们考虑一个例子。我们有两个进程P和P2。P和P2的周期分别为50和100，即p&#x3D;50和p2&#x3D;100。P和P2的处理时间分别为t&#x3D;20和t&#x3D;35。每个进程的截止期限要求，它在下一个周期开始之前完成CPU执行。</p>
<p>首先，我们<strong>应问自已是否可能调度这些任务以便每个进程都能满足截止期限</strong>。如果我们<strong>按执行与周期的比率t&#x2F;p测量一个进程的CPU利用率</strong>，那么P的CPU利用率20&#x2F;50&#x3D;0.40，P2的是35&#x2F;100&#x3D;0.35，**总的CPU利用率为75%**。因此，我们似乎可以调度这些任务以便满足它们的截止期限，并且仍让CPU有多余可用的时间。</p>
<p>现在假设使用单调速率调度，这里P1分配的优先级要高于P2的，因为P1的周期比P2的更短。首先，P1开始，并在时间20完成CPU执行，从而满足第一个截止期限。P2在这点开始运行，并运行直到时间50。此时，它被P1抢占，尽管它的CPU执行仍有5ms的时间。P1在时间70完成CPU执行，在这点调度器恢复P2。P在时间75完成CPU执行，也满足第一个截止期限。然后，系统一直空闲直到时间100，这时，P再次被调度。</p>
<center> <img src="./osimg/单调速率调度.png" > </center>

<p><strong>单调速率调度可认为是最优的</strong>，因为如果一组进程不能由此算法调度，它不能由任何其他<strong>分配静态优先级的算法</strong>来调度。我们接下来分析一组进程，它们不能使用单调速率算法来调度。</p>
<p>假设进程P1具有周期p&#x3D;50和CPU执行t&#x3D;25。进程P2的对应值是p2&#x3D;80和t2&#x3D;35。单调速率调度将为进程P1分配较高的优先级，因为它具有较短的周期。两个进程的总CPU利用率为（25&#x2F;50）+（35&#x2F;80）&#x3D;0.94，因此似乎合乎逻辑的结论是：这两个进程可以被调度，并且仍让CPU有6%的可用时间, 然而P2在85结束，超过了80的截止时间。</p>
<center> <img src="./osimg/单调速率调度失败.png" > </center>

<p>尽管是最优的，然而单调速率调度有一个限制：CPU的利用率是有限的，并不总是可能完全最大化CPU资源。调度N个进程的最坏情况下的CPU利用率为</p>
<center> <p> N(2^(1/N)-1) </p> </center>

<p>当N趋近于正无穷时，CPU利用率最低为69%。若计算得出的利用率高于这个值，那么调度有可能失败。</p>
<h4 id="5-6-4-最早截止期限优先调度"><a href="#5-6-4-最早截止期限优先调度" class="headerlink" title="5-6-4 最早截止期限优先调度"></a>5-6-4 最早截止期限优先调度</h4><p>应用于实时系统的<strong>抢占的，动态优先级调度算法</strong>。之所以是动态的是由于它动态的计算当前任务的截止期限，若一个任务已经执行完毕，那么他的截止期限将被调整为下一次的截止期限，这会导致优先级变化。</p>
<p><strong>最早截止期限优先</strong>（Earliest-Deadline-First，EDF）调度<strong>根据截止期限动态分配优先级</strong>，截止期限越早，优先级越高；截止期限越晚，优先级越低。根据EDF策略，当<strong>一个进程可运行时，它应向系统公布截止期限要求</strong>。</p>
<p>采用上文中不能使用单调速率调度的例子, 进程P1有p&#x3D;50，t&#x3D;25, 进程P2有p&#x3D;80, t&#x3D;35. 进程P1的截止期限为最早，所以它的初始优先级比进程P2的要高。当P1的CPU执行结束时，进程P2开始运行。不过，虽然单调速率调度允许P1在时间50（即下一周期开始之际）抢占P2，但是<strong>EDF调度允许进程P2继续运行</strong>,因为它的下一个截止期限（时间80）比P1的（时间100）要早.</p>
<center> <img src="./osimg/最早截止期限优先调度.png" > </center>

<p><strong>与单调速率调度不一样，EDF调度不要求进程应是周期的，也不要求进程的CPU执行的长度是固定的</strong>。唯一的要求是：进程在变成可运行时，应<strong>宣布它的截止期限</strong>。EDF调度具有吸引力的地方是：它是<strong>理论上最佳的</strong>。但实际上由于上下文切换和中断处理的代价，无法达到100%CPU利用率。</p>
<h4 id="5-6-5-比例分享调度"><a href="#5-6-5-比例分享调度" class="headerlink" title="5-6-5 比例分享调度"></a>5-6-5 比例分享调度</h4><p><strong>比例分享</strong>（proportional share）调度程序在所有应用之间分配T股。如果一个<strong>应用程序接收N股的时间</strong>，那么<strong>确保了它将有N&#x2F;T的总的处理器时间</strong>.</p>
<p>比例分享调度程序应<strong>采用准入控制策略</strong>，以便确保每个进程能够得到分配时间。准人控制策略是：只有客<strong>户请求的股数小于可用的股数，才能允许客户进入</strong></p>
<h4 id="5-6-6-posix实时调度"><a href="#5-6-6-posix实时调度" class="headerlink" title="5-6-6 posix实时调度"></a>5-6-6 posix实时调度</h4><p>P180</p>
<h3 id="5-7-操作系统例子"><a href="#5-7-操作系统例子" class="headerlink" title="5-7 操作系统例子"></a>5-7 操作系统例子</h3><p>P181</p>
<h2 id="6-同步"><a href="#6-同步" class="headerlink" title="6 同步"></a>6 同步</h2><p>协作进程能直接共享逻辑地址空间（代码和数据）。但<strong>共享数据的并发访问</strong>可能导致数据的不一致，如写操作并发。</p>
<h3 id="6-1-背景"><a href="#6-1-背景" class="headerlink" title="6-1 背景"></a>6-1 背景</h3><p>回看有界缓冲区的问题。原来的解决方案允许缓冲区同时最多只有BUFFERSIZE-1项。假如我们想要修改这一算法以便弥补这个缺陷。一种可能方案是，增加一个整型变量counter，并且初始化为0。每当向缓冲区增加一项时，递增counter；每当从缓冲区移走一项时，递减counter。生产者进程代码可以修改如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">  <span class="comment">/*produce an item in next-produced*/</span></span><br><span class="line">  <span class="keyword">while</span> (counter == BUFFER_SIZE);<span class="comment">/*do nothing*/</span></span><br><span class="line">  buffer[in]=next_produced;</span><br><span class="line">  in=(in<span class="number">+1</span>) %BUFFER SIZE;</span><br><span class="line">  counter++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消费者代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">  <span class="keyword">while</span>(counter == <span class="number">0</span>); <span class="comment">/*do nothing*/</span></span><br><span class="line">  next_consumed = buffer[out];</span><br><span class="line">  out = (out<span class="number">+1</span>) % BUFFER_SIZE;</span><br><span class="line">  counter--;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上方的代码各自正确，但<strong>并发执行时可能出错</strong></p>
<p>语句“counter++”可能通过以下的机器语言实现：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">register_0 = counter</span><br><span class="line">register_0 = register_0 + 1</span><br><span class="line">counter = register_0</span><br></pre></td></tr></table></figure>
<p><strong>counter++ 和 counter–可能用的同一个寄存器，但由于中断处理程序会保存先前的寄存器状态，所以无所谓</strong></p>
<p>此时，指令的执行顺序可能为：</p>
<center> <img src="./osimg/并发++.png"> </center>

<p>可见，结果并不一定为5，还可能为6或4。</p>
<p>多个进程<strong>并发访问和操作同一数据</strong>并且执行<strong>结果与特定访问顺序有关</strong>，称为<strong>竞争条件</strong>（race condition）。为了防止竞争条件，需要<strong>确保一次只有一个进程可以操作变量counter</strong>。为了做出这种保证，要求这些<strong>进程按一定方式来同步</strong>。</p>
<h3 id="6-2-临界区问题"><a href="#6-2-临界区问题" class="headerlink" title="6-2 临界区问题"></a>6-2 临界区问题</h3><p>假设某个系统有n个进程{P0，P1，···，Pn-i}。每个进程有一段代码，称为<strong>临界区</strong>（critical section），进程在执行该区时可能修改公共变量、更新一个表、写一个文件等。</p>
<p>该系统的<strong>重要特征</strong>是，当一个进程在临界区内执行时，其他进程不允许在它们的临界区内执行。也就是说, <strong>没有两个进程可以在它们进入区的临界区内同时执行</strong>。</p>
<p><strong>临界区问题</strong>（critical-section problem）是，设计一个协议以便协作进程。在进入临界区前，每个进程应请求许可。实现这一请求的代码区段称为<strong>进入区</strong>（entry section）。临界区之后可以有<strong>退出区</strong>（exit section），其他代码为<strong>剩余区</strong>（remainder section）。</p>
<center> <img src="./osimg/含临界区进程示例.png"> </center>

<h4 id="临界区问题的解决方案要求"><a href="#临界区问题的解决方案要求" class="headerlink" title="临界区问题的解决方案要求"></a>临界区问题的解决方案要求</h4><p>临界区问题的解决方案应满足如下三条要求：</p>
<ul>
<li><strong>互斥</strong>：进程P在其临界区内执行，那么其他进程都不能在其临界区内执行。(<strong>同时只能有一个进程在临界区运行</strong>)</li>
<li><strong>进步</strong>: 若没有进程在其临界区内执行，并且有进程需要进入临界区，那么<strong>只有那些不在剩余区内执行的进程可以参加选择(剩余区进程都要退出了，不必参与选择)<strong>，以便确定谁能下次进入临界区，而且这种</strong>选择不能无限推迟</strong>。</li>
<li><strong>有限等待</strong>: 一个进程做出进入临界区的请求直到这个请求允许为止，其他进程允许进入其临界区的次数具有上限。</li>
</ul>
<p>在任一给定时间点，一个操作系统可能具有多个处于内核态的活动进程。因此，操作系统的实现代码（内核代码）可能出现竞争条件.</p>
<p>处理<strong>操作系统（内核代码）的临界区问题</strong>有两种常用方法：</p>
<ul>
<li><strong>提供非抢占式内核</strong>：不允许处于内核模式的进程被抢占。处于内核模式运行的进程会一直运行，直到退出内核模式、阻塞或自愿放弃CPU控制。因此也<strong>不会有竞争访问带来的竞争条件</strong></li>
<li><strong>提供抢占式内核</strong>：更难设计，但响应更快，适合实时编程</li>
</ul>
<h3 id="6-3-peterson解决方案"><a href="#6-3-peterson解决方案" class="headerlink" title="6-3 peterson解决方案"></a>6-3 peterson解决方案</h3><p>Peterson方案是一个经典的临界区解决方案，但由于<strong>计算机执行机器基本语言方法不一致，不能确保Peterson解决方案能正确运行</strong>。</p>
<p>Peterson解决方案<strong>适用于两个进程交错执行临界区与剩余区</strong>。两个进程为P0和P1。为了方便，当使用Pi时，用Pj来表示另一个进程，即j&#x3D;&#x3D;1-i。</p>
<p>Peterson解答要求两个进程共享两个数据项：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> turn; <span class="comment">// 轮到谁进入临界区 turn==i 表示i将进入</span></span><br><span class="line"><span class="type">bool</span> flag[<span class="number">2</span>]; <span class="comment">// 表示谁准备进入了</span></span><br></pre></td></tr></table></figure>
<center> <img src="./osimg/peterson.png"> </center>

<p>要证明方案正确性，我们需要证明<a href="#%E4%B8%B4%E7%95%8C%E5%8C%BA%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%A6%81%E6%B1%82">临界区问题的解决方案要求</a>满足</p>
<p>证明互斥成立：</p>
<p>应注意到，只有当flag[j] &#x3D;&#x3D; false或者turn &#x3D;&#x3D; i时，进程Pi才能进入临界区。而且，注意，如果两个进程同时在临界区内执行，那么flag[0] &#x3D;&#x3D; flag[1] &#x3D;&#x3D; true。这两点意味着，P0和P1不可能同时成功地执行它们的while语句，因为turn的值只可能为0或1，而不可能同时为两个值。因此，只有一个进程如Pj，能成功地执行完while语句，而进程Pi;应至少再一次执行语句（”turn&#x3D;&#x3D;j”）。而且，只要Pj在临界区内，flag[j] &#x3D;&#x3D; true和turn &#x3D;&#x3D; j就同时成立。结果，互斥成立。</p>
<p>证明进步和有限等待：</p>
<p>若 flag[j] &amp;&amp; turn &#x3D;&#x3D; j, 此时Pi被阻塞。但Pj退出时会设置flag[j] &#x3D;&#x3D; false; 此时Pi能立刻被唤醒并进入临界区（进步）。若Pj希望再次执行，此时turn &#x3D;&#x3D; i, Pj被阻塞，但等到Pi退出时有flag[i] &#x3D;&#x3D; false; 此时Pj就可以继续，因此对于i和j都只需要至多等待一次（等待另外一个退出, 此时只有两个进程）。</p>
<h3 id="6-4-硬件同步"><a href="#6-4-硬件同步" class="headerlink" title="6-4 硬件同步"></a>6-4 硬件同步</h3><p>对于<strong>单处理器环境</strong>，临界区问题可简单地加以解决：在<strong>修改共享变量时只要禁止中断出现</strong>。这样，就能确保当前指令流可以有序执行，且不会被抢占。由于不可能执行其他指令，所以共享变量不会被意外地修改。这种方法<strong>往往为非抢占式内核所采用</strong>。</p>
<p>然而，在<strong>多处理器环境</strong>下，这种解决方案是不可行的。多处理器的<strong>中断禁止会很耗时，因为消息要传递到所有处理器</strong>。消息传递会延迟进人临界区，并降低系统效率。另外, <strong>如果系统时钟是通过中断来更新的，那么它也会受到影响</strong>。</p>
<p><strong>基于软件的临界区问题解决方案并不一定保证有效</strong>，因此，许多现代系统<strong>提供特殊硬件指令</strong>，用于检测和修改字的内容，或者用于<strong>原子地</strong>（atomically）交换两个字（作为<strong>不可中断的指令</strong>）。我们可以采用这些特殊指令，相对简单地解决临界区问题。此处不介绍具体的机器指令，而是用两个函数test_and_set()以及compare_and_swap()抽象的介绍</p>
<p>对于test_and_set()：</p>
<center> <img src="./osimg/testandset.png" > </center>

<p>函数test_and_set(target)会<strong>返回target的旧值</strong>，并将target的内容修改为true。</p>
<p>若test_and_set()执行在两个不同的cpu上，他们<strong>会以任意顺序执行</strong>，因此只有最先执行的进程能得到lock为false因此继续执行，另一个则等待到进程退出(lock &#x3D; false)</p>
<p>对于compare_and_swap():</p>
<p>其函数原型为：</p>
<center> <img src="./osimg/compareandswap.png" > </center>

<p>他返回value的旧值，并在value &#x3D;&#x3D; expected的条件下赋值为new_value.</p>
<p>其互斥实现为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(compare_and_swap(&amp;lock,<span class="number">0</span>,<span class="number">1</span>)); <span class="comment">// wait</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* do something */</span></span><br><span class="line"></span><br><span class="line">  lock = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* remainder section */</span></span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<p>以上两个函数都<strong>必须是原子的</strong></p>
<p>虽然这些算法<strong>满足互斥要求</strong>，但是<strong>并未满足有限等待要求</strong>。我们提出另一种基于test_and_set()的算法，它满足所有临界区的要求。共用的数据结构如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> waiting[n];</span><br><span class="line"><span class="type">bool</span> lock;</span><br></pre></td></tr></table></figure>

<center> <img src="./osimg/fulltestandset.png" > </center>

<p>为了<strong>证明满足进步要求</strong>，注意，以上有关互斥的论证也适用，因为<strong>进程在退出临界区时或将lock设为false，或将waiting[j]设为false。这两种情况都允许等待进程进入临界区</strong>。</p>
<p>为了<strong>证明满足有限等待</strong>，注意，当一个进程退出临界区时，它会<strong>循环扫描数组(i + 1, ~ , n - 1, 0, i - 1)<strong>并指派下一个进程，因此</strong>最多等待n-1次</strong>。</p>
<h3 id="6-5-互斥锁"><a href="#6-5-互斥锁" class="headerlink" title="6-5 互斥锁"></a>6-5 互斥锁</h3><p>临界区问题的<strong>基于硬件的解决方案不但复杂，而且不能为程序员直接使用</strong>。因此，操作系统设计人员构建软件工具，以解决临界区问题。</p>
<p>最简单的工具就是<strong>互斥锁</strong>（mutex lock）。一个进程在进入临界区时应得到锁；它在退出临界区时释放锁。函数acquire()获取锁，而函数release()释放锁.每个互斥锁有一个布尔变量available，它的值表示锁是否可用. <strong>当进程试图获取不可用的锁时，进程会被阻塞，并等待到锁释放</strong>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">acquire</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(!available); <span class="comment">// busy wait</span></span><br><span class="line">  available = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">release</span><span class="params">()</span>&#123;</span><br><span class="line">  available = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>对acquire()或release()的调用必须原子地执行</strong>。因此，互斥锁通常采用如6.4节所述的<strong>硬件机制来实现</strong></p>
<h4 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h4><p>这里所给实现的<strong>主要缺点</strong>是，它<strong>需要忙等待</strong>（busy waiting）。当有一个进程在临界区中，任何其他进程在<strong>进入临界区时必须连续循环地调用acquire()<strong>。其实，这种类型的互斥锁</strong>也被称为自旋锁</strong>（spin lock），因为进程不停地旋转，以等待锁变得可用。连续循环显然是个问题。忙等待<strong>浪费CPU周期，而这原本可以有效用于其他进程</strong>。</p>
<p>不过，自旋锁确实有一个<strong>优点</strong>：当进程在<strong>等待锁时，没有上下文切换</strong>（上下文切换可能需要相当长的时间）。因此，当使<strong>用锁的时间较短时，自旋锁还是有用的</strong>。自旋锁通常用于多处理器系统，一个线程可以在一个处理器上“旋转”，而其他线程在其他处理器上执行临界区。</p>
<h3 id="6-6-信号量-pv"><a href="#6-6-信号量-pv" class="headerlink" title="6-6 信号量-pv"></a>6-6 信号量-pv</h3><p>互斥锁是最简单的同步工具，这里我们介绍<strong>信号量</strong>，有类似互斥锁的功能，但能提供更多高级方法来同步活动。</p>
<p>一个<strong>信号量（semaphore）S是个整型变量</strong>，它除了<strong>初始化外只能通过两个标准原子操作：wait()和signal()来访问</strong>。操作wait()最初称为P（荷兰语proberen，测试）；操作signal()最初称为V（荷兰语verhogen，增加）. 因此信号量操作也叫<strong>PV操作</strong></p>
<p>他们的定义如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// wait()</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">wait</span><span class="params">(semaphore S)</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(S &lt;= <span class="number">0</span>)&#123;&#125;; <span class="comment">// busy wait</span></span><br><span class="line">  --S; <span class="comment">// 等待有可用资源</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// signal()</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">signal</span><span class="params">(semaphore S)</span>&#123;</span><br><span class="line">  ++S;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在wait()和signal()操作中, <strong>信号量整数值的修改应不可分割地执行</strong>。也就是说，当<strong>一个进程修改信号量值时，没有其他进程能够同时修改同一信号量的值</strong>另外，对于wait（S），S整数值的<strong>测试</strong>（S ≤ 0）和<strong>修改</strong>（S–），也<strong>不能被中断</strong>。</p>
<h4 id="6-6-1-信号量的使用"><a href="#6-6-1-信号量的使用" class="headerlink" title="6-6-1 信号量的使用"></a>6-6-1 信号量的使用</h4><p><strong>操作系统通常区分计数信号量与二进制信号量</strong>。<strong>计数信号量</strong>（counting semaphore）的<strong>值不受限制</strong>，而<strong>二进制信号量</strong>（binarysemaphore）的<strong>值只能为0或1</strong>。因此，二进制信号量类似于互斥锁。事实上，在没有提供互斥锁的系统上，可以使用二进制信号量来提供互斥。</p>
<p><strong>计数信号量</strong>可以用于控制访问具有<strong>多个实例的某种资源</strong>。信号量的<strong>初值为可用资源数量</strong>。当进程<strong>需要使用资源</strong>时，需要对该信号量<strong>执行wait()<strong>操作（减少信号量的计数）。当进程</strong>释放资源</strong>时，需要对该信号量**执行signal()**操作（增加信号量的计数）。当信号量的计数为0时，所有资源都在使用中。之后，需要使用资源的进程将会阻塞，直到计数大于0。</p>
<p>以下为一个使用信号量解决的同步问题</p>
<center> <img src="./osimg/semaphore.png" > </center>

<p>注意，信号量最好设为<strong>可用</strong>资源数量。</p>
<h4 id="6-6-2-信号量的实现"><a href="#6-6-2-信号量的实现" class="headerlink" title="6-6-2 信号量的实现"></a>6-6-2 信号量的实现</h4><h5 id="克服忙等待"><a href="#克服忙等待" class="headerlink" title="克服忙等待"></a>克服忙等待</h5><p>可以这样<strong>修改信号量操作wait()和signal()的定义</strong>：当一个进程执行操作wait()并且发现信号量值不为正时，它必须等待。然而，该进程不是忙等待而是<strong>阻塞自己</strong>。阻塞操作<strong>将一个进程放到与信号量相关的等待队列中，并且将该进程状态切换成等待状态</strong>。然后, <strong>控制转到CPU调度程序，以便选择执行另一个进程</strong>。</p>
<p>等待信号量S而<strong>阻塞的进程，在其他进程执行操作signal()后，应被重新执行</strong>。进程的<strong>重新执行是通过操作wakeup()来进行的</strong>，它<strong>将进程从等待状态改为就绪状态</strong>。然而，进程被添加到就绪队列.</p>
<p>因此我们按以下方法实现信号量：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">process</span> *<span class="title">list</span>;</span> <span class="comment">// 等待队列</span></span><br><span class="line">&#125;semaphore</span><br></pre></td></tr></table></figure>

<p>每个信号量都有<strong>一个整数value和一个进程链表list</strong>。当一个进程必须等待信号量时，就被添加到进程链表。操作signal()从等待进程链表上取走一个进程，并加以唤醒。</p>
<p>wait()和signal()实现如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">wait</span><span class="params">(semaphore *S)</span>&#123;</span><br><span class="line">  S-&gt;value--;</span><br><span class="line">  <span class="keyword">if</span>(S-&gt;value &lt; <span class="number">0</span>)&#123;</span><br><span class="line">    S-&gt;<span class="built_in">list</span>.append(this_process); <span class="comment">// add process to list</span></span><br><span class="line">    block();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">signal</span><span class="params">(semaphore *S)</span>&#123;</span><br><span class="line">  S-&gt;value++;</span><br><span class="line">  <span class="keyword">if</span>(S-&gt;value &lt;= <span class="number">0</span>)&#123;</span><br><span class="line">    P = S-&gt;<span class="built_in">list</span>.back();</span><br><span class="line">    S-&gt;<span class="built_in">list</span>.erase(S-&gt;<span class="built_in">list</span>.end());</span><br><span class="line">    wakeup(P);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意, <strong>这样实现的信号量的值可以是负数</strong>，而在具有忙等待的信号量经典定义下，信号量的值不能为负。如果信号量的值为负，那么<strong>它的绝对值就是等待它的进程数</strong>。出现这种情况源于，在实现操作wait()时互换了递减和测试的顺序。</p>
<p>通过每个进程控制块PCB的一个链接字段，等待进程的链表可以轻松实现。FIFO队列实现的列表可以确保有限等待。当然也可以采用其他的排队策略. <strong>信号量的正确使用不依赖于信号量链表的特定排队策略</strong>。</p>
<p>关键的是, <strong>信号量操作应原子执行</strong>。我们应保证：对<strong>同一信号量</strong>，没有两个进程可以同时执行操作wait()和signal(). (<strong>不能打断计数器更新，不然会有counter++的错误</strong>)</p>
<p>在<strong>单处理器环境</strong>下,简单禁止中断可以实现原子执行。</p>
<p>对于<strong>多处理器环境</strong>，每个处理器的中断都应被禁止；每个处理器中断的禁止会很困难，也会严重影响性能。因此, <strong>SMP系统应提供其他加锁技术</strong>，如compare_and_swap()或自旋锁，以确保wait()与signal()原子执行。</p>
<p>有一点很重要，这里定义的wait和signal操作<strong>只是将忙等待从等待区转移到临界区中</strong>。由于临界区指令通常很短，不会长时间占用，因此忙等待的效率可以接受，但对于那些临界区很长的应用程序，忙等待此时会很低效。</p>
<h4 id="6-6-3-死锁和饥饿"><a href="#6-6-3-死锁和饥饿" class="headerlink" title="6-6-3 死锁和饥饿"></a>6-6-3 死锁和饥饿</h4><p>具有等待队列的信号量实现可能导致这样的情况：两个或多个<strong>进程无限等待一个事件</strong>而<strong>该事件只能由这些等待进程之一来产生</strong>。这里的事件是执行操作signal()。当出现这样的状态时，这些进程就为<strong>死锁</strong>（deadlocked）。</p>
<p>例子如下</p>
<center> <img src="./osimg/6死锁例子.png" > </center>

<p>另外的相关问题是<strong>无限阻塞</strong>和<strong>饥饿</strong>，有LIFO顺序增删的列表会出现<strong>无限阻塞</strong>，最早进入的进程可能无法释放。</p>
<h4 id="6-6-4-优先级反转"><a href="#6-6-4-优先级反转" class="headerlink" title="6-6-4 优先级反转"></a>6-6-4 优先级反转</h4><p>作为一个例子，假设有三个进程，L、M和H，它们的优先级顺序为L &lt; M &lt; H。假定进程H需要资源R，而R目前正在被进程L访问。通常，进程H将等待L用完资源R。但是，现在假设进程M进人可运行状态，从而抢占进程L。间接地，具有较低优先级的进程M，影响了进程H应等待多久，才会使得进程L释放资源R。</p>
<p>(<strong>例子中，M可以抢占L而H不能抢占L的原因可能为：M不需要影响L的资源使用，可能只是简单的CPU调度导致的抢占，而H需要使用L的资源，因此不能直接抢占L，如读写操作。因此，M的抢占导致了L的更晚释放，间接导致了H的延迟运行</strong>)</p>
<p>这个问题称为<strong>优先级反转</strong>（priority inversion）。它<strong>只出现在具有两个以上优先级的系统中</strong>，因此一个解决方案是只有两个优先级。但显然这是不够用的。</p>
<p>通常，这些系统在解决问题时<strong>采用优先级继承协议</strong>（priority-inheritance protocol）。根据这个协议，所有<strong>正在访问资源的进程获得需要访问它的更高优先级进程的优先级</strong>，直到它们用完了有关资源为止。当它们<strong>用完时，它们的优先级恢复到原始值</strong>。因此L临时获得H的优先级，也就不会被M抢占。</p>
<h3 id="6-7-经典同步问题"><a href="#6-7-经典同步问题" class="headerlink" title="6-7 经典同步问题"></a>6-7 经典同步问题</h3><h4 id="6-7-1-有界缓冲问题"><a href="#6-7-1-有界缓冲问题" class="headerlink" title="6-7-1 有界缓冲问题"></a>6-7-1 有界缓冲问题</h4><p>以生产者-消费者问题为例，需要以下的共享数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> n; <span class="comment">// buffer_size</span></span><br><span class="line">semaphore mutex; <span class="comment">// 独占</span></span><br><span class="line">semaphore empty; <span class="comment">// 指示空缓冲区</span></span><br><span class="line">semaphore full; <span class="comment">// 指示满缓冲区，也就是被填入了东西的格子</span></span><br></pre></td></tr></table></figure>

<p>假设缓冲池有n个缓冲区，每个缓冲区可存一个数据项。信号量mutex提供缓冲池访问的互斥要求，并初始化为1。信号量empty和full分别用于表示空的和满(填入了内容)的缓冲区数量。信号量empty初始化为n，而信号量full初始化为0。</p>
<p>生产者和消费者的结构如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 生产者</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">  <span class="comment">/* 生产内容 */</span></span><br><span class="line">  wait(empty); <span class="comment">// 等待空位</span></span><br><span class="line">  wait(mutex); <span class="comment">// 不允许同时生产和消费</span></span><br><span class="line">  <span class="comment">/* 填充内容 */</span></span><br><span class="line">  signal(mutex); <span class="comment">// 释放独占</span></span><br><span class="line">  signal(full); <span class="comment">// 发出填充完成信号</span></span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 消费者</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">  wait(full);</span><br><span class="line">  wait(mutex);</span><br><span class="line">  <span class="comment">/* 取出产品 */</span></span><br><span class="line">  signal(mutex);</span><br><span class="line">  signal(empty);</span><br><span class="line">  <span class="comment">/* 消费取出的产品 */</span></span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<p>观察由mutex的wait和signal围成的代码块，可见尽量减少独占区域可以加快运行效率。</p>
<h4 id="6-7-2-读者-作者问题"><a href="#6-7-2-读者-作者问题" class="headerlink" title="6-7-2 读者-作者问题"></a>6-7-2 读者-作者问题</h4><p>对于数据库，进行读操作的为<strong>读者</strong>，需要修改数据库内容的写操作执行者为<strong>作者</strong>。显然多个读者同时访问没问题，但<strong>作者不能和其它读者或作者一起访问共享的数据</strong>。</p>
<p>为满足要求，我们<strong>需要要求作者写入时独占数据库的访问权</strong>。</p>
<p>这个问题还有多个变种：</p>
<ul>
<li>第一读者-作者问题: 要求<strong>读者不应保持等待，除非作者已获得权限</strong>使用共享对象。换句话说，没有读者，由于某个作者等待，而等待其他读者的完成。(<strong>读者尽快读</strong>)</li>
<li>第二读者-作者问题：一旦作者就绪，那么作者会尽可能快地执行。换句话说，如果有一个作者等待访问对象，那么不会有新的读者可以开始读。(<strong>作者尽快写</strong>)</li>
</ul>
<p>这两个问题的<strong>解答都可能导致饥饿</strong>。对于第一种情况，作者可能饥饿；对于第二种情况，读者可能饥饿。</p>
<p>对于第一读者-作者问题的解决如下，需要以下的数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore rw_mutex = <span class="number">1</span>; <span class="comment">// 指示读写状态</span></span><br><span class="line">semaphore mutex = <span class="number">1</span>; <span class="comment">// 保证更新read_count的互斥</span></span><br><span class="line"><span class="type">int</span> read_count = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>信号量mutex和rw_mutex初始化为1；read_count初始化为0。信号量<strong>rw_mutex为读者和作者进程所共用</strong>。信号量<strong>mutex用于确保在更新变量read_count时的互斥</strong>。变量read_count用于跟踪多少进程正在读对象。信号量<strong>rw_mutex供作者作为互斥信号量。它也为第一个进入临界区和最后一个离开临界区的读者所使用，而不为其他读者所使用</strong>。</p>
<center> <img src = "./osimg/第一读者-作者问题.png"> </center>

<p>注意，如果有一个作者进程在临界区内，且n个读者处于等待，那么一个读者在rw_mutex上等待，而n-1个在mutex上等待。也要注意，当一个作者执行signal(rw_mutex)时，可以重新启动等待读者或作者的执行。这一选择由调度程序来进行。</p>
<p>有些系统将读者-作者问题及其解答进行了抽象，从而提供<strong>读写锁</strong>（read-writer lock）。在获取读写锁时，需要指定锁的模式：读访问或写访问。当一个进程只希望读共享数据时，可申请读模式的读写锁；当一个进程希望修改共享数据时，应申请写模式的读写锁。多个进程<strong>可允许并发获取读模式的读写锁</strong>，但是<strong>只有一个进程可获取写模式的读写锁</strong>，作者进程需要互斥的访问。</p>
<h4 id="6-7-3-哲学家就餐问题"><a href="#6-7-3-哲学家就餐问题" class="headerlink" title="6-7-3 哲学家就餐问题"></a>6-7-3 哲学家就餐问题</h4><p>假设有5个哲学家，他们的生活只是思考和吃饭。这些哲学家共用一个圆桌，每位都有一把椅子。在桌子中央有一碗米饭，在桌子上放着5根筷子（图6-13）。当一位哲学家思考时，他与其他同事不交流。时而，他会感到饥饿，并试图拿起与他相近的两根筷子（筷子在他和他的左或右邻居之间）。一个哲学家一次只能拿起一根筷子。显然，他不能从其他哲学家手里拿走筷子。当一个饥饿的哲学家同时拥有两根筷子时，他就能吃。在吃完后，他会放下两根筷子，并开始思考。</p>
<center> <img src = "/osimg/哲学家就餐问题.png" > </center>

<p><strong>哲学家就餐问题</strong>是大量并发控制问题的一个例子。这个代表型的例子满足：在<strong>多个进程之间分配多个资源</strong>，而且不会出现死锁和饥饿。</p>
<p>一种简单的解决方法是<strong>每只筷子都用一个信号量来表示</strong>。一个哲学家通过执行操作wait()试图获取相应的筷子，他会通过执行操作signal()以释放相应的筷子。因此，共享数据为</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">semaphore chopstick[<span class="number">5</span>];</span><br><span class="line">fill(chopstick,chopstick+<span class="number">5</span>,<span class="number">1</span>); <span class="comment">//初始化为1</span></span><br></pre></td></tr></table></figure>
<p>对于每个哲学家其结构为：</p>
<center> <img src = "/osimg/哲学家i.png" > </center>

<p>但这种方法只能确保不会有相邻的两个哲学家同时进食，仍然<strong>会导致饥饿</strong>。若每个哲学家都拿起左手边的筷子，那么每个哲学家都将无限等待右手的筷子。</p>
<p>补救措施：</p>
<ul>
<li>最多允许4个哲学家同时上桌</li>
<li>必须当两根筷子都能被拿起时才拿</li>
<li>采用非对称解决，单号的那先拿左手筷子，双号的先拿右手的筷子</li>
</ul>
<p>更多的解决方案在第七章<a href="#%E6%AD%BB%E9%94%81">死锁</a>提到。</p>
<h3 id="6-8-管程"><a href="#6-8-管程" class="headerlink" title="6-8 管程"></a>6-8 管程</h3><p>虽然信号量提供了一种方便且有效的进程同步机制，但是<strong>信号量的使用错误可能导致难以检测的时序错误</strong>，因为这些错误<strong>只有在特定执行顺序时才会出现，而这些顺序并不总是出现</strong>。对于生产者-消费者问题的信号量解决方案，若不遵守进程在进入临界区之前执行wait（mutex），之后执行signal（mutex）这一顺序，那么会出现多个进程在临界区中，这些错误可能是无意的编程错误或故意行为，但很难被检查。</p>
<p>为了处理这种错误，研究人员开发了一些高级语言工具。本节介绍一种重要的、高级的同步工具，即<strong>管程</strong>（monitor）。</p>
<p>管程封装了同步所需的工具，降低了出现编程错误的可能。</p>
<h4 id="6-8-1-使用方法"><a href="#6-8-1-使用方法" class="headerlink" title="6-8-1 使用方法"></a>6-8-1 使用方法</h4><p>管程是<strong>抽象数据类型</strong>（AbstractDataType，ADT）封装了数据及对其操作的一组函数, 提供一组由程序员定义的、在管程内互斥的操作。管程类型也包括一组变量，用于定义这一类型的实例状态，也包括操作这些变量的函数实现.</p>
<center> <img src = "/osimg/管程结构和语法.png" > </center>

<p><strong>管程类型的表示不能直接由各种进程所使用</strong>。因此，只有<strong>管程内定义的函数才能访问管程内的局部声明的变量和形式参数</strong>。类似地，管程的局部变量只能为局部函数所访问。</p>
<p><strong>管程结构确保每次只有一个进程在管程内处于活动状态</strong>。因此，程序员不需要明确编写同步约束。示意如下</p>
<center> <img src = "/osimg/管程示意.png" > </center>

<p>更加客制化，更强大的同步机制可由程序员自己定义的<strong>条件变量</strong>（condition）提供，为了提供定制化的同步方案，可以定义一个或多个condition变量. <strong>当不满足条件时调用x.wait(), 满足时调用x.signal()</strong></p>
<p>对于<strong>条件变量x</strong>，只有x.wait()和x.signal()可以调用：</p>
<ul>
<li>x.wait(): 调用这一操作的进程会<strong>被挂起</strong>，直到被x.signal()唤醒</li>
<li>x.signal(): 重新<strong>恢复挂起进程</strong>，若没有挂起进程，则不执行任何操作。与signal()不同，后者永远改变信号量。</li>
</ul>
<center> <img src = "/osimg/有条件变量的管程.png" > </center>

<p>现在，假设<strong>进程P调用x.signal()</strong>, 此时在条件变量x上还有一个挂起进程Q。若允许Q继续执行，那么P必须等待，否则会有两个进程运行在管程内。此时，有两种可能：</p>
<ul>
<li><strong>唤醒并等待</strong>（signal and wait）：进程<strong>P等待直到Q离开管程</strong>，或者<strong>等待另一个条件</strong>。</li>
<li><strong>唤醒并继续</strong>（signal and continue）：进程<strong>Q等待直到P离开管程</strong>或者<strong>等待另一个条件</strong>。</li>
</ul>
<h4 id="6-8-2-哲学家就餐问题的管程解决方案"><a href="#6-8-2-哲学家就餐问题的管程解决方案" class="headerlink" title="6-8-2 哲学家就餐问题的管程解决方案"></a>6-8-2 哲学家就餐问题的管程解决方案</h4><p>为解答，我们需要声明哲学家的三种状态:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> &#123;</span>THINKING, HUNGRY, EATING&#125; state[<span class="number">5</span>];</span><br></pre></td></tr></table></figure>
<p>为避免死锁，我们要求只能在两根筷子都可用时才能拿起，其实现为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(state[(i+<span class="number">1</span>)%<span class="number">5</span>] != EATING &amp;&amp; state[(i+<span class="number">4</span>)%<span class="number">5</span>] != EATING)&#123;</span><br><span class="line">  state[i] = EATING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意<strong>应该还要要求哲学家状态为HUNGRY，表示在等待拿起筷子</strong>。</p>
<p>此外，还需要条件变量来让哲学家在没拿到筷子时挂起自己，避免忙等待。因此需要：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">condition self[<span class="number">5</span>];</span><br></pre></td></tr></table></figure>
<p>由此，我们有管程</p>
<center> <img src = "/osimg/哲学家就餐问题管程解答.png" > </center>

<h4 id="6-8-3-采用信号量的管程实现"><a href="#6-8-3-采用信号量的管程实现" class="headerlink" title="6-8-3 采用信号量的管程实现"></a>6-8-3 采用信号量的管程实现</h4><p>对于每个管程，都有一个<strong>信号量mutex（初始化为1）</strong>。进程在进入管程之前应执行wait（mutex）在离开管程之后应执行signal（mutex）。</p>
<p>由于<strong>唤醒进程必须等待，直到重新启动的进程离开或等待</strong>，需要引入新的<strong>信号量next(初始化为0)来让唤醒的进程挂起它自己</strong>。此外还需要next_count对挂起进程计数。</p>
<p>对于每个外部函数F，应该被替换成</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">F()&#123;</span><br><span class="line">  wait(mutex);</span><br><span class="line">  <span class="comment">/* body of F */</span></span><br><span class="line">  <span class="keyword">if</span>(next_count &gt; <span class="number">0</span>) signal(next); <span class="comment">// 唤醒一个进程</span></span><br><span class="line">  <span class="keyword">else</span> signal(mutex); <span class="comment">// 无等待进程，执行完毕就退出并释放互斥锁</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码确保了<strong>管程内互斥</strong>。</p>
<p>条件变量的实现：</p>
<p><strong>条件变量x有信号量x_sem, 和x_count两个成员，均初始化为0</strong></p>
<p>x.wait():</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">x_count++; <span class="comment">// x上的进程自增, 调用x.wait()的进程加入x条件的等待队列</span></span><br><span class="line"><span class="keyword">if</span>(next_count &gt; <span class="number">0</span>) signal(next); <span class="comment">// 若当前有挂起的进程，唤醒她</span></span><br><span class="line"><span class="keyword">else</span> signal(mutex); <span class="comment">// 无等待进程，释放互斥锁以允许下一个进程运行</span></span><br><span class="line">wait(x_sem); <span class="comment">// ？</span></span><br><span class="line">x_count--;</span><br></pre></td></tr></table></figure>
<p>x.signal():</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(x_count &gt; <span class="number">0</span>)&#123;</span><br><span class="line">  next_count++;</span><br><span class="line">  signal(x_sem);</span><br><span class="line">  wait(next);</span><br><span class="line">  next_count--;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以下为解决生产者-消费者的范例：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;semaphore.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span> <span class="comment">// for sleep function</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义信号量</span></span><br><span class="line"><span class="type">sem_t</span> mutex;  <span class="comment">// 管程的互斥信号量</span></span><br><span class="line"><span class="type">sem_t</span> next;   <span class="comment">// 管程内的条件变量信号量</span></span><br><span class="line"><span class="type">int</span> next_count = <span class="number">0</span>;  <span class="comment">// 管程内等待的线程数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 条件变量x的信号量和计数器</span></span><br><span class="line"><span class="type">sem_t</span> x_sem;</span><br><span class="line"><span class="type">int</span> x_count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 共享资源</span></span><br><span class="line">std::queue&lt;<span class="type">int</span>&gt; buffer;</span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> <span class="type">int</span> max_buffer_size = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 管程入口</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">enter_monitor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">sem_wait</span>(&amp;mutex); <span class="comment">// 进入管程</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 管程退出</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">exit_monitor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (next_count &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;next); <span class="comment">// 如果有等待线程，唤醒一个</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;mutex); <span class="comment">// 否则释放管程互斥信号量</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 条件变量x的wait操作</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">x_wait</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    x_count++;</span><br><span class="line">    <span class="keyword">if</span> (next_count &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;next); <span class="comment">// 如果有等待线程，唤醒一个</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;mutex); <span class="comment">// 否则释放管程互斥信号量</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">sem_wait</span>(&amp;x_sem); <span class="comment">// 等待条件变量信号量</span></span><br><span class="line">    x_count--;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 条件变量x的signal操作</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">x_signal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x_count &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        next_count++;</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;x_sem); <span class="comment">// 唤醒等待在x条件变量上的线程</span></span><br><span class="line">        <span class="built_in">sem_wait</span>(&amp;next); <span class="comment">// 等待next信号量</span></span><br><span class="line">        next_count--;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">producer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="built_in">enter_monitor</span>();</span><br><span class="line">        <span class="keyword">while</span> (buffer.<span class="built_in">size</span>() == max_buffer_size) &#123;</span><br><span class="line">            <span class="built_in">x_wait</span>(); <span class="comment">// 缓冲区满，等待</span></span><br><span class="line">        &#125;</span><br><span class="line">        buffer.<span class="built_in">push</span>(count);</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Produced &quot;</span> &lt;&lt; count++ &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">if</span> (buffer.<span class="built_in">size</span>() == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="built_in">x_signal</span>(); <span class="comment">// 唤醒消费者</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">exit_monitor</span>();</span><br><span class="line">        <span class="built_in">sleep</span>(<span class="number">1</span>); <span class="comment">// 模拟生产时间</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">consumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="built_in">enter_monitor</span>();</span><br><span class="line">        <span class="keyword">while</span> (buffer.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="built_in">x_wait</span>(); <span class="comment">// 缓冲区空，等待</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> value = buffer.<span class="built_in">front</span>();</span><br><span class="line">        buffer.<span class="built_in">pop</span>();</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Consumed &quot;</span> &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">if</span> (buffer.<span class="built_in">size</span>() == max_buffer_size - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="built_in">x_signal</span>(); <span class="comment">// 唤醒生产者</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">exit_monitor</span>();</span><br><span class="line">        <span class="built_in">sleep</span>(<span class="number">1</span>); <span class="comment">// 模拟消费时间</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化信号量</span></span><br><span class="line">    <span class="built_in">sem_init</span>(&amp;mutex, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">sem_init</span>(&amp;next, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">sem_init</span>(&amp;x_sem, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function">std::thread <span class="title">prod1</span><span class="params">(producer)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">cons1</span><span class="params">(consumer)</span></span>;</span><br><span class="line"></span><br><span class="line">    prod<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line">    cons<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 销毁信号量</span></span><br><span class="line">    <span class="built_in">sem_destroy</span>(&amp;mutex);</span><br><span class="line">    <span class="built_in">sem_destroy</span>(&amp;next);</span><br><span class="line">    <span class="built_in">sem_destroy</span>(&amp;x_sem);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="6-8-4-管程内的进程重启"><a href="#6-8-4-管程内的进程重启" class="headerlink" title="6-8-4 管程内的进程重启"></a>6-8-4 管程内的进程重启</h4><p>现在，我们讨论<strong>管程内的进程重新启动的顺序问题</strong>。如果<strong>多个进程已挂起在条件x上，并且有个进程执行了操作x.signal()，那么我们如何选择哪个挂起进程应能重新运行</strong>?一个简单的解决方法是使用先来先服务（FCFS）顺序，这样等待最长的进程首先重新运行。然而，在许多情况下，这种简单调度方案是不够的。为此，可以<strong>使用条件等待</strong>（conditional-wait）结构。它具有如下形式：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">x.wait(c)</span><br></pre></td></tr></table></figure>
<p>其中<strong>c是整型表达式</strong>，需要在执行操作wait()时进行计算。值<strong>c称为优先值</strong>（priority number），与挂起进程的名称一起存储。当执行x.signal()时，具有最小优先值的进程会被重新启动。</p>
<p>ResourceAllocator P213</p>
<h3 id="6-9-同步例子"><a href="#6-9-同步例子" class="headerlink" title="6-9 同步例子"></a>6-9 同步例子</h3><h4 id="6-9-1-windows同步"><a href="#6-9-1-windows同步" class="headerlink" title="6-9-1 windows同步"></a>6-9-1 windows同步</h4><p>P215</p>
<h4 id="6-9-2-linux同步"><a href="#6-9-2-linux同步" class="headerlink" title="6-9-2 linux同步"></a>6-9-2 linux同步</h4><p>P215</p>
<h4 id="6-9-3-solaris同步"><a href="#6-9-3-solaris同步" class="headerlink" title="6-9-3 solaris同步"></a>6-9-3 solaris同步</h4><p>P216</p>
<h4 id="6-9-4-pthreads同步"><a href="#6-9-4-pthreads同步" class="headerlink" title="6-9-4 pthreads同步"></a>6-9-4 pthreads同步</h4><p>P218</p>
<h3 id="6-10-替代方法"><a href="#6-10-替代方法" class="headerlink" title="6-10 替代方法"></a>6-10 替代方法</h3><h4 id="6-10-1-事务内存"><a href="#6-10-1-事务内存" class="headerlink" title="6-10-1 事务内存"></a>6-10-1 事务内存</h4><p><strong>事务内存</strong>（transactional memory）的概念源自数据库理论，但它提供了一种进程同步的策略。<strong>内存事务</strong>（memory transaction）为一个<strong>内存读写操作的序列</strong>，它是<strong>原子的</strong>。如果事务中的所有操作都完成了，内存事务就被提交。否则，应中止操作并回滚。</p>
<p>优点是，事务内存<strong>由内存系统而非开发人员保证原子性</strong>，不涉及锁所以也不会导致死锁。</p>
<p>实现方式有软硬件两种：</p>
<ul>
<li><strong>软件事务内存</strong>（Software Transactional Memory，STM）：<br>STM通过<strong>在事务块中插人检测代码来工作</strong>。代码，由<strong>编译器插入</strong>，通过检查哪些语句并发运行和哪些地方需要特定的低级加锁，来管理每个事务。</li>
<li><strong>硬件事务内存</strong>（Hardware Transactional Memory，HTM）：<br>使用硬件高速缓存层次结构和高速缓存一致性协议，对<strong>涉及驻留在单独处理器的高速缓存中的共享数据进行管理和解决冲突</strong>。HTM不要求特定的代码，因此具有<strong>比STM更少的开销</strong>。但是，HTM确实<strong>需要修改现有的缓存层次结构和缓存一致性协议，以便支持事务内存</strong>。</li>
</ul>
<h4 id="6-10-2-openmp"><a href="#6-10-2-openmp" class="headerlink" title="6-10-2 openmp"></a>6-10-2 openmp</h4><p>OpenMp提供</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp critical&#123;</span></span><br><span class="line">  <span class="comment">/* code */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>来声明临界区，一次只有一个线程可在临界区执行。</p>
<p>采用OpenMP临界区编译器指令的<strong>优点之一</strong>是：与标准互斥锁相比，它通常被认为<strong>更加容易</strong>。<br><strong>缺点</strong>是，应用程序<strong>开发人员仍然必须识别可能的竞争条件</strong>，并使用编译器指令充分保护共享数据。此外，由于临界区编译器指令的行为很像互斥锁，当有两个或<strong>更多的临界区时死锁仍然可能发生</strong>。</p>
<h4 id="6-10-3-函数式编程语言"><a href="#6-10-3-函数式编程语言" class="headerlink" title="6-10-3 函数式编程语言"></a>6-10-3 函数式编程语言</h4><p>著名的编程语言，如C、C++、Java和C#，称为<strong>命令式</strong>（imperative）（或<strong>过程式</strong>（procedural））语言。命令式语言用<strong>于实现基于状态的算法</strong>。采用这些语言，算法流程对执行正确是至关重要的，并且状态采用变量和其他数据结构来表示。当然，程序<strong>状态是可变的，因为变量可以随着时间不同而被分配不同的值</strong>。</p>
<p><strong>函数式不同于命令式语言的编程</strong>。命令式与函数式语言的根本区别是，函数式语言并<strong>不维护状态</strong>。也就是说，一旦一个<strong>变量被定义和赋了一个值，它的值是不可变的，即它不能被修改</strong>。由于函数式语言不允许可变状态，它们不需要关心诸如竞争条件和死锁等问题。</p>
<p>Scala，Erlang</p>
<h2 id="7-死锁"><a href="#7-死锁" class="headerlink" title="7 死锁"></a>7 死锁</h2><p>在多道程序环境中，多个进程可以竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。有时，如果所<strong>申请的资源被其他等待进程占有</strong>，那么该等待进程<strong>有可能再也无法改变状态</strong>。这种情况称为<strong>死锁</strong>.</p>
<h3 id="7-1-系统模型"><a href="#7-1-系统模型" class="headerlink" title="7-1 系统模型"></a>7-1 系统模型</h3><p>进程在使用资源前应申请资源，在使用资源之后应释放资源。一个进程可能要申请许多资源，以便完成指定任务。显然，申请的资源数量不能超过系统所有资源的总和.</p>
<p>在正常操作模式下，进程只能按如下顺序使用资源:</p>
<ol>
<li><strong>申请</strong>：进程请求资源。如果申请不能立即被允许,那么申请进程应等待，直到它能获得该资源为止</li>
<li><strong>使用</strong>：进程对资源进行操作</li>
<li><strong>释放</strong>：进程释放资源</li>
</ol>
<p>当一组进程内的每个进程都在等待一个事件，而这一事件只能由这一组进程的另一个进程引起，那么这组进程就处于<strong>死锁状态</strong>。这里所关心的主要事件是资源的获取和释放. </p>
<h3 id="7-2-死锁特征"><a href="#7-2-死锁特征" class="headerlink" title="7-2 死锁特征"></a>7-2 死锁特征</h3><p>互斥死锁的经典例子为<a href="#6-6-3-%E6%AD%BB%E9%94%81%E5%92%8C%E9%A5%A5%E9%A5%BF">死锁例子</a></p>
<h4 id="7-2-1-必要条件"><a href="#7-2-1-必要条件" class="headerlink" title="7-2-1 必要条件"></a>7-2-1 必要条件</h4><p>如果在一个系统中以下<strong>四个条件同时成立</strong>，那么就能<strong>引起死锁</strong>:</p>
<ol>
<li><strong>互斥</strong>（mutual exclusion）: <strong>即至少有一个资源必须处于非共享模式</strong>，即一次只有一个进程可使用。如果另一进程申请该资源，那么申请进程应等到该资源释放为止。</li>
<li><strong>占有并等待</strong>（holdandwait）: 一个进程应<strong>占有至少一个资源</strong>，并<strong>等待另一个资源</strong>，而<strong>该资源为其他进程所占有</strong>。</li>
<li><strong>非抢占</strong>（no preemption）: 资源不能被抢占，即<strong>资源只能被进程在完成任务后自愿释放</strong>。</li>
<li><strong>循环等待</strong>（circular wait）: 有一组等待进程{P0，P1，··· ，Pn}，P0等待的资源为P1占有，P1等待的资源为P2占有，..，Pn-1等待的资源为Pn占有，Pn等待的资源为P0占有。也就是说Pi占有了资源R[(i-1)%(n+1)]。</li>
</ol>
<p><strong>所有四个条件必须同时成立才会出现死锁</strong>，循环等待条件意味着占有并等待条件，这样<strong>四个条件并不完全独立</strong>。</p>
<h4 id="7-2-2-资源分配图"><a href="#7-2-2-资源分配图" class="headerlink" title="7-2-2 资源分配图"></a>7-2-2 资源分配图</h4><p>通过称为<strong>系统资源分配图</strong>（system resource-allocation graph）的<strong>有向图</strong>可以更精确地<strong>描述死锁</strong></p>
<p>一个资源分配图有以下几个元素组成：</p>
<ul>
<li><strong>节点集合 V &#x3D; {P,R}</strong>: 其中<strong>P为系统活动进程的集合</strong>{P0,P1,···,Pn}, <strong>R为系统所有资源类型的集合</strong>{R0,R1,···,Rm}</li>
<li><strong>申请边</strong> : 一条Pi → Rj的<strong>有向边</strong>被称为申请边，表示Pi申请了Rj的一个实例</li>
<li><strong>分配边</strong>: 一条Ri → Pj的<strong>有向边</strong>被称为分配边，表示Ri的一个资源分配给了Pj</li>
</ul>
<p>Ri可能有多个资源实例，在图中以小点表示</p>
<center> <img src="./osimg/资源分配图.png" > </center>

<p>根据资源分配图的定义，可以证明：如果<strong>分配图没有环</strong>，那么<strong>系统就没有进程死锁</strong>。如果<strong>分配图有环</strong>，那么<strong>可能存在死锁</strong>。</p>
<p>若每个<strong>资源只有单个实例</strong>，那么有环一定有死锁, <strong>环是死锁的充要条件</strong>。</p>
<p>若<strong>资源有多个实例</strong>，那么有环不一定存在死锁, <strong>环只是死锁的必要条件</strong>。</p>
<center> <img src="./osimg/环与死锁.png" > </center>

<h3 id="7-3-死锁处理方法"><a href="#7-3-死锁处理方法" class="headerlink" title="7-3 死锁处理方法"></a>7-3 死锁处理方法</h3><p>一般来说，处理死锁问题有三种方法:</p>
<ul>
<li>通过协议来<strong>预防或避免死锁</strong>，确保系统不会进入死锁状态</li>
<li>允许系统进入死锁状态，然后检测它，并加以恢复</li>
<li>忽视这个问题，认为死锁不可能在系统内发生。</li>
</ul>
<p>第三种解决方案为大多数操作系统所采用，包括Linux和Windows。因此，应用程序<strong>开发人员需要自己编写程序，以便处理死锁</strong>。</p>
<p>为确保不发生死锁，系统可以采用<strong>死锁预防</strong>和<strong>死锁避免</strong>方案</p>
<ul>
<li><strong>死锁预防</strong>: <strong>确保至少有一个<a href="#7-2-1-%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6">必要条件</a>不成立</strong>。这些方法通过<strong>限制如何申请资源的方法来预防死锁</strong>。</li>
<li><strong>死锁避免</strong>: 要求操作系统<strong>事先得到有关进程申请资源和使用资源的额外信息</strong>。有了这些额外信息，系统可以确定：对于每个申请，进程是否应等待。为了<strong>确定当前申请是允许还是延迟</strong>，系统应考虑：现有的可用资源、已分配给每个进程的资源及每个进程将来将要申请和释放的资源。（可能导致新任务无法立刻进行，造成性能下降）</li>
</ul>
<p>如果系统<strong>不使用死锁预防或死锁避免算法</strong>，那么死锁情况可能发生。在这种情况下，系统<strong>可以提供一个算法来检查系统状态以确定死锁是否发生，提供另一个算法来从死锁中恢复</strong>。</p>
<p>不处理死锁会导致越来越多的进程进入死锁状态，导致性能下降。然而，由于死锁次数少，比起运用代价大的算法预防和恢复，还不如直接重启。</p>
<h3 id="7-4-死锁预防"><a href="#7-4-死锁预防" class="headerlink" title="7-4 死锁预防"></a>7-4 死锁预防</h3><h4 id="7-4-1-互斥"><a href="#7-4-1-互斥" class="headerlink" title="7-4-1 互斥"></a>7-4-1 互斥</h4><p><strong>互斥条件必须成立, 基本上是资源本身的属性，无法解决</strong>。也就是说，至少有一个资源应是非共享的。相反，可共享资源不要求互斥访问，因此不会参与死锁。</p>
<h4 id="7-4-2-持有并等待"><a href="#7-4-2-持有并等待" class="headerlink" title="7-4-2 持有并等待"></a>7-4-2 持有并等待</h4><p>为了确保持有并等待条件不会出现在系统中，应<strong>保证：当每个进程申请一个资源时，它不能占有其他资源</strong>。对此有两种协议来解决问题：</p>
<ol>
<li>每个<strong>进程在执行前申请并获得所有资源</strong>。这可以这样实现：要求进程<strong>申请资源的系统调用在所有其他系统调用之前进行</strong>。</li>
<li><strong>进程仅在没有资源时才可申请资源</strong>。一个进程可申请一些资源并使用它们。然而，在它<strong>申请更多其他资源之前</strong>，它应<strong>释放现已分配的所有资源</strong>。</li>
</ol>
<p>具体的例子为：</p>
<p>对于第一种协议，假设我们有一个进程，它将数据从DVD驱动器复制到磁盘文件，并对磁盘文件进行排序，再打印结果到打印机。如果所有资源应在进程开始之前申请，那么进程应一开始就申请DVD驱动器、磁盘文件和打印机。在它的整个执行过程中，它会一直占有打印机，尽管它只在结束时才需要打印机。</p>
<p>第二种方法允许：进程在开始时只申请DVD驱动器和磁盘文件。它将复制数据从DVD到磁盘，再释放DVD驱动器和磁盘文件。然后，进程应再申请磁盘文件和打印机。当复制数据从磁盘文件到打印机之后，它就释放这两个资源并终止。</p>
<p>但是，这两个协议有两个<strong>缺点</strong>：</p>
<ol>
<li><strong>资源利用率可能比较低，因为许多资源可能已分配，但是很长时间没有被使用</strong>。例如，在所给的例子中，只有确认数据始终存于磁盘文件的情况下，才可以释放DVD驱动器和磁盘文件，并再次申请磁盘文件和打印机资源。否则，不管采用哪种协议，应在开始之前申请所有资源。</li>
<li><strong>可能发生饥饿</strong>。一个进程如需要多个常用资源，可能必须永久等待，因为在<strong>它所需要的资源中至少有一个已分配给其他进程</strong>。</li>
</ol>
<h4 id="7-4-3-无抢占"><a href="#7-4-3-无抢占" class="headerlink" title="7-4-3 无抢占"></a>7-4-3 无抢占</h4><p>第三个必要条件是，不能抢占已分配的资源。为了<strong>确保这一条件不成立</strong>，可以采用如下协议：</p>
<p>如果一个<strong>进程持有资源并申请另一个不能立即分配的资源</strong>（也就是说，这个进程应等待），那么它<strong>现在分配的资源都可被抢占</strong>。换句话说，这些资源都<strong>被隐式释放</strong>了. <strong>被抢占资源添加到进程等待的资源列表上</strong>。只有当进程获得其原有资源和申请的新资源时，它才可以重新执行。(<strong>需要重新获取被抢占的资源</strong>)</p>
<p>换句话说，如果一个进程申请一些资源，那么<strong>首先检查它们是否可用</strong>。如果<strong>可用</strong>，那么就<strong>分配它们</strong>。如果<strong>不可用</strong>，那么<strong>检查这些资源是否已分配给等待额外资源的其他进程</strong>。如果<strong>是</strong>，那么<strong>从等待进程中抢占这些资源</strong>，并分配给申请进程。如果<strong>资源不可用且也不被其他等待进程持有</strong>，那么<strong>申请进程应等待</strong>。</p>
<p>这个协议通常用于状态可以保存和恢复的资源，如CPU寄存器和内存。它一般不适用于其他资源，如互斥锁和信号量。</p>
<h4 id="7-4-4-循环等待"><a href="#7-4-4-循环等待" class="headerlink" title="7-4-4 循环等待"></a>7-4-4 循环等待</h4><p>死锁的第四个也是最后一个条件是循环等待。<strong>确保这个条件不成立</strong>的一个方法是：对<strong>所有资源类型进行完全排序，而且要求每个进程按递增顺序来申请资源</strong>。</p>
<center> <img src="./osimg/排序解决循环等到.png"> </center>

<p>我们可以采用如下协议来预防死锁：每个<strong>进程只能按递增顺序申请资源</strong>。即一个进程开始可申请任何数量的资源类型Ri的实例。之后，当且仅当F(Rj)&gt;F(Ri)时，该进程才可以申请资源类型Rj的实例。</p>
<p>此外，当一个进程申请资源类型Rj时，它应先释放所有资源Ri(F(Ri) &gt; F(Rj)), 即<strong>申请序号更小的资源需要释放所有更高序号的资源</strong>。注意，如果<strong>需要同一资源类型的多个实例，那么应一起申请它们</strong>。</p>
<p>采取这种资源分配方案下，不可能出现循环等待资源的问题，可通过反证法得到。</p>
<p>因为每个进程 P[i+1] 都在占有R[i]的情况下希望获取R[i+1],因此，我们有</p>
<center> <img src="./osimg/F.png"> </center>

<p>但是不可能会有F(R0) &lt; F(R0), 所以这种情况不可能，因此无循环等待。总会有一个进程释放掉老资源，从而可以使得等待队列可以进行下去。</p>
<p>请记住, <strong>设计一个完全排序或层次结构本身不能防止死锁</strong>，而是要<strong>靠应用程序员来按顺序编写程序</strong>。另外，函数<strong>F应该根据系统内资源使用的正常顺序来定义</strong>。例如，由于磁带驱动器通常在打印机之前使用，所以定义F（磁带驱动器）&lt; F（打印机）较为合理。</p>
<h5 id="锁的动态获取导致的顺序失效"><a href="#锁的动态获取导致的顺序失效" class="headerlink" title="锁的动态获取导致的顺序失效"></a>锁的动态获取导致的顺序失效</h5><p>是要注意，如果<strong>能动态地获取锁</strong>那么<strong>制定一个加锁的顺序并不保证死锁预防</strong></p>
<p>假设我们有一个在两个账户之间转移资金的函数。为了防止竞争条件，每个账户都有一个相关的互斥锁，它可通过函数get_lock()来获得</p>
<p>若两个线程同时调用transaction(from, to, amount), 会可能导致死锁。</p>
<center> <img src="./osimg/动态获取锁.jpg"> </center>

<p>图中也给出了解决方案，即若不能同时获取到两个锁就退出，使得占有并等待条件失效。</p>
<h3 id="7-5-死锁避免"><a href="#7-5-死锁避免" class="headerlink" title="7-5 死锁避免"></a>7-5 死锁避免</h3><p><strong>死锁预防算法</strong>有副作用: <strong>设备使用率低和系统吞吐率低</strong>。</p>
<p><strong>避免死锁的另一种方法需要额外信息</strong>，即<strong>如何申请资源</strong>。例如，有一台磁带驱动器和一台打印机的系统可能需要知道：进程P将会先申请磁带驱动器，再申请打印机，最后释放这些资源；而进程Q将会先申请打印机，再申请磁带驱动器。在获悉每个进程的请求与释放的完整顺序之后，系统可以决定，在<strong>每次请求时进程是否应该等待以避免未来可能的死锁</strong>。针对每次申请要求，系统在做决定时<strong>考虑现有可用资源、现已分配给每个进程的资源和每个进程将来申请与释放的资源</strong>。</p>
<p>最简单的算法实现要求进程提交每种资源类型的最大资源使用量，以此作为先验来构造算法，确保不会死锁。</p>
<h4 id="7-5-1-安全状态"><a href="#7-5-1-安全状态" class="headerlink" title="7-5-1 安全状态"></a>7-5-1 安全状态</h4><p>如果系统能按一定顺序为每个进程分配资源（不超过它的最大需求），仍然避免死锁，那么系统的状态就是安全的（safe）。更为正式地说，只有存在一个<strong>安全序列</strong>（safe sequence），系统才处于安全状态。</p>
<p>进程序列&lt; P1，P2，···，Pn &gt;在当前分配状态下为安全序列是指：</p>
<ul>
<li>对于每个Pi，Pi<strong>仍然可以申请的资源数(还需要的)小于当前可用资源加上所有进程Pj（其中j &lt; i）所占有的资源</strong>. 资源<strong>即使不能立即可用，那么Pi可以等待直到所有Pj释放资源</strong>。当它们完成时，Pi可得到需要的所有资源</li>
</ul>
<p>若不存在这样的序列，则系统状态为<strong>非安全的</strong>。</p>
<h5 id="安全状态与死锁的关系"><a href="#安全状态与死锁的关系" class="headerlink" title="安全状态与死锁的关系"></a>安全状态与死锁的关系</h5><center> <img src="./osimg/安全状态与死锁的关系.png"> </center>

<p>通过安全状态的概念，我们可以定义避免算法，以便确保系统不会死锁。这个想法简单，即确保系统始终处于安全状态。最初，系统处于安全状态。当有<strong>进程申请一个可用资源时，系统应确定：这一资源申请是可以立即分配，还是应让进程等待</strong>。只有在分配后系统仍处于安全状态，才能允许申请。</p>
<p>采用这种方案，如果进程申请一个现已可用的资源，那么它<strong>可能仍然必须等待</strong>。因此，与<strong>没有采用死锁避免算法相比，这种情况下的资源使用率可能更低</strong>。</p>
<h4 id="7-5-2-资源分配图算法"><a href="#7-5-2-资源分配图算法" class="headerlink" title="7-5-2 资源分配图算法"></a>7-5-2 资源分配图算法</h4><p>我们向原始的<a href="#7-2-2-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE">资源分配图</a>中加入一条新的<strong>需求边</strong> Pi -&gt; Rj, 表示<strong>Pi在未来可能会需要Rj的资源</strong>，该边用虚线表示。</p>
<p><strong>当进程Pi申请Rj时，需求边Pi -&gt; Rj变为申请边，当Pi释放Rj时，分配边Rj -&gt; Pi 变成需求边</strong>。</p>
<p>请注意，系统资源的<strong>需求应事先说明</strong>。即当<strong>进程Pi开始执行时，所有需求边应先处于资源分配图内</strong>。</p>
<p>现在，假设<strong>进程Pi申请资源Rj</strong>。只有在<strong>将申请边Pi→Rj变成分配边Rj→Pi并且不会导致资源分配图形成环</strong>时，才能<strong>允许申请</strong>。通过采用环检测算法，检查安全性。检测图中是否有环的算法需要<strong>n²数量级的操作</strong>，其中n是系统的进程数量。</p>
<center> <img src="./osimg/资源分配图的状态.png"> </center>

<p><em>若没有环形成，则资源分配使得系统处于安全状态。如果有环形成，系统处于非安全状态，此时若每个资源实例只有一个，那么出现死锁，若有多个则不一定</em></p>
<h4 id="7-5-3-银行家算法"><a href="#7-5-3-银行家算法" class="headerlink" title="7-5-3 银行家算法"></a>7-5-3 银行家算法</h4><p>对于每种<strong>资源类型有多个实例的资源分配系统</strong>，资源<strong>分配图算法就不适用了</strong>。(资源分配图对于多个实例的资源无法精准判断死锁状态)</p>
<p>银行家算法适用于多个实例的资源分配，但是它的<strong>效率不如资源分配图方案</strong>。之所以如此命名是因为：这一算法可用于银行系统，以确保银行不会分配现金，以致它不再满足所有客户的需要。</p>
<p>实现它需要几个数据结构：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> N = <span class="number">1000</span>; <span class="comment">// 系统进程的数量</span></span><br><span class="line"><span class="type">int</span> M = <span class="number">100</span>; <span class="comment">// 系统资源的种类</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 每种资源的可用实例数量。如果</span></span><br><span class="line"><span class="comment">Available[j]=k，那么资源类型Rj有k个可用实例。 */</span></span><br><span class="line"><span class="type">int</span> Available[M]</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 每个进程的最大需求。如果</span></span><br><span class="line"><span class="comment">Max[i][j]=k，那么进程Pi最多可申请资源类型Rj的k个实例。 */</span></span><br><span class="line"><span class="type">int</span> Max[N][M];</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 每个进程现在分配的每种资源类型的实例数量。</span></span><br><span class="line"><span class="comment">如果Allocation[i][j]进程Pi现在已分配了资源类型Rj的k个实例。 */</span></span><br><span class="line"><span class="type">int</span> Allocation[N][M]</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 每个进程还需要的剩余资源。如果Need[i][j] = k,</span></span><br><span class="line"><span class="comment">那么Pi还可能再申请k个资源Rj */</span></span><br><span class="line"><span class="type">int</span> Need[N][M]; <span class="comment">// Need[i][j] = Max[i][j] - Allocation[i][j]</span></span><br></pre></td></tr></table></figure>

<p>以上的数据结构的值会随着时间更新。</p>
<p><strong>定义对于向量X，Y。 X &lt;&#x3D; Y 为 for each X[i] , we have X[i] &lt;&#x3D; Y[i]</strong></p>
<h5 id="7-5-3-1-安全算法"><a href="#7-5-3-1-安全算法" class="headerlink" title="7-5-3-1 安全算法"></a>7-5-3-1 安全算法</h5><p>确认<strong>系统是否处于安全状态的算法</strong>如下：</p>
<center> <img src="./osimg/安全算法.png"> </center>

<p>(其实第一步的初始化可以改为仅当Allocation[i] !&#x3D; 0才有Finish[i]&#x3D; true)</p>
<p>代码实现为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pair&lt;<span class="type">bool</span>,vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">is_safe</span>()&#123;</span><br><span class="line">  <span class="type">int</span> n = Allocation.<span class="built_in">size</span>(), m = Allocation[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">  vector&lt;<span class="type">int</span>&gt; work = Available;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">finish</span><span class="params">(n,<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">safe_seq</span><span class="params">(n)</span></span>;</span><br><span class="line">  <span class="type">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(cnt &lt; n)&#123;</span><br><span class="line">    <span class="type">bool</span> find_i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)&#123;</span><br><span class="line">      <span class="keyword">if</span>(!finish[i])&#123;</span><br><span class="line">        <span class="type">bool</span> ok = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt; m; ++j)&#123;</span><br><span class="line">          <span class="keyword">if</span>(Need[i][j] &gt; work[j])&#123;</span><br><span class="line">            ok = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(ok)&#123;</span><br><span class="line">          <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt; m; ++j)&#123;</span><br><span class="line">            work[j] += Allocation[i][j];</span><br><span class="line">            finish[i] = <span class="literal">true</span>;</span><br><span class="line">            safe_seq[cnt++] = i;</span><br><span class="line">            find_i = <span class="literal">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(!find_i) <span class="keyword">return</span> &#123;<span class="literal">false</span>,&#123;&#125;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> &#123;<span class="literal">true</span>,safe_seq&#125;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// O(m*n!) ???</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">safe_seq实现有误，正确的相当于判断有一个进程排列存在使得系统安全</span></span><br><span class="line"><span class="comment">使用next_permutaion()暴力判断O(m*n!)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">上面的说法有误，不需要全排列，对于第k轮，若Pi，Pj都可选，那么一定有Pi和Pj开始的有效序列。因此无需全排列，复杂度O(m*n^2)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h5 id="7-5-3-2-资源请求算法"><a href="#7-5-3-2-资源请求算法" class="headerlink" title="7-5-3-2 资源请求算法"></a>7-5-3-2 资源请求算法</h5><p>现在描述<strong>判断请求是否安全的算法</strong></p>
<center> <img src="./osimg/请求是否安全.png"> </center>

<p>如果新的资源分配状态是安全的，那么交易完成且进程Pi可分配到需要的资源。然而，如果新状态不安全，那么进程Pi应等待Request_i并恢复到原来的资源分配状态。</p>
<p>也就是说，在<strong>通过资源请求后也需要再次运行系统状态检查</strong>，若处于不安全状态则回调。(每次资源分配的是O(mn^2)的，开销太大了)</p>
<h5 id="7-5-3-3-说明示例"><a href="#7-5-3-3-说明示例" class="headerlink" title="7-5-3-3 说明示例"></a>7-5-3-3 说明示例</h5><p>P244</p>
<h3 id="7-6-死锁检测"><a href="#7-6-死锁检测" class="headerlink" title="7-6 死锁检测"></a>7-6 死锁检测</h3><h4 id="7-6-1-每种资源类型都只有单个实例"><a href="#7-6-1-每种资源类型都只有单个实例" class="headerlink" title="7-6-1 每种资源类型都只有单个实例"></a>7-6-1 每种资源类型都只有单个实例</h4><p>这种情况下的死锁检测算法可以用<strong>等待图</strong>，也就是资源分配图的变形解答</p>
<p><strong>等待图的创建</strong>仅需删除资源分配图每两个连通的进程节点中的资源节点，并直接连接两者得到</p>
<center> <img src="./osimg/资源分配图和等待图.jpg"> </center>

<p>更确切地说，<strong>等待图的从Pi到Pj的边意味</strong>着：<br><strong>进程Pi等待进程Pj释放一个Pi所需的资源</strong>。等待图有一条由Pi→Pj的边，当且仅当相应资源分配图包含两条边Pi→Rq。和Rq→Pj，其中Rq为资源. </p>
<h4 id="7-6-2-每种资源类型可有多个实例"><a href="#7-6-2-每种资源类型可有多个实例" class="headerlink" title="7-6-2 每种资源类型可有多个实例"></a>7-6-2 每种资源类型可有多个实例</h4><p><strong>等待图方案不适用于每种资源类型可有多个实例的资源分配系统</strong>。</p>
<p>下面描述的死锁检测算法适用于这样的系统。该算法使用了一些随时间而变化的数据结构, <strong>类似于银行家算法</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> N = <span class="number">1000</span>, M = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 各种资源的可用实例数量 */</span></span><br><span class="line"><span class="type">int</span> Available[M];</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 每个进程的每种资源的当前分配数量 */</span></span><br><span class="line"><span class="type">int</span> Allocation[N][M];</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 当前每个进程的每种资源的当前请求 */</span></span><br><span class="line"><span class="type">int</span> Request[N][M];</span><br></pre></td></tr></table></figure>

<center> <img src="./osimg/死锁检测.png" > </center>

<p>你可能不明白为什么只要确定Request_i ≤ Work（第2步中），就收回了进程Pi的资源（第3步）。已知Pi现在不参与死锁（因Request_i ≤ Work），因此，可以<strong>乐观地认为Pi不再需要更多资源以完成任务</strong>，它会返回现已分配的所有资源。如果这个<strong>假定不正确，那么稍后会发生死锁</strong>。<strong>下次调用死锁检测算法时，就会检测到死锁状态</strong>。</p>
<h4 id="7-6-3-应用检测算法"><a href="#7-6-3-应用检测算法" class="headerlink" title="7-6-3 应用检测算法"></a>7-6-3 应用检测算法</h4><p><strong>何时应该调用检测算法</strong>？答案取决于两个因素:</p>
<ul>
<li>死锁可能发生的频率</li>
<li>死锁发生时，有多少进程会受影响？</li>
</ul>
<p>如果经常发生死锁，就应经常调用检测算法。分配给死锁进程的资源会一直空着，直到死锁被打破。另外，参与死锁等待环的进程数量可能不断增加。</p>
<p>只有<strong>当某个进程提出请求且得不到满足时，才会出现死锁</strong>。这一请求可能是完成等待进程链的最后请求。</p>
<p>在极端情况下，即<strong>每次分配请求不能立即允许时，就调用死锁检测算法</strong>。在这种情况下，不仅<strong>能确定哪些进程死锁，而且能确定哪个特定进程“造成”了死锁</strong>。（而实际上，每个死锁进程都是资源图内环的一个链节，因此，所有进程一起造成了死锁。）如果有许多不同资源类型，那么一个请求可能形成资源图的多个环，每个环由最近请求所完成.</p>
<p>当然，对于<strong>每个请求都调用死锁检测算法将会引起相当的计算开销</strong>。另一个不太昂贵的方法只是每隔一定时间调用检测算法，如每小时一次，或当CPU使用率低于40%时。（死锁最终会使系统性能下降，并造成CPU使用率下降。）如果在<strong>任一时间点调用检测算法</strong>，那么资源图可能有多个环。通常<strong>不能确定哪个死锁进程“造成”了死锁</strong>。</p>
<h3 id="7-7-死锁恢复"><a href="#7-7-死锁恢复" class="headerlink" title="7-7 死锁恢复"></a>7-7 死锁恢复</h3><p>打破死锁有两个选择：</p>
<ol>
<li>简单地<strong>中止一个或多个进程</strong>来打破循环等待</li>
<li>从一个或多个死锁进程那里<strong>抢占</strong>一个或多个资源。</li>
</ol>
<h4 id="7-7-1-进程终止"><a href="#7-7-1-进程终止" class="headerlink" title="7-7-1 进程终止"></a>7-7-1 进程终止</h4><p>通过中止进程来消除死锁，有两种方法:</p>
<ol>
<li><strong>中止所有死锁进程</strong>: 这种方法显然会打破死锁环，但是代价也大。这些死锁进程可能已计算了较长时间；这些部分计算的结果也要放弃，并且以后可能还要重新计算</li>
<li><strong>一次中止一个进程</strong>，直到消除死锁循环为止。这种方法的<strong>开销会相当大</strong>，这是因为<strong>每次中止一个进程，都应调用死锁检测算法</strong>，以确定是否仍有进程处于死锁。</li>
</ol>
<p>终止一个进程并不简单。如果进程正在更新文件，那么终止它会使文件处于不正确的状态。类似地，如果进程正在打印数据，那么系统在打印下一个文件之前应将打印机重置到正确的状态。</p>
<p>如果采用了<strong>部分终止</strong>，那么我们应<strong>确定哪个（或哪些）死锁进程应该终止</strong>. 应该<strong>中止造成最小代价的进程</strong>。然而最小代价（minimum cost）并不精确。许多因素都可能影响选择哪个进程，包括：</p>
<ul>
<li>进程的优先级是什么？</li>
<li>进程已计算了多久？在完成指定任务之前还要计算多久？</li>
<li>进程使用了多少数量的何种类型的资源（例如，这些资源是否容易抢占）？</li>
<li>进程需要多少资源才能完成？</li>
<li>需要终止多少进程？</li>
<li>进程是交互的还是批处理的？</li>
</ul>
<h4 id="7-7-2-资源抢占"><a href="#7-7-2-资源抢占" class="headerlink" title="7-7-2 资源抢占"></a>7-7-2 资源抢占</h4><p>如果要求<strong>采用抢占来处理死锁</strong>，那么需要处理三个问题：</p>
<ol>
<li><strong>选择牺牲进程</strong>：与进程终止一样，应确定抢占的顺序，使得代价最小。代价因素可包括这样的参数，如死锁进程拥有的资源数量、死锁进程到现在为止所消耗的时间等。</li>
<li><strong>回滚</strong>：如果从一个进程那里抢占了一个资源，那么应对该进程做些什么安排？显然，该进程不能继续正常执行；它缺少所需的某些资源。我们应将该进程<strong>回滚到某个安全状态，以便从该状态重启进程</strong>。为一般来说，很难确定什么是安全状态，最简单的解决方案是完全回滚：中止进程并重新执行。然而，更为有效的方法是回滚进程直到足够打破死锁，但是这种方法要求系统维护有关运行进程的更多状态信息。</li>
<li><strong>饥饿</strong>：如果一个系统是基于代价来选择牺牲进程，那么<strong>同一进程可能总是被选为牺牲的。结果，这个进程永远不能完成指定任务</strong>，任何实际系统都需要处理这种饥饿情况。显然，应<strong>确保一个进程只能有限次数地被选为牺牲进程</strong>。最为常用的方法是<strong>在代价因素中加上回滚次数</strong>。</li>
</ol>
<h2 id="8-内存管理策略"><a href="#8-内存管理策略" class="headerlink" title="8 内存管理策略"></a>8 内存管理策略</h2><h3 id="8-1-背景"><a href="#8-1-背景" class="headerlink" title="8-1 背景"></a>8-1 背景</h3><p>内存是现代计算机运行的核心。内存由一个很大的<strong>字节数组来组成</strong>，每个字节都有<strong>各自的地址</strong>。CPU根据<strong>程序计数器的值从内存中提取</strong>指令，这些指令可能引起对特定内存地址的额外加载与存储。</p>
<p>一个典型的指令执行周期，首先从内存中读取指令。接着，该指令会被解码，也可能需要从内存中读取操作数。在指令对操作数执行后，它的结果可能存回到内存。内存单元<strong>只看到地址流</strong>，而并不知道这些地址是如何产生的。</p>
<h4 id="8-1-1-基本硬件"><a href="#8-1-1-基本硬件" class="headerlink" title="8-1-1 基本硬件"></a>8-1-1 基本硬件</h4><p>CPU可以<strong>直接访问</strong>的通用存储只有<strong>内存和处理器内置的寄存器</strong>。机器指令可以用内存地址作为参数，而不能用磁盘地址作为参数. 如果数据不在内存中，那么在<strong>CPU使用它们之前应先把数据移到内存</strong>。</p>
<p>CPU内<strong>置寄存器</strong>通常可以在<strong>一个CPU时钟周期内完成访问</strong>. 对于寄存器的内容，大多数CPU<strong>可以在一个时钟周期内解释并执行一条或多条指令</strong>. 但是内存需要通过总线通信，做不到这么快的访问和执行，内存的访问<strong>可能需要多个CPU时钟周期</strong>。 因此CPU需要<strong>暂停</strong>(stall)以等待来自内存的数据。这样的低效率可以通过<strong>添加位于CPU芯片上的高速缓存(cache)来缓解</strong>。</p>
<p>我们不仅<strong>关心访问物理内存的相对速度</strong>，而且还要<strong>确保操作的正确</strong>. 为了系统操作的正确，我们应<strong>保护操作系统不被用户进程访问</strong>。在<strong>多用户系统</strong>上，我们还应保护<strong>用户进程不会互相影响</strong>。这种保护应<strong>通过硬件来实现</strong>，因为操作系统通常不干预CPU对内存的访问（由于导致性能损失）。</p>
<h5 id="通过基地址和界限地址的实现"><a href="#通过基地址和界限地址的实现" class="headerlink" title="通过基地址和界限地址的实现"></a>通过基地址和界限地址的实现</h5><p>我们需要<strong>确保每个进程都有自己独立的内存空间</strong>。我们可以限制进程可访问的内存空间的范围。采用<strong>基地址寄存器和界限地址寄存器</strong>，我们分别记录了进程的<strong>最小的合法物理内存地址</strong>以及<strong>访问范围的大小</strong>。入下图所示</p>
<center> <img src="./osimg/基地址.png" > </center>

<p>图示的地址范围包括[300040, 420939], 注意不包含420940</p>
<p><strong>内存空间保护</strong>的实现是通过CPU硬件<strong>对在用户模式下产生的地址与寄存器的地址进行比较来完成的</strong>。当在<strong>用户模式</strong>下执行的程序试图<strong>访问操作系统内存或其他用户内存时</strong>，会陷入操作系统，而操作系统则将它作为<strong>致命错误</strong>来处理。</p>
<center> <img src="./osimg/及地址内存保护.png" > </center>

<p><strong>只有操作系统</strong>可以通过特殊的<strong>特权指令</strong>，才能<strong>加载基地址寄存器和界限地址寄存器</strong>。由于特权指令只能在<strong>内核模式</strong>下执行，而只有操作系统才能在内核模式下执行，所以<strong>只有操作系统</strong>可以加载基地址寄存器和界限地址寄存器。这种方案<strong>允许操作系统修改这两个寄存器</strong>的值，而不允许用户程序修改它们。</p>
<p>在内核模式下执行的<strong>操作系统可以无限制地访问操作系统及用户的内存</strong>. 像加载用户程序到内存，错误的转储，修该系统调用的参数以及上下文切换中的寄存器状态保存都是在访问内存的条件下进行的。</p>
<h4 id="8-1-2-地址绑定"><a href="#8-1-2-地址绑定" class="headerlink" title="8-1-2 地址绑定"></a>8-1-2 地址绑定</h4><p>在磁盘上<strong>等待调到内存</strong>以便执行的进程形成了<strong>输入队列</strong>（input queue）。</p>
<p>正常的单任务处理过程是：从输入队列中选取一个进程并加载到内存；进程在执行时，会访问内存的指令和数据；最后，进程终止时，它的内存空间将会释放。</p>
<p>大多数系统允许用户进程放在物理内存中的任意位置。因此，虽然计算机的地址空间从00000开始，但用户进程的开始地址不必也是00000.</p>
<p>在大多数情况下，用户程序在执行前，需要经过好几个步骤，其中有的是可选的（参见图8-3）。在这些步骤中, <strong>地址可能会有不同表示形式</strong>。源程序中的地址通常是用<strong>符号表示</strong>(如变量count**)编译器通常将这些符号地址绑定（bind）到可重定位的地址**（如“从本模块开始的第14字节”）. <strong>链接程序或加载程序再将这些可重定位的地址绑定到绝对地址</strong>（如74014）。每次绑定都是从一个地址空间到另一个地址空间的映射.</p>
<center> <img src="./osimg/8-3.png" > </center>

<p>通常，指令和数据<strong>绑定到存储器地址可在沿途的任何一步中进行</strong>：</p>
<ul>
<li><strong>编译时</strong>（compile time）：如果在<strong>编译时就已知道进程将在内存中的驻留地址</strong>，那么就可以生成<strong>绝对代码</strong>（absolute code）。例如，如果事先就知道用户进程驻留在内存地址R处，那么生成的编译代码就可以从该位置开始并向后延伸. 如果<strong>将来开始地址发生变化，那么就有必要重新编译代码</strong>。</li>
<li><strong>加载时</strong>（load time）：如果在<strong>编译时并不知道进程将驻留在何处</strong>，那么编译器就应生成<strong>可重定位代码</strong>（relocatable code）。对这种情况，最后<strong>绑定会延迟到加载时</strong>才进行。如果<strong>开始地址发生变化，那么只需重新加载用户代码以合并更改的值</strong>。</li>
<li><strong>执行时</strong>（runtime time）：如果进程在<strong>执行时可以从一个内存段移到另一个内存段</strong>，那么<strong>绑定应延迟到执行时才进行</strong>。这种方案<strong>需要特定硬件设备</strong>，大多数操作系统采用这种方法。</li>
</ul>
<h4 id="8-1-3-逻辑地址空间和物理地址空间"><a href="#8-1-3-逻辑地址空间和物理地址空间" class="headerlink" title="8-1-3 逻辑地址空间和物理地址空间"></a>8-1-3 逻辑地址空间和物理地址空间</h4><p><strong>CPU生成的地址</strong>通常称为<strong>逻辑地址</strong>（1ogical address），而<strong>内存单元看到的地址</strong>（即加载到内存地址寄存器（memory-address register）的地址）通常称为<strong>物理地址</strong>（physical address）。</p>
<p><strong>编译时和加载时的地址绑定方法生成相同的逻辑地址和物理地址</strong>。然而, <strong>执行时</strong>的地址绑定方案<strong>生成不同的逻辑地址和物理地址</strong>，因为程序运行时在内存中的地址会移动，因此逻辑地址和物理地址不是一对一的。在这种情况下，我们通常称逻辑地址为<strong>虚拟地址</strong>（virtual address）.</p>
<ul>
<li><strong>逻辑地址空间</strong>（logical address space）为程序所生成的<strong>所有逻辑地址的集合</strong>. </li>
<li><strong>物理地址空间</strong>（physical address space）为<strong>逻辑地址对应的所有物理地址的集合</strong></li>
</ul>
<p>虚拟地址到物理地址的<strong>运行时映射</strong>是由<strong>内存管理单元</strong>（Memory-Management Unit，MMU）的<strong>硬件设备</strong>来完成。其运行方式及入图，这里<strong>重定位寄存器为基地址寄存器</strong>。</p>
<center> <img src="./osimg/动态重定位.png" > </center>

<p>用户程序不会看到真实的物理地址，它只是用指向位置346的指针对实际位置为14000+346的内存单元进行操作。</p>
<p><strong>用户程序只生成逻辑地址</strong>，这些地址实际使用前需要映射到物理地址。</p>
<h4 id="8-1-4-动态加载"><a href="#8-1-4-动态加载" class="headerlink" title="8-1-4 动态加载"></a>8-1-4 动态加载</h4><p>虽然叫“加载”，但其实不在加载时，是在程序运行时继续向其中添加内容。</p>
<p><strong>动态加载</strong>可以得到更好的内存利用率。采用动态加载时, <strong>程序只有在调用时才会加载</strong>。所有程序都<strong>以可重定位加载格式保存</strong>在磁盘上。主程序被加载到内存，并执行。当一个程序需要调用另一个程序时，<strong>调用程序首先检查另一个程序是否已加载</strong>。如果没有, <strong>可重定位链接程序</strong>会加载所需的程序到内存，并<strong>更新程序的地址表</strong>以反映这一变化。接着，控制传递给新加载的程序。</p>
<p>动态加载的优点时程序仅在需要时被加载，可以大大减少那些使用频率低的程序对内存的占用，如错误处理程序。此外, <strong>动态加载不需要操作系统提供特别支持</strong></p>
<h4 id="8-1-5-动态链接和共享库"><a href="#8-1-5-动态链接和共享库" class="headerlink" title="8-1-5 动态链接和共享库"></a>8-1-5 动态链接和共享库</h4><p><strong>动态链接库</strong>（dynamically linked library, dll）为<strong>系统库</strong>，可链接到用户程序，以便运行. </p>
<p>有的操作系统只支持<strong>静态链接</strong>（static linking），它的<strong>系统库与其他目标模块一样，通过加载程序，被合并到二进制程序映像</strong>。</p>
<p><strong>动态链接类似于动态加载</strong>。这里，不是加载而是<strong>链接</strong>，会<strong>延迟到运行时</strong>。这种功能通常用于系统库，如语言的子程序库。没有这种功能，系统内的所有程序都需要一份语言库的副本（或至少那些被程序所引用的子程序）。这种要求浪费了磁盘空间和内存空间。</p>
<p>如果<strong>有动态链接</strong>，在<strong>二进制映像内</strong>(保存在磁盘上的已经编译完成的程序)，每个<strong>库程序的引用</strong>都有一个<strong>存根</strong>（stub）。</p>
<p><strong>存根是一小段代码</strong>，用来<strong>指出如何定位适当的内存驻留库程序</strong>，或者<strong>在程序不在内存内时应如何加载库</strong>。当执行存根时，它首先检查所需程序是否已在内存中。如果不在，就将程序加到内存。不管如何，存根<strong>会用程序地址来替换自己，并开始执行程序</strong>。因此，下次<strong>再执行该程序代码时，就可以直接进行，而不会因动态链接产生任何开销</strong>。采用这种方案，使用语言库的<strong>所有进程只需要一个库代码副本</strong>就可以了。</p>
<p><strong>动态链接</strong>也可<strong>用于库的更新</strong>（如修改bug）。一个库可以被新的版本所替代，而且使用该库的所有程序会自动使用新的版本. </p>
<p><strong>没有动态链接</strong>，所有这些程序<strong>应当重新链接以便访问新的库</strong>。为了不让程序意外执行新的、不兼容版本的库，版本信息包括在程序和库中。一个库的多个版本可以都加载到内存, <strong>程序将通过版本信息来确定使用哪个库的副本</strong>. 只有采用新库编译的程序才会受新库的不兼容改动的影响。在新库安装之前链接的其他程序将继续使用较旧的库。这种系统也称为<strong>共享库</strong>（shared library）。</p>
<p>与动态加载不同，动态链接通常<strong>需要操作系统的帮助</strong>。如果内存中的进程是彼此保护的，那么<strong>只有操作系统才可以检查所需程序是否在某个进程的内存空间内，或是允许多个进程访问同样的内存地址</strong>. </p>
<h3 id="8-2-交换"><a href="#8-2-交换" class="headerlink" title="8-2 交换"></a>8-2 交换</h3><p>进程必须在内存中以便执行。不过，进程可以<strong>暂时从内存交换（swap）到备份存储（backing store）</strong>，当再次执行时再调回到内存中（图8-5）。交换有<strong>可能让所有进程的总的物理地址空间超过真实系统的物理地址空间</strong>从而<strong>增加了系统的多道程序程度</strong>.</p>
<center> <img src="./osimg/交换.png"> </center>

<h4 id="8-2-1-标准交换"><a href="#8-2-1-标准交换" class="headerlink" title="8-2-1 标准交换"></a>8-2-1 标准交换</h4><p>标准交换在<strong>内存与备份存储之间移动进程</strong>。备份存储通常是快速磁盘。他应该足够大到容纳所有用户进程的内存映像副本，且提供对这些副本的直接访问。</p>
<p>系统维护一个<strong>可运行的所有进程的就绪队列</strong>（ready queue），它们的<strong>映像在备份存储或内存中</strong>。当CPU<strong>调度器决定要执行一个进程</strong>时，它<strong>调用分派器</strong>。分派器<strong>检查队列中的下一个进程是否在内存中</strong>。如果<strong>不在，并且没有空闲内存区域</strong>，那么分派器会<strong>换出</strong>（swap out）当前位于内存中的一个进程，并<strong>换入</strong>（swap in）所需进程。然后, <strong>重新加载寄存器，并且将控制权转移到所选进程</strong>。</p>
<p>这种交换系统的<strong>上下文切换时间相当高</strong>，且<strong>交换时间主要</strong>来自备份储存的<strong>传输时间</strong>。对于100MB的进程，假设磁盘传输为50MB&#x2F;s，那么需要两秒来载入程序到内存。</p>
<p>显然，知道一个用户进程真正需要的内存空间而不是可能需要的内存空间，是非常有用的。因此，只需要<strong>交换真正使用的内存，就可以减少交换时间</strong>。为有效使用这种方法，用户需要<strong>告诉系统它的内存需求情况</strong>。因此，具有<strong>动态内存需求的进程</strong>需要通过系统调用（request_memory（）和releasememory（））来通知操作系统它的内存需求变化情况。</p>
<p>交换也受到其他因素的约束。如果我们<strong>想要换出一个进程，那么应确保该进程是完全处于空闲的</strong>。特别关注的是任何等待I&#x2F;O。当需要换出一个进程以释放内存时，该进程可能正在等待I&#x2F;O操作。然而，如果<strong>I&#x2F;O异步访问用户内存的I&#x2F;O缓冲区，那么该进程就不能换出</strong>。换入的进程可能会被原始进程的I&#x2F;O修改影响。</p>
<p>解决方案有：</p>
<ul>
<li>不能换出等待处理I&#x2F;O的进程</li>
<li>I&#x2F;O操作的执行<strong>只能使用操作系统的缓冲</strong>。只有在进程<strong>换入时</strong>，操作系统缓冲与进程内存之间<strong>才能进行数据转移</strong>(之前的进程处于换出状态，不会有I&#x2F;O)。这种<strong>双缓冲</strong>增加了复制次数，加大了开销。</li>
</ul>
<p>现代操作系统<strong>不会使用标准交换</strong>，因为其交换时间太长。大多使用其变种。</p>
<h4 id="8-2-2-移动系统的交换"><a href="#8-2-2-移动系统的交换" class="headerlink" title="8-2-2 移动系统的交换"></a>8-2-2 移动系统的交换</h4><p>移动系统通常<strong>不支持任何形式的交换</strong>。移动设备通常采用<strong>闪存</strong>，而不是空间更大的硬盘作为它的永久存储.</p>
<p>当空闲内存降低到一定值以下时，苹果的iOS，不是采用交换，而是要求应用程序<strong>自愿放弃分配的内存</strong>. 只读数据（如代码）可从系统中删除，以后如有必要再从闪存重新加载。已<strong>修改的数据（如堆栈）不会被删除</strong>。操作系统可以终止任何未能释放足够内存的应用程序。</p>
<p>Android不支持交换，而采用类似iOS使用的策略。如果没有足够可用的空闲内存，则它可以终止进程。然而，在<strong>终止进程之</strong>前，Android将其<strong>应用程序状态（application state）写到闪存，以便它能快速重新启动</strong>。</p>
<p>iOS和Android支持分页</p>
<h3 id="8-3-连续内存分配"><a href="#8-3-连续内存分配" class="headerlink" title="8-3 连续内存分配"></a>8-3 连续内存分配</h3><p>内存通常分为两个区域：一个用于<strong>驻留操作系统</strong>，另一个<strong>用于用户进程</strong>。操作系统可以放在低内存，也可放在高内存。影响这一决定的主要因素是中断向量的位置. <strong>由于中断向量通常位于低内存，因此程序员通常将操作系统也放在低内存</strong>。</p>
<p>采用<strong>连续内存分配</strong>（contiguous memory allocation）时，每个进程位于一个<strong>连续的内存区域</strong>，与包含<strong>下一个进程的内存相连</strong>。</p>
<h4 id="8-3-1-内存保护"><a href="#8-3-1-内存保护" class="headerlink" title="8-3-1 内存保护"></a>8-3-1 内存保护</h4><p>在有<strong>重定位寄存器和界限寄存器的情况下</strong>，我们可以防止进程访问不属于他的内存。若CPU生成的逻辑地址大于界限寄存器的值，那么为非法访问。MMU动态的将逻辑地址加上界限寄存器的值来得到物理地址。</p>
<center> <img src="./osimg/8-6.png" > </center>

<p>当CPU调度器选择一个进程来执行时，作为<strong>上下文切换工作的一部分，分派器会用正确的值来加载重定位寄存器和界限寄存器</strong>。这保证了内存访问的安全。</p>
<p><strong>重定位寄存器</strong>方案提供了一种有效方式，以便<strong>允许操作系统动态改变大小</strong>。许多情况都需要这一灵活性。例如，操作系统的驱动程序需要代码和缓冲空间。如果一个驱动程序（或其他操作系统的服务）不常使用，可以不必在内存中保留它的代码和数据，这部分空间可以用于其他目的。这类代码有时称为<strong>暂时</strong>（transient）的操作系统代码；它们<strong>根据需要再调入或调出</strong>。因此，使用这种代码可以<strong>在程序执行时动态改变操作系统的大小</strong>。</p>
<h4 id="8-3-2-内存分配"><a href="#8-3-2-内存分配" class="headerlink" title="8-3-2 内存分配"></a>8-3-2 内存分配</h4><p>最简单的内存分配方法之一是<strong>将内存分为多个固定大小的分区</strong>，这种方式的内存分配限制了程序多道程度，因为<strong>每个分区只允许一个进程</strong>。</p>
<p>对于<strong>可变分区</strong>方案，操作系统有一个<strong>表</strong>，用于<strong>记录哪些内存可用和哪些内存已用</strong>。开始，所有内存都可用于用户进程，因此可以作为一大块的<strong>可用内存</strong>，称为<strong>孔</strong>（hole）。最后，正如将会看到的，内存有一个集合，以包含各种大小的孔。</p>
<p><strong>任何时候，都有一个可用块大小的列表和一个输入队列</strong>。操作系统根据调度算法来对输入队列进行排序。内存不断地分配给进程，直到下一个进程的<strong>内存需求不能满足</strong>为止，这时没有足够大的可用块（或孔）来加载进程。操作系统<strong>可以等到有足够大的空间，或者可以往下扫描输入队列，以确定是否有其他内存需求较小的进程可以被满足</strong>。</p>
<p>通常，如上所述，可用的内存块为分散在内存里的不同大小的孔的集合。当<strong>新进程需要内存时，系统为该进程查找足够大的孔</strong>。如果<strong>孔太大</strong>，那么就<strong>分为两块：一块分配给新进程，另一块还回到孔集合</strong>。当进程<strong>终止</strong>时，它将释放内存，该<strong>内存将还给孔的集合</strong>。如果新孔与其他孔<strong>相邻，那么将这些孔合并成大孔</strong>。这时，系统可以检查：是否有进程在等待内存空间，以及新合并的内存空间是否满足等待进程等。</p>
<p>这种方法是通用<strong>动态存储分配问题</strong>, 它有以下常用选择方法：</p>
<ul>
<li><strong>首次适应</strong>：分配<strong>首个足够大的孔</strong>。查找可以从头开始，也可以从上次首次适应结束时开始。一旦找到足够大的空闲孔，就可以停止。</li>
<li><strong>最优适应</strong>：分配最小的足够大的孔。应查找整个列表，除非列表按大小排序。这种方法可以产生<strong>最小剩余孔</strong>。</li>
<li><strong>最差适应</strong>：分配最大的孔。同样，应查找整个列表，除非列表按大小排序。这种方法可以产生<strong>最大剩余孔</strong>，该孔可能比最优适应产生的较小剩余孔更为适用。</li>
</ul>
<p>模拟结果显示，首次适应和最优适应在执行时间和利用空间方面都好于最差适应。首次适应和最优适应在利用空间方面难分伯仲，但是首次适应要更快些。</p>
<h4 id="8-3-3-碎片"><a href="#8-3-3-碎片" class="headerlink" title="8-3-3 碎片"></a>8-3-3 碎片</h4><p>用于内存分配的<strong>首次适应和最优适应算法</strong>都有<strong>外部碎片</strong>（external fragmentation）的问题。随着进程加载到内存和从内存退出，空闲内存空间被<strong>分为小的片段</strong>。当总的<strong>可用内存之和可以满足请求但并不连续时，这就出现了外部碎片问题：存储被分成了大量的小孔</strong>.</p>
<p>根据内存空间总的大小和平均进程大小的不同，外部碎片问题或许次要或许重要。例如，采用首次适应方法的统计说明，不管使用什么优化，假定有N个可分配块，那么可能有0.5N个块为外部碎片。即1&#x2F;2的内存可能不能使用。这一特性称为<strong>50%规则</strong>(50-percent rule)。</p>
<p>内存碎片可以是内部的，也可以是外部的。假设有一个18464字节大小的孔，并采用多分区分配方案。假设有一个进程需要18462字节。如果只能分配所要求的块，那么还剩下一个2字节的孔。维护这一小孔的开销要比孔本身大很多。因此，通常按<strong>固定大小的块为单位（而不是字节）来分配内存</strong>。采用这种方案, <strong>进程所分配的内存可能比所需的要大</strong>。这两个数字之差称为<strong>内部碎片</strong>（internal fragmentation），这部分内存在分区内部，但又不能用。</p>
<p>外部碎片的解决有两种：</p>
<ul>
<li><strong>紧缩</strong>（compaction）。它的目的是<strong>移动内存内容，以便将所有空闲空间合并成一整块</strong>。然而，紧缩<strong>并非总是可能的</strong>。如果重定位是静态的，并且在汇编时或加载时进行的，那么就不能紧缩。只有<strong>重定位是动态的，并且在运行时进行的，才可采用紧缩</strong>。移动程序和数据，然后再<strong>根据新基地址的值来改变基地址寄存器</strong>。不过数据的移动会带来一定的开销。</li>
<li>允许进程的逻辑地址空间是<strong>不连续</strong>的. 这样，只要有物理内存可用，就允许为进程分配内存。有两种互补的技术可以实现这个解决方案：<strong>分段</strong>（8.4节）和<strong>分页</strong>（8.5节）。这两个技术也可以组合起来。</li>
</ul>
<h3 id="8-4-分段"><a href="#8-4-分段" class="headerlink" title="8-4 分段"></a>8-4 分段</h3><p>分段允许进程的物理地址是<strong>不连续</strong>的，但段内地址连续。<br>分段<strong>没有避免外部碎片和紧缩</strong></p>
<h4 id="8-4-1-基本方法"><a href="#8-4-1-基本方法" class="headerlink" title="8-4-1 基本方法"></a>8-4-1 基本方法</h4><p>比起将内存视为1维数组，程序员更倾向于将内存视为一组不同长度的段。一个程序的代码和数据可以按类保存在不同的段中，而程序员并不在乎这些段是怎么在内存中分布的。这些段的长度是不同的，其长度是由这些段在程序中的目的决定的。段内的元素是通过它们距段首的偏移来指定.</p>
<p><strong>分段</strong>（segmentation）就是支持这种用户视图的内存管理方案。逻辑地址空间是由一组段构成。每个<strong>段都有名称和长度</strong>。地址指定了段名称和段内偏移。因此<strong>用户通过两个量来指定地址：段名称和段偏移</strong>。</p>
<p>为了实现简单起见，段是<strong>编号的</strong>，是通过段号而不是段名称来引用。因此，逻辑地址由有序对（two tuple）组成：</p>
<center> <p> （段号，偏移） </p> </center>

<p>通常，在编译用户程序时, <strong>编译器会根据输入程序来自动构造段</strong>。、<br>一个C编译器可能会创建如下段：</p>
<ul>
<li>代码</li>
<li>全局变量</li>
<li>堆 (内存从堆上分配)</li>
<li>每个线程使用的栈</li>
<li>标准的C库</li>
</ul>
<p>在编译时链接的库可能分配不同的段。加载程序会装入所有这些段，并为它们分配段号。</p>
<h4 id="8-4-2-分段硬件"><a href="#8-4-2-分段硬件" class="headerlink" title="8-4-2 分段硬件"></a>8-4-2 分段硬件</h4><p>虽然用户现在能够通过二维地址来引用程序内的对象，但是实际物理内存仍然是维的字节序列。因此，我们应定义一个实现方式，以便映<strong>射用户定义的二维地址到一维物理地址</strong>。这个地址是通过<strong>段表</strong>（segment table）来实现的。段表的<strong>每个条目都有段基地址</strong>（segment base）和<strong>段界限</strong>（segment limit）。段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度。</p>
<p>段表的使用如图所示：每个<strong>逻辑地址由段号s和段偏移d组成</strong>。 通过检测段偏移d是否小于段界限来判定是否非法访问</p>
<center> <img src="./osimg/分段例子.png"> </center>

<h3 id="8-5-分页"><a href="#8-5-分页" class="headerlink" title="8-5 分页"></a>8-5 分页</h3><p>分页和分段一样允许进程的物理地址是不连续的，但<strong>分页避免了外部碎片和紧缩</strong>，也<strong>避免了也避免了将不同大小的内存块匹配到交换空间的麻烦问题</strong>. 问题出现的原因是：当位于内存的代码和数据段<strong>需要换出</strong>时，应<strong>在备份存储上找到空间</strong>。备份<strong>存储也有同样的与内存相关的碎片问题，但是访问更慢</strong>，因此紧缩是不可能的. 分页<strong>需要操作系统和计算机硬件的协作</strong>。</p>
<h4 id="8-5-1-基本方法"><a href="#8-5-1-基本方法" class="headerlink" title="8-5-1 基本方法"></a>8-5-1 基本方法</h4><p>实现分页的<strong>基本方法涉及将物理内存分为固定大小的块</strong>，称为<strong>帧或页帧</strong>（frame）；而将<strong>逻辑内存也分为同样大小的块</strong>，称为<strong>页或页面</strong>（page）。当需要执行一个进程时，它的页从文件系统或备份存储等源处，加载到内存的可用帧。</p>
<p><strong>备份存储也划分为固定大小的块</strong>，它与单个内存帧或与多个内存帧（簇）的大小一样。（大小为内存帧的倍数）</p>
<p>分页的硬件支持如图8-10所示。由C<strong>PU生成的每个地址分为两部分：页码（page number）（p）和页偏移（page offset）（d）</strong>。</p>
<p>页码作为页表的<strong>索引</strong>。页表<strong>包含每页所在物理内存的基地址</strong>。这个基地址与页偏移的组合就形成了物理内存地址，可发送到物理单元。</p>
<p><strong>帧码</strong>作为对应页的帧的编号，一个帧内可有多个字节，帧的大小与页面相同。</p>
<center> <img src="./osimg/分页.png"> </center>

<p>页大小（与帧大小一样）是由硬件来决定的。页的大小为2的幂；<br>如果逻辑地址空间为2^m ，且页大小为2^n字节，那么逻<strong>辑地址的高m-n位表示页码</strong>，而<strong>低n位表示页偏移</strong>。这样，逻辑地址就如下图所示：</p>
<center> <img src="./osimg/分页逻辑地址.png"> </center>

<p>p为页码，d为页偏移</p>
<h5 id="分页例子"><a href="#分页例子" class="headerlink" title="分页例子"></a>分页例子</h5><p>举一个具体（虽说很小）的例子，假设如图8-12所示的内存。这里，逻辑的地址的n为2，m为4。采用大小为4字节而物理内存为32字节（8页），我们说明程序员的内存视图如何映射到物理内存。逻辑地址0的页码为0，页偏移为0。根据页表，可以查到页码0对应帧5，因此逻辑地址0映射到物理地址20[&#x3D;（5×4）+0]。逻辑地址3（页码为0，页偏移为3）映射到物理地址23[&#x3D;（5×4）+3]。逻辑地址4的页码为1，页偏移为0；根据页表，页码1对应为帧6。因此，逻辑地址4映射到物理地址24[&#x3D;（6×4)+0]。逻辑地址13映射到物理地址9。</p>
<center> <img src="./osimg/分页例子.png"> </center>

<p>分页本身是一种<strong>动态的重定位</strong>. 采用分页类似于采用一组基址（重定位）寄存器，每个基址对应着一个内存帧。不过动态定位由页表实现，对于进程本身地址空间并未变动。</p>
<p>分页<strong>没有外部碎片</strong>，因为每个空闲帧都能被分配（只要分块分配就没有外部碎片）。但是<strong>存在内部碎片</strong>。若进程所需的内存不是页面大小的整数倍，那么最后一个页面有内存被浪费。最坏情况下最后的页只有一个字节，且其他的空间不能被使用。</p>
<p>页面大小的选择要考虑很多，小的页面能带来更小的平均内部碎片，但是会增加页表的大小，而且大的页表在I&#x2F;O时更有效。一般页面大小为4KB~8KB，现在也有8MB的页面。</p>
<p>通常，对于<strong>32位的CPU</strong>，每个<strong>页表条目是4字节长的</strong>，但是这个大小也可能改变(分层页表)。一个<strong>32位的条目可以指向2^32 个物理帧中的任一个</strong>。如果帧为4KB（2²），那么具有4字节条目的系统可以访问2^44 字节大小（或16TB）的物理内存。这里我们应该注意到，分页内存系统的物理内存的大小不同于进程的最大逻辑大小。当<strong>进一步探索分页时，我们将引入其他的信息，这个信息应保存在页表条目中。该信息也减少了可用于帧地址的位数</strong>。因此，一个具有32位页表条目的系统可访问的物理内存<strong>可能小于最大值</strong>。32位CPU采用32位地址，意味着，一个进程的空间只能为2^32 字节（4GB）。因此，分页<strong>允许我们使用的物理内存大于CPU地址指针可访问的空间</strong>。</p>
<p>当系统进程需要执行时，它将检查该进程的大小（按页来计算），进程的每页都需要一帧。因此，如果进程需要n页，那么内存中至少应有n个帧。如果有，那么就可分配给新进程。进程的<strong>第一页装入一个已分配的帧，帧码放入进程的页表中</strong>。下一页分配给另一帧，其<strong>帧码也放入进程的页表中</strong>，等等（图8-13）。</p>
<center> <img src="./osimg/分页帧分配.png"> </center>

<p>有了页表，进程就无法访问不存在于也表内的帧，保证了内存访问安全。</p>
<p>由于操作系统管理物理内存，它应知道物理内存的分配细节：<strong>哪些帧已分配，哪些帧空着，总共有多少帧，等等。这些信息通常保存在称为帧表</strong>（frame table）的数据结构中。在<strong>帧表中，每个条目对应着一个帧，以表示该帧是空闲还是已占用</strong>；如果占用，是<strong>被哪个（或哪些）进程的哪个页所占用</strong>。</p>
<p>操作系统<strong>为每个进程维护一个页表的副本</strong>，就如同它需要维护指令计数器和寄存器的内容一样。每当操作系统自己将逻辑地址映射成物理地址时，这个副本可用作转换。当一个进程可分配到CPU时，CPU分派器也根据该副本来定义硬件页表。因此, <strong>分页增加了上下文切换的时间</strong>。</p>
<h4 id="8-5-2-硬件支持"><a href="#8-5-2-硬件支持" class="headerlink" title="8-5-2 硬件支持"></a>8-5-2 硬件支持</h4><p>操作系统<strong>保存页表的方法</strong>各异，有的为<strong>每个进程分配一个页表</strong>。<strong>页表的指针，与其他寄存器的值（如指令计数器），一起存入进程控制块PCB</strong>。当分派器需要启动一个进程时，它应首先加载<strong>用户寄存器</strong>，并根据保存的<strong>用户页表</strong>来定义正确的<strong>硬件页表值</strong>。其他操作系统<strong>提供一个或多个页表</strong>，以便减少进程的<strong>上下文切换的开销</strong>。</p>
<p>页表的<strong>硬件实现</strong>有多种方法。最为简单的一种方法是，将页表<strong>作为一组专用的寄存器</strong>来实现。CPU<strong>分派器</strong>在加载其他寄存器时，也需要<strong>加载这些寄存器</strong>。当然, <strong>加载或修改页表寄存器的指令是特权的，因此只有操作系统才可以修改内存映射表</strong>。具有这种结构的一个例子是DECPDP-11。它的地址有16位，而页面大小为8KB(2^13 )。因此页表有8(2^3 )个条目，可放在快速寄存器中。</p>
<p>如果<strong>页表比较小</strong>（例如256个条目），那么页表使用<strong>寄存器还是令人满意的</strong>。但是，大多数现代计算机都允许<strong>页表非常大</strong>（例如100万个条目）。对于这些机器，采用<strong>快速寄存器来实现页表就不可行</strong>了。因而需要将页表<strong>放在内存</strong>中，并将<strong>页表基地址寄存器</strong>（Page-Table Base Register，PTBR）<strong>指向页表</strong>。改变页表只需要改变这一寄存器就可以，这也大大<strong>降低了上下文切换</strong>的时间。</p>
<p>使用页表基地址寄存器PTBR也存在小问题，如果需要访问位置i，那么应首先利用PTBR的值，再加上i的页码作为偏移，来查找页表。这一任务需要内存访问。根据所得的帧码，再加上页偏移，就得到了真实物理地址。接着就可以访问内存内的所需位置。采用这种方案, <strong>访问一个字节需要两次内存访问</strong>（一次用于页表条目，一次用于字节, 不使用TLB的话，这是页表必须承担的开销）。大多数情况下，这种延迟是无法忍受的。我们还不如采用交换机制！</p>
<p>这个问题的<strong>标准解决方案是采用专用的、小的、查找快速的高速硬件缓冲</strong>，它称为<strong>转换表缓冲区</strong>（Translation Look-aside Buffer，TLB）。TLB是<strong>关联的高速内存</strong>。TLB条目由<strong>两部分组成：键（标签）和值</strong>。当关联内存根据给定值查找时，它会<strong>同时与所有的键进行比较</strong>。如果找到条目，那么就得到相应值的字段。搜索速度很快；现代的TLB查找硬件是指令流水线的一部分，基本上<strong>不添加任何性能负担</strong>.</p>
<p>TLB与页表一起使用的方法如下：TLB只<strong>包含少数的页表条目</strong>。当CPU产生一个逻辑地址后，它的页码就发送到TLB。如果找到这个页码，它的<strong>帧码也就立即可用，可用于访问内存</strong>。因此TLB命中的话仅需一次访问。</p>
<p>如果<strong>页码不在TLB中</strong>（称为<strong>TLB未命中</strong>（TLB miss）），那么就<strong>需访问页表</strong>。取决于CPU，这可能由硬件自动处理或通过操作系统的中断来处理。当得到帧码后，就可以用它来访问内存（见图8-14）。</p>
<p>之后，将<strong>页码和帧码添加到TLB</strong>，这样下次再用时就可很快查找到。如果TLB内的<strong>条目已满，那么会选择一个来替换</strong>。替换策略有很多，从最近最少使用替换（LRU），到轮转替换，到随机替换等。有的CPU允许操作系统参与LRU条目的替换，其他的自己负责替换。另外，有的TLB允许有些<strong>条目固定</strong>下来，也就是说，它们不会从TLB中被替换。通常，<strong>重要内核代码的条目是固定下来的</strong>。</p>
<center> <img src="./osimg/TLB.png"> </center>

<p>有的TLB在每个<strong>TLB条目中还保存地址空间标识符</strong>（Address-Space Identifier，ASID）。ASID<strong>唯一标识每个进程</strong>，并为进程<strong>提供地址空间的保护</strong>。当TLB试图解析虚拟页码时，它确保当前运行进程的ASID与虚拟页相关的<strong>ASID相匹配</strong>。如果不匹配，那么就作为<strong>TLB未命中</strong>。</p>
<p><em>每个CPU只有一个TLB而不是每个进程都有，因此可能出现虚拟页逻辑地址重合，此时需要唯一的表示每个进程，可以使用pid作为ASID</em></p>
<p>提供地址空间保护外，ASID也<strong>允许TLB同时包括多个不同进程的条目</strong>。如果TLB<strong>不支持单独的ASID</strong>，每次<strong>选择一个页表</strong>时（例如，上下文切换时），TLB就<strong>应被刷新</strong>（flush）（或删除），以<strong>确保下一个进程不会使用错误的地址转换</strong>.</p>
<p>更高的TLB命中率能减少有效访问时间。</p>
<h4 id="8-5-3-保护"><a href="#8-5-3-保护" class="headerlink" title="8-5-3 保护"></a>8-5-3 保护</h4><p><strong>分页环境下的内存保护</strong>是通过与<strong>每个帧关联的保护位</strong>来实现的。通常，这些<strong>位保存在页表中</strong>。</p>
<p>用一个位可以定义一个页是可读可写或只可读。每次内存引用都要通过页表，来查找正确的帧码；在<strong>计算物理地址的同时，可以通过检查保护位来验证有没有对只可读页进行写操作</strong>。对只读页进行写操作会向操作系统产生硬件陷阱或内存保护冲突）。</p>
<p>还有一个位通常与页表中<strong>的每一条目</strong>相关联: <strong>有效-无效位</strong>（valid-invalid bit）。当该位为有效时，该值表示相关的页在进程的逻辑地址空间内，因此是合法（或有效）的页。当该位为<strong>无效时</strong>，该值表示相关的页<strong>不在进程的逻辑地址空间</strong>内。通过使用有效-无效位，非法地址会被捕捉到。操作系统通过<strong>对该位的设置，可以允许或不允许对某页的访问</strong>。</p>
<p>例如，对于14位地址空间（0～16383）的系统，假设有一个程序，它的有效地址空间为0～10468。如果页的大小为2KB，那么页表如图8.15所示。页0、1、2、3、4和5的地址可以通过页表正常映射。然而，如果试图产生页表6或7内的地址时，则会发现有效-无效位为无效，这样操作系统就会捕捉到这一非法操作（无效页引用）。</p>
<center> <img src="./osimg/有效无效.png"> </center>

<p>但是问题是。由于程序的地址<strong>只到10468，所以任何超过该地址的引用都是非法的</strong>。不过，由于对<strong>页5的访问是有效的</strong>，因此<strong>到12287为止的地址都是有效的</strong>。只有12288～16383的地址才是无效的。这个问题是由于页大小为2KB的原因，也反映了<strong>分页的内部碎片</strong>。</p>
<p>有的系统提供硬件，如<strong>页表长度寄存器</strong>（Page-Table Length Register，PTLR）来<strong>表示页表的大小</strong>，该寄存器的值可用于<strong>检查每个逻辑地址以验证其是否位于进程的有效范围内</strong>。如果检测无法通过，则会被操作系统捕捉到。</p>
<h4 id="8-5-4-共享页"><a href="#8-5-4-共享页" class="headerlink" title="8-5-4 共享页"></a>8-5-4 共享页</h4><p>分页的<strong>优点之一是可以共享公共代码</strong>。对于分时环境，这种考虑特别重要。若代码是<strong>可重入代码</strong>（reentrant code）或<strong>纯代码</strong>（pure code），则可以共享。共享能显著降低重复冗余代码和数据对内存的浪费。</p>
<center> <img src="./osimg/分页代码共享.png"> </center>

<p><strong>可重入代码是不能自我修改的代码：它在执行期间不会改变</strong>。因此，两个或更多个进程可以同时执行相同代码。每个进程都有它自已的寄存器副本和数据存储，以便保存进程执行的数据。当然，两个<strong>不同进程的数据不同</strong>。</p>
<p>在物理内存中，只需保存一个程序代码的副本。每个用户的<strong>页表映射到编辑器的同一物理副本</strong>，但是<strong>数据页映射到不同的帧</strong>。</p>
<h3 id="8-6-页表结构"><a href="#8-6-页表结构" class="headerlink" title="8-6 页表结构"></a>8-6 页表结构</h3><h4 id="8-6-1-分层分页"><a href="#8-6-1-分层分页" class="headerlink" title="8-6-1 分层分页"></a>8-6-1 分层分页</h4><p>大多数现代计算机系统支持大逻辑地址空间（2^32 ～ 2^64 ）。在这种情况下, <strong>页表本身可以非常大</strong>。例如，假设具有32位逻辑地址空间的一个计算机系统。如果系统的页大小为4KB（2²），那么页表可以多达100万的条目（2^32 &#x2F; 2²）。假设每个条目有4字节，那么每个进程需要4MB物理地址空间来存储页表本身。显然，我们并不想在内存中连续地分配这个页表。</p>
<p>这个问题的一个简单解决方法是将<strong>页表划分为更小的块</strong>.</p>
<p>一种方法是使用两层分页算法，就是将页表再分页（图8-17）。例如，再次假设一个系统，具有32位逻辑地址空间和<strong>4KB(2^12 )大小的页</strong>。一个逻辑地址被分为20位的页码和<strong>12位的页偏移</strong>。因为要对页表进行再分页，所以该<strong>页码可分为10位的页码和10位的页偏移</strong>。这样，一个逻辑地址就分为如下形式：</p>
<center> <img src="./osimg/两级页表.png"> </center>

<p>由于<strong>地址转换由外向内</strong>，也被称为<strong>向前映射页表</strong>。</p>
<center> <img src="./osimg/分层架构.png"> </center>

<h5 id="多层分页为什么能节省内存"><a href="#多层分页为什么能节省内存" class="headerlink" title="多层分页为什么能节省内存*"></a>多层分页为什么能节省内存*</h5><center> <img src="./osimg/多层分页为什么能节省内存.png"> </center>

<p>对于<strong>64位的逻辑地址空间</strong>的系统, <strong>两层分页方案就不再适合</strong>。为了说明这一点，假设系统的页面大小为4KB（2^12 ）。这时，页表可由多达2^52 个条目组成。如果采用两层分页，那么内部页表可方便地定为一页长，或包括2^10 个4字节的条目。地址形式如下图所示：</p>
<center> <img src="./osimg/64双层.png"> </center>

<p>此时外部页表仍有2^42 项，此时可以进一步划分，64位的UltraSPARC采用了七层分页，可以看出多层分页不适合64位系统。</p>
<h4 id="8-6-2"><a href="#8-6-2" class="headerlink" title="8-6-2"></a>8-6-2</h4><p>处理大于32位地址空间的<strong>常用方法是使用哈希页表</strong>（hashedpage table），采用<strong>虚拟页码作为哈希值</strong>。哈希页表的每一个条目都包括一个链表，该链表的元素哈希到同一位置（该<strong>链表用来解决处理碰撞</strong>）。每个元素由三个字段组成：1）虚拟页码，2）映射的帧码，3）指向链表内下一个元素的指针。</p>
<center> <img src="./osimg/哈希页表.png"> </center>

<p>哈希页表的一个变体——<strong>聚簇页表</strong>，被用于64位地址空间的方案。不过，哈希表内的<strong>每个条目引用多个页（例如16）而不是单个页</strong>。因此，单个<strong>页表条目可以映射到多个物理帧</strong>。聚簇页表对于稀疏（sparse）地址空间特别有用，这里的引用是不连续的并且散布在整个地址空间中。</p>
<h4 id="8-6-3-倒置页表"><a href="#8-6-3-倒置页表" class="headerlink" title="8-6-3 倒置页表"></a>8-6-3 倒置页表</h4><p>为每个进程提供页表确实很耗内存。</p>
<p>因此, 我们可以使用<strong>倒置页表</strong>（inverted page table）。对于<strong>每个真正的内存页或帧，倒置页表才有一个条目</strong>。每个<strong>条目包含保存在真正内存位置上的页的虚拟地址，以及拥有该页进程的信息</strong>。因此，整个<strong>系统只有一个页表</strong>，并且<strong>每个物理内存的页只有一条相应的条目</strong>(难以共享)。</p>
<p>由于一个倒置页表通常<strong>包含多个不同的映射物理内存的地址空间</strong>，通常<strong>要求它的每个条目保存一个地址空间标识符</strong>（8.5.2节）。地址空间标识符的保存确保了，具体进程的每个<strong>逻辑页可映射到相应的物理帧</strong>.</p>
<center> <img src="./osimg/倒置页表.png"> </center>

<p>为了说明这种方法，这里描述一种用于IBMRT的倒置页表的简化版本。IBM是最早采用倒置页表的大公司：从IBMSystem38、RS&#x2F;6000，到现代的IBMPowerCPU。对IBMRT，系统内的每个虚拟地址为一个三元组：</p>
<center> <p> (进程id，页码，偏移) </p> </center>

<p>每个<strong>倒置页表条目为二元组(进程id，页码)<strong>，这里进程id用来作为地址空间的标识符。当发生</strong>内存引用</strong>时，<strong>由（进程id，页码）组成的虚拟地址被提交到内存子系统</strong>。然后，搜索倒置页表来寻找匹配。如果找到匹配条目，如条目i，则<strong>生成物理地址（i，偏移）</strong>。如果找不到匹配，则为非法地址访问。</p>
<p>虽然这种方案减少了存储每个页表所需的内存空间，但是它<strong>增加了由于引用页而查找页表所需的时间</strong>。由于<strong>倒置页表是按物理地址来排序</strong>的，而<strong>查找是根据虚拟地址</strong>的，因此查找匹配可<strong>能需要搜索整个表</strong>。这种搜索需要很长时间. 为了解决这个问题，可以<strong>使用一个哈希表</strong>（如8.6.2节所述），以将<strong>搜索限制在一个或最多数个页表条目</strong>。当然，每次<strong>访问哈希表也增加了一次内存引用</strong>，因此每次虚拟地址的引用<strong>至少需要两个内存读</strong>. 对于这个问题，可以<strong>使用TLB缓解</strong>。</p>
<p>采用<strong>倒置页表</strong>的系统在<strong>实现共享内存时会有困难</strong>，因为<strong>每个物理页只有一个虚拟页条目</strong>，一个物理页不可能有两个（或多个）共享的虚拟地址。解决这个问题的一个简单技术是, <strong>只允许页表包含一个虚拟地址到共享物理地址的映射</strong>????。这意味着，对未映射的虚拟地址的引用会导致页错误。</p>
<h4 id="8-6-4-solaris"><a href="#8-6-4-solaris" class="headerlink" title="8-6-4 solaris"></a>8-6-4 solaris</h4><p>P277</p>
<h3 id="8-7-intel-32与64位体系结构"><a href="#8-7-intel-32与64位体系结构" class="headerlink" title="8-7 intel 32与64位体系结构"></a>8-7 intel 32与64位体系结构</h3><p>P277</p>
<h4 id="ia32"><a href="#ia32" class="headerlink" title="ia32"></a>ia32</h4><h4 id="x86-64"><a href="#x86-64" class="headerlink" title="x86-64"></a>x86-64</h4><p>P279</p>
<h3 id="arm架构"><a href="#arm架构" class="headerlink" title="arm架构"></a>arm架构</h3><p>P280</p>
<h2 id="9-虚拟内存管理"><a href="#9-虚拟内存管理" class="headerlink" title="9 虚拟内存管理"></a>9 虚拟内存管理</h2><h3 id="9-1-背景"><a href="#9-1-背景" class="headerlink" title="9-1 背景"></a>9-1 背景</h3><p>指令应处于物理内存以便执行的要求，似乎是必要的和合理的；但它也是有缺点的，因为它<strong>将程序的大小限制为物理内存的大小</strong>。事实上，通过实际程序的研究会发现，在<strong>许多情况下并不需要将整个程序置于内存中</strong>。例如，分析以下内容：</p>
<ul>
<li>程序通常具有处理异常错误条件的代码。由于这些错误很少实际发生，所以这些代码几乎从不执行。</li>
<li>数组、链表和表等所分配的内存量通常多于实际需要值</li>
<li>程序的某些选项和功能可能很少使用</li>
</ul>
<p>即使需要整个程序，也<strong>可能不同时需要整个程序</strong>。分段能够执行只有部分处于内存的程序，可以带来许多好处：</p>
<ul>
<li>程序不再受物理内存的可用量所限制。</li>
<li>可以同时运行更多的程序，进而增加CPU利用率和吞吐量，但没有增加响应时间或周转时间。</li>
<li>加载或交换每个用户程序到内存所需的I&#x2F;O会更少，用户程序会运行得更快。</li>
</ul>
<p>因此，运行不完全处于内存的程序将使系统和用户都受益。</p>
<p><strong>虚拟内存</strong>（virtual memory）将用户<strong>逻辑内存与物理内存分开</strong>. 这使得编程更容易，因为不需要考虑空间。</p>
<p>进程的<strong>虚拟地址空间</strong>（virtual address space）就是<strong>进程如何在内存中存放的逻辑（或虚拟）视图</strong>。通常，进程从某一逻辑地址（如地址0）开始，连续存放，如图9-2所示。根据第8章所述，物理地址可以按帧来组织，并且分配给进程的物理帧也可以不连续。这就需要<strong>内存管理单元（MMU）将逻辑页映射到内存的物理页帧</strong>。</p>
<center> <img src="./osimg/9-1.png"> </center>

<p>随着<strong>动态内存的分配</strong>，允许<strong>堆向上生长</strong>。类似地，随着<strong>子程序的不断调用</strong>，还允许<strong>堆栈向下生长</strong>。堆与堆栈之间的巨大空白空间（或空洞）为虚拟地址的一部分，只有在<strong>堆与堆栈生长时，才需要实际的物理页</strong>。</p>
<p><strong>虚拟内存</strong>除了将用户<strong>逻辑内存与物理内存分开</strong>，还<strong>允许文件和内存通过共享页面而被多个进程共享</strong>。节省了内存资源。</p>
<center> <img src="./osimg/虚拟内存共享.png"> </center>

<h3 id="9-2-请求调页"><a href="#9-2-请求调页" class="headerlink" title="9-2 请求调页"></a>9-2 请求调页</h3><p>将可执行程序从磁盘加载到内存可以<strong>一次性将整个程序加载到内存</strong>，也可以<strong>仅在需要时加载</strong>，这就是<strong>请求调页</strong>。请求调页的虚拟内存仅在程序执行期间被请求才被加载。</p>
<p>请求调页系统<strong>类似于具有交换的分页系统</strong>, 这里进程驻留在外存上（通常为磁盘）。当进程需要执行时，它被交换到内存中。不过，不是将整个进程交换到内存中，而是<strong>采用情性交换器</strong>（lazy swapper）。惰性交换器<strong>除非需要某个页面，否则从不将它交换到内存中</strong>。在请求调页的上下文中，使用术语“交换器”在技术上是不正确的. <strong>交换器操纵整个进程，而调页程序（pager）只涉及进程的页面</strong>. 因此，在讨论请求调页时，我们使用“调页程序”，而不是“交换器”</p>
<center> <img src="./osimg/分页内存带磁盘的传送.png"> </center>

<h4 id="9-2-1-基本概念"><a href="#9-2-1-基本概念" class="headerlink" title="9-2-1 基本概念"></a>9-2-1 基本概念</h4><p>当换入进程时，调页程序会<strong>猜测在该进程被再次换出之前会用到哪些页</strong>，只把那些要使用的页调入内存。</p>
<p>使用这种方案<strong>需要一定形式的硬件支持</strong>，以<strong>区分内存的页面和磁盘的页面</strong>。8.5.3节所述的有效-无效位方案可用于这一目的。然而此时，当该位被设置为<strong>a“有效”时</strong>，相关联的<strong>页面是合法的，并且在内存中</strong>。当该位被设置为<strong>a“无效”时</strong>，页面<strong>无效</strong>（即不在进程的逻辑地址空间中），或<strong>有效但只在磁盘上</strong>。这时出现多种情况。</p>
<center> <img src="./osimg/9-5.png"> </center>

<p>如果进程<strong>试图访问那些尚未调入内存中的页面</strong>时，对标记为无效的页面访问会<strong>产生缺页错误</strong>（page fault）。分页硬件在通过页表转换地址时会<strong>注意到无效位被设置，从而陷入操作系统</strong>。处理这种缺页错误的程序很简单：</p>
<ol>
<li>检查这个<strong>进程的内部表</strong>（通常与PCB（ProcessControlBlock，进程控制块）一起保存），以<strong>确定该引用是有效的还是无效的内存访问</strong>。</li>
<li>如果引用无效，那么终止进程。如果引用有效但是尚未调入页面，那么现在就应调入。</li>
<li>找到一个空闲帧（例如，从空闲帧链表上得到一个）。</li>
<li>调度一个磁盘操作，以将所需页面读到刚分配的帧。</li>
<li>当磁盘读取完成时, <strong>修改进程的内部表和页表</strong>，以指示该页现在处于内存中。</li>
<li>重新启动被陷阱中断的指令。该进程现在能访问所需的页面，就好像它总是在内存中。</li>
</ol>
<center> <img src="./osimg/缺页除里.png"> </center>

<p>在极端情况下，我们可以开始执行一个没有内存页面的进程。之后的任何请求都会产生缺页错误并尝试调入内存。这种<strong>方案为纯请求调页</strong>(pure demand paging)：只有在需要时才将页面调入内存。</p>
<p>理论上，有些程序的每次指令执行可以访问多个新的页面，从而每条指令可能引起多个缺页错误, 会导致不可接受的系统性能。幸运的是，对运行进程的分析表明，这种行为是极不可能的. 如9.6.1节所述，程序具有<strong>局部引用</strong>（locality of reference）即倾向于引用最近使用的内存，这使得请<strong>求调页具有较为合理的性能</strong>。</p>
<p><strong>支持请求调页的硬件与分页和交换的硬件相同</strong>：</p>
<ul>
<li><strong>页表</strong>：该表能够通过有效-无效位或保护位的特定值将条目标记为无效。</li>
<li><strong>外存</strong>（secondary memory）（或<strong>辅助存储</strong>）：这种外存<strong>用于保存不在内存（主存）中的那些页面</strong>。外存通常为<strong>高速硬盘</strong>，称为<strong>交换设备</strong>，用于交换的这部分磁盘称为<strong>交换空间</strong>（swap space）。</li>
</ul>
<p><strong>请求调页的关键要求是在缺页错误后重新启动任何指令的能力</strong>。因为当<strong>发生缺页错误时, 保存了被中断的进程状态</strong>（寄存器、条件代码、指令计数器），所以<strong>应能够在完全相同的位置和状态下，重新启动进程</strong>，只不过现在所需的页面已在内存中并且是可以访问的.</p>
<p>当<strong>一条指令可以修改多个不同的位置时，就会出现重要困难</strong>。例如，IBM System 360&#x2F;370的MVC（movecharacter，移动字符）指令，可以从一个位置<strong>移动</strong>多达256字节<strong>到另一个位置(可能重叠)<strong>。如果任何一块（源或目的）跨越页边界，那么在执行了部</strong>分移动时可能会出现缺页错误</strong>。此外，如果<strong>源块和目的块有重叠，源块可能已被修改</strong>；在这种情况下，我们不能简单重新启动指令。(<strong>能保存进程以及相关寄存器状态，但对到内存的改动则无法回复</strong>)。</p>
<p>这种情况有两种解决方法：</p>
<ol>
<li>让<strong>缺页错误在微代码执行前产生</strong>，提前载入缺页，然后执行移动。</li>
<li>使用<strong>临时寄存器来保存覆盖位置的值</strong>。如果有缺页错误，则<strong>在陷阱发生之前，所有旧值都将写回到内存中</strong>。</li>
</ol>
<h4 id="9-2-2-请求调页的性能"><a href="#9-2-2-请求调页的性能" class="headerlink" title="9-2-2 请求调页的性能"></a>9-2-2 请求调页的性能</h4><p>请求调页可以<strong>显著影响计算机系统的性能</strong>. 对大多数计算机系统而言，内存访问时间（用ma表示）的范围为10～200ns。只要<strong>没有出现缺页错误</strong>，有效访问时间就<strong>等于内存访问时间</strong>。然而，如果<strong>出现缺页错误</strong>，那么就应<strong>先从磁盘中读入相关页面</strong>，再访问所需要的字。</p>
<p>设p为出现缺页错误的概率：</p>
<center> <img src="./osimg/有效访问时间.png" > </center>

<p>缺页错误的发生会导致以下动作：</p>
<ol>
<li>陷入操作系统</li>
<li>保存用户寄存器和进程状态</li>
<li>确定中断是否为缺页错误</li>
<li>检查页面引用是否合法，并确定页面的磁盘位置</li>
<li>从磁盘读入页面到空闲帧：<ul>
<li>在该磁盘队列中等待，直到读请求被处理</li>
<li>等待磁盘的寻道或延迟时间</li>
<li>开始传输磁盘页面到空闲帧</li>
</ul>
</li>
<li>在等待时，将CPU分配给其他用户（CPU调度, <strong>可选</strong>）。</li>
<li>收到来自I&#x2F;O子系统的中断（I&#x2F;O完成）。</li>
<li>保存其他用户的寄存器和进程状态（如果执行了第6步）。</li>
<li>确认中断是来自上述磁盘的。</li>
<li>修正页表和其他表，以表示所需页面现在已在内存中。</li>
<li>等待CPU再次分配给本进程。</li>
<li>恢复用户寄存器、进程状态和新页表，再重新执行中断的指令。</li>
</ol>
<p>在任何情况下，缺页错误的处理时间有三个主要组成部分：</p>
<ul>
<li>处理缺页错误中断。</li>
<li>读入页面。</li>
<li>重新启动进程。</li>
</ul>
<center> <img src="./osimg/有效访问时间和错误率.png" > </center>

<p>对于<strong>请求调页</strong>, <strong>降低缺页错误率</strong>是极为重要的。否则，会增加有效访问时间，从而极大地减缓了进程的执行速度。</p>
<p>请求调页的另一个方面是<strong>交换空间的处理和整体使用</strong>。交换空间的磁盘<strong>I&#x2F;O通常要快于文件系统的</strong>。交换空间的文件系统更快，因为它是<strong>按更大的块来分配</strong>的，且<strong>不采用文件查找和间接分配方法</strong>. </p>
<p>有两种使用方式：</p>
<ol>
<li>系统可以在<strong>进程启动时将整个文件映像复制到交换空间</strong>中，然后从交换空间执行请求调页，获得<strong>更好的分页吞吐量</strong>。</li>
<li>开始时从文件系统进行请求调页，但是在<strong>置换页面时则将页面写入交换空间</strong>。这种方法确保，只<strong>从文件系统读取所需的页面</strong>，而所有<strong>后续调页都是从交换空间完成的</strong>。这样能使用更少的交换空间。</li>
</ol>
<p>对于<strong>二进制文件的请求调页</strong>，有些系统试图限制交换空间的用量。这些文件的请求调页是<strong>从文件系统中直接读取</strong>的。然而，当需要<strong>页面置换</strong>时，这些帧可以<strong>简单地覆盖</strong>（因为它们<strong>从未被修改</strong>）；当再次需要时，从文件系统中再次直接读入。然而，对于<strong>与文件无关的页面</strong>还是<strong>需要使用交换空间</strong>（称为<strong>匿名内存</strong>（anonymous memory）），这些页面包括进程的<strong>堆栈</strong>（stack）和<strong>堆</strong>（heap）。</p>
<h3 id="9-3-写时复制"><a href="#9-3-写时复制" class="headerlink" title="9-3 写时复制"></a>9-3 写时复制</h3><p>系统调用fork()的进程创建最初可以通过使用类似于页面共享的技术（在8.5.4节中讨论），绕过请求调页的需要。这种技术提供了快速的进程创建，并最小化必须分配给新创建进程的新页面的数量。</p>
<p>回想一下，系统调用fork()创建了父进程的一个复制，以作为子进程。传统上，fork()为子进程创建一个父进程地址空间的副本，复制属于父进程的页面。然而，考虑到许多子进程在创建之后立即调用系统调用exec()，父进程地址空间的复制可能没有必要。</p>
<p><em>exec()让子进程被另一个程序覆盖，会失去之前的共享内存和共享线程</em></p>
<p>因此，可以采用一种称为<strong>写时复制</strong>（copy-on-write）的技术，它通过<strong>允许父进程和子进程最初共享相同的页面</strong>来工作。这些共享页面<strong>标记为写时复制</strong>，这意味着如果任何一个<strong>进程写入共享页面</strong>，那么就<strong>创建共享页面的副本</strong>。</p>
<center> <img src="./osimg/写时复制.png" > </center>

<p>当确定<strong>采用写时复制来复制页面时，重要的是注意空闲页面的分配位置</strong>。许多操作系统为这类请求提供了一个<strong>空闲的页面池</strong>（page pool）。当<strong>进程的堆栈或堆要扩展时或有写时复制页面需要管理时，通常分配这些空闲页面</strong>。操作系统分配这些页面通常采用称为<strong>按需填零</strong>（zero-fill-on-demand）的技术。按需填零页面在<strong>需要分配之前先填零，因此清除了以前的内容</strong>。</p>
<p>UNIX的多个版本(Solaris和Linux)提供vfork(), 它允许子进程使用父进程的地址空间，但<strong>不提供写时复制</strong>，也就是说，任何子进程对数据的修改导致其他进程包括父进程的数据的改变。</p>
<h3 id="9-4-页面置换"><a href="#9-4-页面置换" class="headerlink" title="9-4 页面置换"></a>9-4 页面置换</h3><p>如果增加了多道程度，那么可能会<strong>过度分配（over-allocating）内存</strong>。如果运行6个进程，每个进程有10个页面但是<strong>实际上只使用5个页面</strong>，那么会有更高的CPU利用率和吞吐量，并且还有10帧可作备用。然而，对于特定数据集合，每个<strong>进程可能会突然试图使用其所有页面，从而共需要60帧，而只有40帧可用</strong>。</p>
<p>再者，还需要考虑到<strong>内存不仅用于保存程序页面</strong>。用于<strong>I&#x2F;O的缓存也消耗大量的内存</strong>，这种使用会增加内存置换算法的压力. 有些系统为I&#x2F;O缓存<strong>分配了固定百分比</strong>的内存，而其他系统<strong>允许用户进程和I&#x2F;O子系统竞争使用</strong>所有系统内存。</p>
<p>内存的<strong>过度分配</strong>会有问题。当用户进程正在执行时，可能<strong>发生缺页错误</strong>。操作系统确定所需页面的磁盘位置，但是<strong>却发现空闲帧列表上没有空闲帧</strong>，所有内存都在使用中。</p>
<center> <img src="./osimg/需要页面置换的情况.png" > </center>

<p>这时，可以终止一个进程，但这样不符合我们设计虚拟内存的初衷。</p>
<p>因此，操作系统<strong>也可以交换出一个进程</strong>，以释放它的所有帧并降低多道程度。</p>
<p>这里我们讨论<strong>最常见的解决方案：页面置换</strong>（page replacement）。</p>
<h4 id="9-4-1-基本页面置换"><a href="#9-4-1-基本页面置换" class="headerlink" title="9-4-1 基本页面置换"></a>9-4-1 基本页面置换</h4><p>页面置换采用以下方法。如果<strong>没有空闲帧，那么就查找当前不在使用的一个帧，并释放它</strong>。步骤如下：</p>
<ol>
<li>找到所需页面的磁盘位置</li>
<li>找到一个空闲帧：<ul>
<li>如果有空闲帧，那么就使用它。</li>
<li>如果没有空闲帧，那么就使用<strong>页面置换算法来选择一个牺牲帧</strong>（victim frame）。</li>
<li>将<strong>牺牲帧的内容写到交换空间上, 修改对应的页表和帧表</strong>。</li>
</ul>
</li>
<li>将<strong>所需页面读入（新的）空闲帧，修改页表和帧表</strong>。</li>
<li>从发生缺页错误位置，继续用户进程。</li>
</ol>
<center> <img src="./osimg/页面置换.png" > </center>

<p>请注意，如果<strong>没有空闲帧，那么需要两个页面传输</strong>（一个调出，一个调人）。这种情况实际上<strong>加倍了缺页错误处理时间</strong>，并相应地<strong>增加了有效访问时间</strong>.</p>
<p>采用<strong>修改位</strong>（modify bit）（或<strong>脏位</strong>（dirty bit））可<strong>减少这种开销</strong>。当采用这种方案时，每个<strong>页面或帧都有一个修改位</strong>，两者之间的<strong>关联采用硬件</strong>。每当<strong>页面内的任何字节被写入</strong>时，它的页面<strong>修改位会由硬件来设置</strong>，以表示该页面已被修改过。当要选择一个页面<strong>进行置换时，就检查它的修改位。如果该位已被设置</strong>，那么该页面<strong>从磁盘读入以后已被修改</strong>。在这种情况下，应<strong>将页面写入磁盘</strong>。然而，如果<strong>修改位未被设置</strong>，那么该页面从<strong>磁盘读入以后还未被修改</strong>。在这种情况下，我们<strong>不需要将内存页面写到磁盘</strong>因为它已经存在。这种技术也适用于只读页面（例如，二进制代码的页面）。这种页面不能被修改；因此，如需要，这些页面可以被放弃。这种方案可显著地降低用于处理缺页错误所需的时间，因为<strong>如果页面没有被修改，可以降低一半的I&#x2F;O时间</strong>。（确保保存修改后的页面）</p>
<p><strong>页面置换是请求调页的基础</strong>。它完成了逻辑内存和物理内存之间的分离. 有了请求调页，程序的逻辑地址空间不在局限于物理内存，磁盘也可以用做拓展内存。</p>
<p>为实现请求调页，必须解决<strong>两个主要问题</strong>：应<strong>设计帧分配算法</strong>（frame-allocation algorithm）和<strong>页面置换算法</strong>（page-replacement algorithm）</p>
<ul>
<li><strong>帧分配算法</strong>：有多个进程在内存中，必须<strong>决定要为每个进程分配多少</strong></li>
<li><strong>页面置换算法</strong>：当需要页面置换时，必须<strong>选择要置换的帧</strong></li>
</ul>
<p>我们希望采用有最小缺页错误率的算法。可以这样评估一个算法：针对特定内存引用串，运行某个置换算法，并计算缺页错误的数量。内存引用的串称为<strong>引用串</strong>（reference string）。可以人工地生成引用或可以跟踪一个给定系统并记录每个内存引用的地址。为了减少数据的数量，可以利用以下两个事实。</p>
<ol>
<li>对于给定的页面大小（页面大小通常由硬件或系统来决定），只需考虑页码，而非完整地址</li>
<li>有一个对页面p的引用，那么紧跟着的对页面p的任何引用决不会引起缺页错误。</li>
</ol>
<p>例如，在跟踪一个特定的进程时，可能记录以下的地址序列：</p>
<center> <img src="./osimg/addrs.png" > </center>

<p>如果页面大小100字节，则可以写成以下引用串：</p>
<center> <img src="./osimg/refs.png" > </center>

<p>此外，还要确定<strong>可用帧的数量</strong>，可用帧越多，缺页错误会减少。最终趋于稳定错误量。</p>
<center> <img src="./osimg/fps.png" > </center>

<p>下面，讨论几种页面置换算法。为此，假设有3个帧并且引用串为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">7</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">7</span>,<span class="number">0</span>,<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h4 id="9-4-2-fifo页面置换"><a href="#9-4-2-fifo页面置换" class="headerlink" title="9-4-2 fifo页面置换"></a>9-4-2 fifo页面置换</h4><p>最简单的页面置换算法是FIFO算法。FIFO页面置换算法为每个页面记录了调到内存的时间。当必须置换页面时，将<strong>选择最旧的页面</strong>。可以创建一个FIFO队列，来管理所有的内存页面, 不需要计时。</p>
<center> <img src="./osimg/FIFO页面置换.png" > </center>

<p>FIFO易于实现，但<strong>性能往往不佳</strong>。</p>
<p>特别的，就算<strong>选择正在被使用的页面进行替换也一切正常</strong>，因为这将立即引发一个缺页错误来取回活动页面。但是<strong>这增加了不必要的缺页错误</strong>，因此应选择合适的使用少的页面替换。</p>
<h5 id="Belady异常"><a href="#Belady异常" class="headerlink" title="Belady异常"></a>Belady异常</h5><p>FIFO置换算法对于特殊的引用串可能出现特别的错误：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br></pre></td></tr></table></figure>

<center> <img src="./osimg/FIFO_Belady.png" > </center>

<p>对于有些页面置换算法，随着分配帧数量的增加，缺页错误率可能会增加。</p>
<h4 id="9-4-3-最优页面置换"><a href="#9-4-3-最优页面置换" class="headerlink" title="9-4-3 最优页面置换"></a>9-4-3 最优页面置换</h4><p>发现Belady异常的一个结果是寻找<strong>最优页面置换算法</strong>（optimal page-replacement algorithm）, 这个算法具有所有算法的<strong>最低的缺页错误率，并且不会遭受Belady异常</strong>。简单地说: <strong>置换最长时间不会使用的页面</strong>.</p>
<center> <img src="./osimg/最优置换算法.png" > </center>

<p>然而这难以实现，因为<strong>需要未来的引用串</strong>，就像SJF一样。因此，我们寻找近似的算法替代。</p>
<h4 id="9-4-4-lru页面替换"><a href="#9-4-4-lru页面替换" class="headerlink" title="9-4-4 lru页面替换"></a>9-4-4 lru页面替换</h4><p><strong>最近最少使用算法</strong>（Least-Recent-Used algorithm,LRU algorithm）。使用<strong>最近的过去作为不远将来的近似</strong>，那么可以<strong>置换最长时间没有使用的页</strong>。</p>
<center> <img src="./osimg/LRU.png" > </center>

<h5 id="实现LRU替换"><a href="#实现LRU替换" class="headerlink" title="实现LRU替换"></a>实现LRU替换</h5><p>LRU页面置换可能需要硬件辅助，主要是需要<strong>确定由上次使用时间定义的帧的顺序</strong>。这有两者实现：</p>
<ul>
<li><strong>计数器</strong>：在最简单的情况下，为<strong>每个页表条目关联一个使用时间域，并为CPU添加一个逻辑时钟或计数器</strong>。每次内存引用都会递增时钟。每当进行页面引用时，时钟寄存器的内容会复制到相应页面的页表条目的使用时间域。这样，我们总是有每个页面的最后引用的“时间”。我们置换具有最小时间的页面。这种方案<strong>需要搜索页表以查找LRU页面</strong>，而且<strong>每次内存访问都要写到内存</strong>（到页表的使用时间域）。当页表更改时（由于CPU调度），还必须保留时间. <strong>时钟溢出</strong>也要考虑。</li>
<li><strong>堆栈</strong>：实现LRU置换的另一种方法是采用页码堆栈。每当<strong>页面被引用</strong>时，它就<strong>从堆栈中移除并放在顶部</strong>。这样, <strong>最近使用的页面总是在堆栈的顶部</strong>, <strong>最近最少使用的页面总是在底部</strong>。因为必须从堆栈的中间删除条目, <strong>最好通过使用具有首指针和尾指针的双向链表</strong>来实现这种方法. 每次<strong>更新有点费时，但是置换不需要搜索</strong>, 堆栈的底部就是LRU页面。适用于LRU置换的软件或微代码实现。</li>
</ul>
<p>像最优置换一样，LRU置换<strong>没有Belady异常</strong>。这两个都属于同一类算法，称为<strong>堆栈算法</strong>（stack algorithm），都<strong>绝不可能有Belady异常</strong>. 堆栈算法可以证明为，帧数为n的内存页面集合是帧数为n+1的内存页面集合的子集。对于LRU置换，内存中的页面集合为最近引用的n个页面。如果帧数增加，那么这n个页面仍然是最近被引用的，因此仍然在内存中。</p>
<p>注意，除了标准的TLB寄存器没有其他辅助硬件，这两种LRU实现都是<strong>不可能的</strong>。每次内存引用，都应更新时钟域或堆栈。如果<strong>每次引用都采用中断</strong>以便允许<strong>软件更新这些数据结构</strong>，那么它会<strong>使内存引用至少慢10倍</strong>，进而使用户进程运行慢10倍。很少有系统可以容忍这种级别的内存管理开销。</p>
<h4 id="9-4-5-近似lru页面置换"><a href="#9-4-5-近似lru页面置换" class="headerlink" title="9-4-5 近似lru页面置换"></a>9-4-5 近似lru页面置换</h4><p>大多数计算机都<strong>不提供LRU算法所需的硬件</strong>，因此无法使用原始的LRU。然而，许多系统都<strong>通过引用位（reference bit）的形式提供一定的支持</strong>。每当<strong>引用一个页面</strong>时（无论是对页面的字节进行读或写），它的<strong>页面引用位就被硬件置位</strong>。页表内的每个<strong>条目都关联着一个引用位</strong>。</p>
<p>初始引用位为0，之后随着使用我们可以<strong>检查引用位来指导哪些页面已被使用</strong>，虽然不知道顺序，但这种信息是许多近似LRU算法的基础。</p>
<h5 id="9-4-5-1-额外引用位算法"><a href="#9-4-5-1-额外引用位算法" class="headerlink" title="9-4-5-1 额外引用位算法"></a>9-4-5-1 额外引用位算法</h5><p>通过<strong>定期记录引用位</strong>，我们可以<strong>获得额外的排序信息</strong>。可以为内存中的<strong>页表的每个页面保留一个8位的字节</strong>。定时器中断定期地（如每100ms）将控制传到操作系统。操作系统<strong>将每个页面引用位移到其8位字节的高位，将其他位右移1位，并丢弃最低位</strong>。这些8位移位寄存器包含着最近8个时间周期内的<strong>页面使用情况</strong>. </p>
<p>例如，如果移位寄存器包含00000000，那么该页面在8个时间周期内没有使用。每个周期内使用至少一次的页面具有11111111的移位寄存器值。具有11000100的历史寄存器值的页面比具有值为01110111的页面更为“最近使用的”。如果<strong>将这些8位字节解释为无符号整数，那么具有最小编号的页面是LRU页面，可以被替换</strong>。对于相同的数字，可以选择置换所有最小值页面，也可以在页面之间用FIFO队列。</p>
<p>当然，移位寄存器的<strong>历史位数可以改变</strong>，并可以改变更新速度（取决于可用的硬件）。在极端情况下，位数可降为0，即<strong>只有引用位本身。这种算法称为第二次机会页面置换算法</strong>（second-chance page-replacement algorithm）。</p>
<h5 id="9-4-5-2-第二次机会算法"><a href="#9-4-5-2-第二次机会算法" class="headerlink" title="9-4-5-2 第二次机会算法"></a>9-4-5-2 第二次机会算法</h5><p>第二次机会置换的<strong>基本算法是一种FIFO置换算法</strong>。然而，当选择了一个页面时，需要<strong>检查其引用位</strong>。如果<strong>值为0，那么就直接置换</strong>此页面；如果<strong>引用位设置为1，那么就给此页面第二次机会</strong>，并<strong>继续选择下一个FIFO页面</strong>。当一个<strong>页面获得第二次机会时，其引用位被清除，并且到达时间被设为当前时间</strong>。因此，获得第二次机会的页面，在所有其他页面被置换（或获得第二次机会）之前，不会被置换。此外，如果一个页面经常使用以致于其引用位总是得到设置，那么它就不会被置换。</p>
<p><strong>实现第二次机会算法</strong>（有时称为<strong>时钟算法</strong>（clock algorithm））的一种方式是<strong>采用循环队列</strong>。<strong>指针（即时钟指针）指示接下来要置换哪个页面</strong>。当需要一个帧时，指针<strong>向前移动直到找到一个引用位为0的页面</strong>。在向前<strong>移动时，它会清除引用位</strong>（图9-17）。一旦<strong>找到牺牲页面，就置换该页面</strong>，并且<strong>在循环队列的这个位置上插入新页面</strong>。</p>
<p>注意，在最坏的情况下，当所有位都已设置，指针会循环遍历整个队列，给每个页面第二次机会。在选择下一个页面进行置换之前，它将清除所有引用位. <strong>如果所有位都为1，第二次机会置换退化为FIFO替换</strong>。</p>
<center> <img src="./osimg/二次机会置换.png" > </center>

<h5 id="9-4-5-3-增强型第二次机会算法"><a href="#9-4-5-3-增强型第二次机会算法" class="headerlink" title="9-4-5-3 增强型第二次机会算法"></a>9-4-5-3 增强型第二次机会算法</h5><p>将引用位和修改位作为有序对可以改进第二次机会算法。有了两个位就有了以下四种情况：</p>
<ul>
<li>(0，0) 最近没有使用且没有修改的页面，最佳的页面置换, 仅需一次I&#x2F;O</li>
<li>(0，1) 最近没有使用但修改过的页面，不太好的置换，因为在置换之前需要将页面写出。</li>
<li>(1，0) 最近使用过但没有修改的页面，可能很快再次使用。</li>
<li>(1，1) 最近使用过且修改过，可能很快再次使用，并且在置换之前需要将页面写出到磁盘（交换空间）</li>
</ul>
<p>替换的优先级从上至下为高到低。替换时<strong>检查页面所属类型</strong>，替换优先级最高的那个的第一个页面。可能需要多次扫描循环队列才能找到。</p>
<p>这种改进<strong>优化了所需的I&#x2F;O数量</strong>。</p>
<h4 id="9-4-6-基于计数的页面替换"><a href="#9-4-6-基于计数的页面替换" class="headerlink" title="9-4-6 基于计数的页面替换"></a>9-4-6 基于计数的页面替换</h4><p>可以为<strong>每个页面的引用次数保存一个计数器</strong>。这有以下两个方案：</p>
<ul>
<li><strong>最不经常使用</strong>（Least Frequently Used, <strong>LFU</strong>）页面置换算法要求<strong>置换具有最小计数的页面</strong>。这种选择的原因是，积极使用的页面应当具有大的引用计数。然而，当<strong>一个页面在进程的初始阶段大量使用但是随后不再使用时，会出现问题</strong>。由于被大量使用，它有一个大的计数，即使不再需要却仍保留在内存中。一种<strong>解决方案是，定期地将计数右移1位</strong>，以形成指数衰减的平均使用计数。</li>
<li><strong>最经常使用</strong>（Most Frequently Used, <strong>MFU</strong>）页面置换算法是基于如下论点：具有<strong>最小计数的页面可能刚刚被引入并且尚未使用</strong></li>
</ul>
<p>正如你可以想象的，MFU和LFU置换都<strong>不常用</strong>。这些算法的<strong>实现是昂贵的</strong>，并且它们不能很好地近似OPT置换。</p>
<h4 id="9-4-7-页面缓冲算法"><a href="#9-4-7-页面缓冲算法" class="headerlink" title="9-4-7 页面缓冲算法"></a>9-4-7 页面缓冲算法</h4><p>除了特定页面置换算法之外，还经常采用其他措施。例如，系统通常<strong>保留一个空闲帧缓冲池</strong>。当<strong>出现缺页错误时</strong>，会像以前一样选择一个牺牲帧。然而，在<strong>写出牺牲帧之前，所需页面就读到来自缓冲池的空闲帧</strong>。这种措施<strong>允许进程尽快重新启动</strong>，而无需等待写出牺牲帧。当<strong>牺牲帧以后被写出后，它被添加到空闲帧池</strong>，原本读入所需页面的空闲帧被分配到所需位置。</p>
<p>这种方法的<strong>扩展之一</strong>是, <strong>维护一个修改页面的列表</strong>。每当<strong>调页设备空闲</strong>时，就<strong>选择一个修改页面以写到磁盘</strong>上，然后<strong>重置它的修改位</strong>。这种方案增加了在需要选择置换时干净的且无需写出的页面的概率。</p>
<p><strong>另一种修改</strong>是, <strong>保留一个空闲帧池，并且记住哪些页面对应哪些帧内</strong>。因为在<strong>帧被写到磁盘后帧内容并未被修改</strong>，所以当该帧被重用之前，如果再次需要，那么<strong>旧的页面可以从空闲帧池中直接取出</strong>并被使用。这种情况<strong>不需要I&#x2F;O</strong>。当<strong>发生缺页错误</strong>时，首先检查所需页面是否<strong>在空闲帧池</strong>中。如果不在，我们应选择一个自由帧并读入页面。（写出时保持内容不变的添加到空闲帧池）</p>
<h4 id="9-4-8-应用程序和页面置换"><a href="#9-4-8-应用程序和页面置换" class="headerlink" title="9-4-8 应用程序和页面置换"></a>9-4-8 应用程序和页面置换</h4><p>某些情况下，通过操作系统的虚拟内存访问数据的应用程序比不使用操作系统缓冲的程序更慢。比如<strong>数据库，他提供自己的内存管理和I&#x2F;O缓冲。他更能好的应用内存和磁盘</strong>。如果系统和应用都提供I&#x2F;O缓冲，那么用于I&#x2F;O的内存自然倍增。</p>
<p>另一个例子是<strong>数据仓库，它频繁地执行大量的、顺序的磁盘读取</strong>，随后计算并写入。LRU算法会删除旧的页面并保留新的页面，而应用程序将更<strong>可能读取较旧的页面而不是较新的页面</strong>（因为它再次开始顺序读取）。这里，MFU(最大频率使用)可能比LRU更为高效。</p>
<p>由于这些问题，有的操作系统<strong>允许特殊程序能够将磁盘分区作为逻辑块的大的数组来使用</strong>，而<strong>不需要通过文件系统的数据结构</strong>。这种数组有时称为<strong>原始磁盘</strong>（raw disk），而这种数组的I&#x2F;O称为原始I&#x2F;O。原始I&#x2F;O绕过所有文件系统服务，例如文件I&#x2F;O的请求调页、文件锁定、预取、空间分配、文件名和目录等。能在原始分区上实现<strong>更高效的服务</strong>。</p>
<h3 id="9-5-帧分配"><a href="#9-5-帧分配" class="headerlink" title="9-5 帧分配"></a>9-5 帧分配</h3><p>为进程分配帧的个数</p>
<h4 id="9-5-1-帧的最小数"><a href="#9-5-1-帧的最小数" class="headerlink" title="9-5-1 帧的最小数"></a>9-5-1 帧的最小数</h4><p><strong>帧分配策略受到多方面的限制</strong>。例如，所分配的帧<strong>不能超过可用帧的数量</strong>（除非有页面共享），也必须<strong>分配至少最小数量的帧</strong>。</p>
<p>分配至少最小数量的帧的一个原因<strong>涉及性能</strong>。显然，随着分配给每个进程的<strong>帧数量的减少，缺页错误率增加，从而减慢进程执行</strong>。</p>
<p>注意，在执行<strong>指令完成之前发生缺页错误，应重新启动指令</strong>。因此，<strong>必须有足够的帧来容纳任何单个指令可以引用的所有不同的页面</strong>。</p>
<p>例如，考虑这样一个机器，它的所有内存引用的指令仅可以引用一个内存地址。在这种情况下，至少需要<strong>一个帧用于指令，另一个帧用于内存引用</strong>。若允许一级间接寻址，那么分页要求每个进程至少需要3个帧。如果分配帧数不够将会导致指令的无限执行。</p>
<p>最小顿数由计算机架构定义。例如，PDP-11的移动指令在有些寻址模式下包括多个字，因此指令本身可跨越2个页面。另外，它有2个操作数，而且每个操作数都可能是间接引用，从而共需要6个帧。另一个例子是IBM370MVC指令。由于这个指令是从存储位置到存储位置，它需要6字节并且可能跨越2个页面。要移动的字符块（来源）和要移动到的区域（目的）都可以跨越2个页面。这种情况需要6个帧。最坏的情况是，MVC指令作为跨越页面边界的EXECUTE指令的操作数，这种情况需要8个帧。</p>
<p><strong>多级的间接寻址将会导致大量的帧需求，因此需要限制最大的间接引用</strong>。</p>
<h4 id="9-5-2-分配算法"><a href="#9-5-2-分配算法" class="headerlink" title="9-5-2 分配算法"></a>9-5-2 分配算法</h4><p>最简单的分配算法就是<strong>平均分配</strong>，对于n个进程，m个帧，就给每个进程分配m&#x2F;n个帧。显然这很容易造成小进程的<strong>内存浪费</strong>。</p>
<p>此时可以使用<strong>比例分配</strong>，根据进程大小按比例分配。</p>
<p>假设进程pi的虚拟内存大小为si，有：</p>
<center> <img src="./osimg/Ssum.png" > </center>

<p>若可用帧为m个那么进程pi能得到的帧为：</p>
<center> <img src="./osimg/Ai.png" > </center>

<p>这里需要保证总和不超过m，简单点的话直接向下取整。</p>
<p>显然，对于平均分配和比例分配，进程<strong>分得的帧受程序多道程度的影响</strong>。而且，对于不同优先级的进程一视同仁，但我们往往想<strong>给高优先级的进程更多的帧</strong>。一种可行办法是，采用<strong>比例分配，但不根据进程大小，而是由优先级分配</strong>。</p>
<h4 id="9-5-3-全局分配和局部分配"><a href="#9-5-3-全局分配和局部分配" class="headerlink" title="9-5-3 全局分配和局部分配"></a>9-5-3 全局分配和局部分配</h4><p>为各个进程分配帧的另一个重要因素是页面置换。由于多个进程竞争帧，可以将页面置换算法分为两大类：</p>
<ul>
<li><strong>全局置换</strong>: 允许一个进程<strong>从所有帧的集合中选择一个置换帧</strong>，而不管该帧是否已分配给其他进程.</li>
<li><strong>局部置换</strong>: 要求每个进程<strong>只从它自己分配的帧中进行选择</strong>。</li>
</ul>
<p><strong>全局置换</strong>算法的一个问题是，进程<strong>不能控制它自己的缺页错误率</strong>. 进程的内存页面的集合不但取决于进程本身的调页行为，而且取决于其他进程的调页行为. 受其他进程影响大。</p>
<p>对于<strong>局部置换</strong>算法，进程的内存页面的集合<strong>仅受该进程本身的调页行为所影响</strong>。然而，局部置换由于<strong>不能使用其他进程的较少使用的内存页面</strong>，可能会阻碍一个进程。</p>
<p>这样, <strong>全局置换</strong>通常会有<strong>更好的系统吞吐量</strong>，因此是更常用的方法。</p>
<h4 id="9-5-4-非均匀内存访问"><a href="#9-5-4-非均匀内存访问" class="headerlink" title="9-5-4 非均匀内存访问"></a>9-5-4 非均匀内存访问</h4><p>通常，对于具有多个CPU的系统（1.3.2节），给定的CPU可以比其他CPU<strong>更快地访问内存的某些部分</strong>。这些<strong>性能差异</strong>是由CPU和内存在系统中<strong>互连造成</strong>的. 通常，这样的系统由多个系统板组成，而且每个系统板包含多个CPU和一定的内存。系统板互连方式各种各样，从系统总线到高速网络连接（如InfiniBand）。可以想象，特定<strong>板CPU访问同板内存的延迟，要小于访问其他板内存的延迟</strong>。</p>
<p><strong>具有明显不同的内存访问时间的系统</strong>统称为<strong>非均匀内存访问</strong>（Non-Uniform Memory Access，NUMA）系统，并且毫无例外地，它们要慢于内存和CPU位于同一主板的系统。</p>
<p>管理哪些页面帧位于哪些位置能够明显影响NUMA系统的性能. 应对<strong>调度系统进行类似的修改</strong>。这些修改的目标是，让分配的内存帧“尽可能地靠近”运行进程的CPU。算法修改包括让<strong>调度程序跟踪每个进程运行的最后一个CPU</strong>。如果<strong>调度程序</strong>尝试将每个进程调度到它先前的CPU上，而且<strong>内存管理系统</strong>尝试分配的顿靠近正在分配的CPU，那么将导致<strong>高速缓存命中率的改进和内存访问时间的减少</strong>。(CPU调度和内存管理系统调度合作)</p>
<p><strong>一旦添加了线程，情况就更为复杂</strong>。例如，具有许多运行线程的某个进程可以在许多不同系统板上有运行线程。在这种情况下，如何分配内存？Solaris通过在内核中创建<em><strong>延迟组</strong></em>（latency group，lgroup）来解决这个问题。每个lgroup将相近的CPU和内存聚集在一起。事实上，基于组之间的延迟量，存在lgroup的一个层次结构。Solaris试图在一个lgroup内调度进程的所有线程，并分配它的所有内存。如果这不可能，则在附近的lgroug选择所需的其余资源。这种做法最大限度地减少总体内存延迟，且最大化CPU缓存命中率。</p>
<h3 id="9-6-系统抖动"><a href="#9-6-系统抖动" class="headerlink" title="9-6 系统抖动"></a>9-6 系统抖动</h3><p>如果<strong>低优先级进程所分配的帧数低于计算机体系结构所需的最小数量(单指令执行所需的帧)<strong>，那么必须</strong>暂停该进程执行</strong>。然后，应调<strong>出它的所有剩余页面，以便释放所有分配的帧</strong>。这个规定引入了中级CPU调度的换进换出层。</p>
<p>对于没有“足够”帧的进程。它会<strong>很快产生缺页错误</strong>。此时，必须置换某个页面。然而，由于它的<strong>所有页面都在使用</strong>中，所以必须立即置换需要再次使用的页面。因此，它会<strong>再次快速产生缺页错误</strong>。</p>
<p>这种<strong>高度的页面调度活动</strong>称为<strong>抖动</strong>（thrashing）。如果一个进程的<strong>调页时间多于它的执行时间</strong>，那么进程就在<strong>抖动</strong>。</p>
<h4 id="9-6-1-系统抖动的原因"><a href="#9-6-1-系统抖动的原因" class="headerlink" title="9-6-1 系统抖动的原因"></a>9-6-1 系统抖动的原因</h4><p>抖动导致严重的<strong>性能问题</strong>。考虑以下场景，这是基于早期调页系统的实际行为。</p>
<p>操作系统监视CPU利用率。如果<strong>CPU利用率太低，那么通过向系统引入新的进程来增加多道程度</strong>。采用<strong>全局置换算法</strong>会置换任何页面，而不管这些页面属于哪个进程。现在假设进程在执行中进入一个新阶段，并且需要更多的帧。它开始出现缺页错误，并从其他进程那里获取帧。然而，这些进程也需要这些页面，因此它们也会出现缺页错误，并且从其他进程中获取帧。这些缺页错误进程必须使用调页设备以将页面换进和换出。当<strong>它们为调页设备排队时，就绪队列清空。随着进程等待调页设备，CPU利用率会降低</strong>。</p>
<p><strong>CPU调度程序看到CPU利用率的降低，进而会增加多道程度</strong>。新进程试图从其他运行进程中获取帧来启动，从而导致<strong>更多的缺页错误和更长的调页设备队列</strong>。因此, <strong>CPU利用率进一步下降，并且CPU调度程序试图再次增加多道程度</strong>。这样就出现了<strong>抖动</strong>，系统吞吐量陡降。缺页错误率显著增加。结果，有效内存访问时间增加。没有工作可以完成，因为进程总在忙于调页。</p>
<center> <img src="./osimg/系统抖动.png" > </center>

<p>通过<strong>局部置换算法</strong>（local replacement algorithm）或<strong>优先权置换算法</strong>（priority replacement algorithm），可以<strong>限制系统抖动</strong>. </p>
<p>如果一个进程开始抖动，那么由于采用局部置换，它不能从另一个进程中获取帧，而且也不能导致后者抖动。然而，这个问题<strong>并没有完全解决</strong>。如果进程抖动，那么在大多数时间内会排队等待调页设备。由于调页设备的平均队列更长，缺页错误的平均等待时间也会增加。因此，即使对于不再抖动的进程，有效访问时间也会增加。(<strong>所以不要想着从抖动中救了，应该避免抖动</strong>)</p>
<p>为了防止抖动，应为进程提供足够多的所需帧数. <strong>工作集策略</strong>（9.6.2节）研究一个进程实际使用多少帧。这种方法<strong>定义了进程执行的局部性模型</strong>（locality model）。</p>
<p>局部性模型指出，随着进程执行，它从一个局部移向另一个局部. <strong>局部性是最近使用页面的一个集合</strong>（图9-19）。一个程序通常由多个不同的可能重叠的局部组成。</p>
<p>例如，当一个函数被调用时，它就定义了一个新的局部。在这个局部里，内存引用可针对函数调用的指令、它的局部变量以及全局变量的某个子集。当退出函数时，进程离开该局部，因为这个函数的局部变量和指令已不再处于活动使用状态。以后可能回到这个局部。</p>
<p>注意，局部性模型是本书目前为止缓存讨论的背后原理。如果对任何数据类型的访问是随机的而没有规律模式，那么缓存就没有用了。</p>
<p>假设<strong>为进程分配足够的帧以适应当前局部</strong>。该进程在其局部内会出现缺页错误，直到所有页面都在内存中；接着它不再会出现缺页错误，除非改变局部。如果<strong>没有能够分配到足够的帧来容纳当前局部</strong>，那么进程将会<strong>抖动</strong>，因为它<strong>不能在内存中保留正在使用的所有页面</strong>。</p>
<h4 id="9-6-2-工作集模型"><a href="#9-6-2-工作集模型" class="headerlink" title="9-6-2 工作集模型"></a>9-6-2 工作集模型</h4><p>如上所述, <strong>工作集模型</strong>（working-set model）是<strong>基于局部性假设</strong>的。这个模型采用<strong>参数△定义工作集窗口</strong>（working-set window）。它的思想是检查最近△个页面引用。这<strong>最近△个页面引用的页面集合称为工作集</strong>（working-set）（如图9-20所示）。如果一个页面处于活动使用状态，那么它处在工作集中。如果它不再使用，那么它在最后一次引用的△时间单位后，会从工作集中删除。因此，工作集是<strong>程序局部的近似</strong>。</p>
<center> <img src="./osimg/工作集.png" > </center>

<p><em>dinner图片什么都看不出来</em></p>
<p><strong>工作集最重要的属性是大小</strong>。假设进程i的工作集大小为WSS_i, 那么有：</p>
<center> <img src="./osimg/D.png" > </center>

<p>D为所需帧的总数, m为可用帧的总数。若 D &gt; m， 则会发生抖动。</p>
<p>一旦选中△了，工作集模型的使用就很简单. <strong>操作系统监视每个进程的工作集，并为它分配大于其工作集的帧数</strong>。如果<strong>还有足够的额外帧，那么可启动另一进程</strong>。如果工作集大小的总和增加，以致超过可用帧的总数，则操作系统会<strong>选择一个进程来挂起</strong>。该进程的<strong>页面被写出</strong>（交换），并且其<strong>帧可分配给其他进程</strong>。挂起的进程以后可以重启。</p>
<p>工作集模型的<strong>困难是跟踪工作集</strong>。工作集窗口是一个移动窗口。对于每次内存引用，新的引用出现在一端，最旧的引用离开另一端。如果一个页面在工作集窗口内的任何位置被引用过，那么它就在工作集窗口内。</p>
<p>(通过定期时钟中断和引用位，我们能够近似工作集模型。例如，假设为10000个引用，而且每5000个引用引起定时器中断。当得到一个定时器中断时，复制并清除所有页面的引用位。因此，如果发生缺页错误，那么可以检查当前的引用位和位于内存的两个位，这两位可以确定在过去的10000～15000个引用之间该页面是否被使用过。如果使用过，那么这些位中至少有一位会被打开。如果没有使用过，那么这些位会被关闭。至少有一位打开的页面会被视为在工作集中。</p>
<p>注意，这种安排并不完全准确，这是因为并不知道在5000个引用内的什么位置出现了引用。通过增加历史位的数量和中断的频率（例如，10位和每1000个引用中断一次），可以降低这一不确定性。然而，服务这些更为频繁中断的成本也会相应更高。)</p>
<h4 id="9-6-3-缺页错误频率"><a href="#9-6-3-缺页错误频率" class="headerlink" title="9-6-3 缺页错误频率"></a>9-6-3 缺页错误频率</h4><p>采用<strong>缺页错误频率</strong>（Page-Fault Frequency，PFF）的策略是一种更为直接的防止抖动的方法。</p>
<p>当缺页错误率太高时，我们知道该进程需要更多的帧。相反，如果缺页错误率太低，则该进程可能具有太多的帧。我们可以<strong>设置所需缺页错误率的上下限</strong>（图9-21）。如果实际<strong>缺页错误率超过上限，则可为进程再分配一帧</strong>；如果实际缺<strong>页错误率低于下限，则可从进程中删除一帧</strong>。因此，可以直接测量和控制缺页错误率，以防止抖动。</p>
<center> <img src="./osimg/缺页错误频率.png" > </center>

<p>与工作集策略一样，也<strong>可能不得不换出一个进程</strong>。如果<strong>缺页错误率增加并且没有空闲帧可用</strong>，那么<strong>必须选择某个进程并将其交换到后备存储</strong>。然后，再将<strong>释放的帧分配给具有高缺页错误率的进程</strong>。</p>
<h3 id="9-7-内存映射文件"><a href="#9-7-内存映射文件" class="headerlink" title="9-7 内存映射文件"></a>9-7 内存映射文件</h3><p>对文件访问采用所讨论的虚拟内存技术，以<strong>将文件I&#x2F;O作为常规内存访问</strong>。这种方法称为<strong>内存映射</strong>（memory mapping）文件，允许一部分虚拟内存与文件进行逻辑关联。</p>
<h4 id="9-7-1-基本机制"><a href="#9-7-1-基本机制" class="headerlink" title="9-7-1 基本机制"></a>9-7-1 基本机制</h4><p>实现<strong>文件的内存映射是，将每个磁盘块映射到一个或多个内存页面</strong>。最初，文件访问按<strong>普通请求调页</strong>来进行，从而产生缺页错误。这样，<strong>文件的页面大小部分从文件系统读取到物理页面</strong>. 以后，文件的<strong>读写就按常规内存访问来处理</strong>, 不需要文件系统I&#x2F;O。</p>
<p>请注意, <strong>内存映射文件的写入不一定是对磁盘文件的即时（同步）写入</strong>。有的操作系统定期检查文件的内存映射页面是否已被修改，以便选择是否更新到物理文件。当关闭文件时，所有内存映射的数据会写到磁盘，并从进程虚拟内存中删除。</p>
<p>有的系统提供系统调用来提供内存映射，其他的系统则默认使用内存映射。</p>
<p><strong>多个进程</strong>可以允许<strong>并发地内存映射同一文件</strong>，以便允许数据共享。任何一个进程的<strong>写入会修改虚拟内存的数据</strong>，并且<strong>其他映射同一文件部分的进程都可看到</strong>。内存映射系统调用还可以<strong>支持写时复制功能</strong>，允许进程既可以按只读模式来共享文件，也可以拥有自己修改的任何数据的副本。为了协调对共享数据的访问，有关进程可以使用第6章描述的实现互斥的机制。</p>
<center> <img src="./osimg/内存映射文件.png" > </center>

<p><strong>很多时候，共享内存实际上是通过内存映射来实现的</strong>。在这种情况下，进程可以通过共享内存来通信，而<strong>共享内存是通过映射同样文件到通信进程的虚拟地址空间来实现</strong>的. </p>
<center> <img src="./osimg/内存映射共享内存.png" > </center>

<h4 id="9-7-2-共享内存windows-api"><a href="#9-7-2-共享内存windows-api" class="headerlink" title="9-7-2 共享内存windows api"></a>9-7-2 共享内存windows api</h4><p>P310</p>
<h4 id="9-7-3-内存映射i-o"><a href="#9-7-3-内存映射i-o" class="headerlink" title="9-7-3 内存映射i&#x2F;o"></a>9-7-3 内存映射i&#x2F;o</h4><p><strong>每个I&#x2F;O控制器</strong>包括<strong>保存命令和传输数据的寄存器</strong>。通常, <strong>专用I&#x2F;O指令</strong>允许在这些<strong>寄存器和系统内存之间进行数据传输</strong>。为了更方便地访问I&#x2F;O设备，许多计算机体系结构提供了<strong>内存映射I&#x2F;O</strong>（memory-mapped I&#x2F;O）。在这种情况下, <strong>一组内存地址专门映射到设备寄存器</strong>。对这些<strong>内存地址的读取和写入</strong>，导致<strong>数据传到或取自设备寄存器</strong>。这种方法适用于具有<strong>快速响应时间的设备</strong>，例如视频控制器。</p>
<p>内存映射I&#x2F;O也适用于其他设备，如用于联结modem和打印机的计算机串口和并口。通过<strong>读取和写入这些设备寄存器</strong>（称为<strong>I&#x2F;O端口</strong>（I&#x2F;O port））, <strong>CPU可以对这些设备传输数据</strong>。为了通过内存映射串行端口发送一长串字节，CPU将<strong>一个数据字节写到数据寄存器</strong>，并将<strong>控制寄存器的一个位置位以表示有字节可用</strong>。设备<strong>读取数据字节</strong>，并<strong>清零控制寄存器的指示位</strong>，以表示<strong>已准备好接收下一个字节</strong>。接着，CPU可以传输下一个字节。</p>
<p>如果<strong>CPU采用轮询监视控制位</strong>，不断<strong>循环查看设备是否就绪</strong>，这种操作称为<strong>程序I&#x2F;O</strong>（Programmed I&#x2F;O，PIO）。如果CPU不是轮询控制位，而是<strong>在设备准备接收一个字节时收到中断</strong>，则数据传输称为<strong>中断驱动</strong>。</p>
<h3 id="9-8-分配内核内存"><a href="#9-8-分配内核内存" class="headerlink" title="9-8 分配内核内存"></a>9-8 分配内核内存</h3><p>当在<strong>用户模式</strong>下运行进程<strong>请求额外内存</strong>时，从<strong>内核维护的空闲页帧列表上分配页面</strong>.</p>
<p>用于分配内核内存的空闲内存池通常不同于用于普通用户模式进程的列表。这有两个主要原因：</p>
<ul>
<li>内核需要<strong>为不同大小的数据结构请求内存</strong>，其中<strong>有的小于一页</strong>。因此，内核<strong>应保守地使用内存</strong>，并努力<strong>最小化碎片浪费</strong>。这一点非常重要，因为<strong>许多操作系统的内核代码或数据不受调页系统的控制</strong>。</li>
<li>用户模式进程分配的页面不必位于连续物理内存。然而,** 有的硬件设备与物理内存直接交互<strong>，即</strong>无法享有虚拟内存接口<strong>带来的便利，因而</strong>可能要求内存常驻在连续物理内存中**。</li>
</ul>
<p>下面讨论两个策略，以便管理用于内核进程的空闲内存：“伙伴系统”和slab分配。</p>
<h4 id="9-8-1-伙伴系统"><a href="#9-8-1-伙伴系统" class="headerlink" title="9-8-1 伙伴系统"></a>9-8-1 伙伴系统</h4><p><strong>伙伴系统</strong>（buddy system）从<strong>物理连续</strong>的<strong>大小固定的段</strong>上进行分配。从这个段上分配内存，采用<strong>2的幂分配器</strong>（power-of-2 allocator）来满足请求分配单元的大小为2的幂（4KB、8KB、16KB等）。请求单元的大小如不适当，就<strong>圆整到下一个更大的2的幂</strong>。例如，如果请求大小为11KB，则按16KB的段来请求.</p>
<p>伙伴系统的一个<strong>优点</strong>是：通过称为<strong>合并</strong>(coalesce)的技术，可以<strong>将相邻伙伴快速组合以形成更大分段</strong>.</p>
<p>伙伴系统的<strong>明显缺点</strong>是：由于圆整到下一个2的幂，很可能<strong>造成分配段内的碎片</strong>。例如，33KB的内存请求只能使用64KB段来满足. 事实上，我们不能保证因内部碎片而浪费的单元一定少于50%。</p>
<center> <img src="./osimg/伙伴系统.png" > </center>

<h4 id="9-8-2-slab分配"><a href="#9-8-2-slab分配" class="headerlink" title="9-8-2 slab分配"></a>9-8-2 slab分配</h4><p><strong>slab分配没有因为碎片而损失空间</strong>。</p>
<p><strong>分配内核内存</strong>的第二种策略称为<strong>slab分配</strong>。每个<strong>slab由一个或多个物理连续</strong>的<strong>页面</strong>组成。每个<strong>cache由一个或多个slab组成</strong>。每个<strong>内核数据结构</strong>都有一个cache。例如，用于表示进程描述符、文件对象、信号量等的数据结构都有各自单独的cache。</p>
<p><strong>每个cache</strong>含有内核数据结构的<strong>对象实例</strong>（称为object）。例如，信号量cache有信号量对象，进程描述符cache有进程描述符对象，等等。图9-27显示了slab、cache及object三者之间的关系</p>
<center> <img src="./osimg/slab.png" > </center>

<p>slab分配算法<strong>采用cache来存储内核对象</strong>. 在创建cache时，若干起初<strong>标记为free的对象</strong>被分配到cache。cache内的<strong>对象数量取决于相关slab的大小</strong>。例如，12KBslab（由3个连续的4KB页面组成）可以存储6个2KB对象。最初，cache内的所有对象都标记为空闲。当<strong>需要内核数据结构的新对象</strong>时，分配器可以<strong>从cache上分配任何空闲对象</strong>以便满足请求。从<strong>cache上分配的对象标记为used</strong>（使用）。</p>
<p>在Linux中，slab可以处于三种可能状态之一：</p>
<ul>
<li><strong>满的</strong>（full）：slab的所有对象标记为使用。</li>
<li><strong>空的</strong>（empty）：slab上的所有对象标记为空闲。</li>
<li><strong>部分</strong>（partial）：slab上的对象有的标记为使用，有的标记为空闲。</li>
</ul>
<p>slab分配器<strong>首先尝试在部分为空的slab中用空闲对象来满足请求</strong>。如果不存在，则从空的slab中分配空闲对象。如果<strong>没有空的slab可用</strong>，则<strong>从连续物理页面分配新的slab，并将其分配给cache</strong>；从这个slab上，再分配对象内存。</p>
<p>slab分配器提供两个<strong>主要优点</strong>：</p>
<ul>
<li><strong>没有因碎片而引起内存浪费</strong>。碎片不是问题，因为每个内核数据结构都有关联的cache, <strong>每个cache都由一个或多个slab组成</strong>，而slab<strong>按所表示对象的大小来分块</strong>。因此，当<strong>内核请求对象内存</strong>时，slab分配器<strong>可以返回刚好表示对象的所需内存</strong>。</li>
<li><strong>可以快速满足内存请求</strong>。分配和释放内存的动作可能是一个耗时过程。然而，由于<strong>对象已预先创建</strong>，因此可以<strong>从cache中快速分配</strong>. 当内核用完对象并释放它时，它被标记为空闲并返回到cache，从而立即可用于后续的内核请求。</li>
</ul>
<h5 id="Linux的SLOB和SLUB"><a href="#Linux的SLOB和SLUB" class="headerlink" title="Linux的SLOB和SLUB"></a>Linux的SLOB和SLUB</h5><p>P314</p>
<h3 id="9-9-其他注意事项"><a href="#9-9-其他注意事项" class="headerlink" title="9-9 其他注意事项"></a>9-9 其他注意事项</h3><h4 id="9-9-1-预调页面"><a href="#9-9-1-预调页面" class="headerlink" title="9-9-1 预调页面"></a>9-9-1 预调页面</h4><p>纯请求调页的一个明显特性是，当进程启动时，发生<strong>大量的缺页错误</strong>。这种情况在<strong>当换出进程重新启动时也会出现</strong>，它的所有页面都在磁盘上，而且每个页面都会通过缺页错误而调进内存。</p>
<p><strong>预调页面</strong>（prepaging）试图<strong>阻止这种大量的最初调页</strong>。这种策略是<strong>同时调进所需的所有页面</strong>。</p>
<p>例如，对于<strong>采用工作集模型的系统</strong>，可以<strong>为每个进程保留一个位于工作集内的页面列表</strong>。当一个<strong>进程必须暂停时</strong>（由于I&#x2F;O的等待或空闲帧的缺少），它的<strong>进程工作集也应记住</strong>。当这个<strong>进程被重启时</strong>（由于I&#x2F;O已经完成或已有足够的可用空闲帧），在<strong>重启之前自动调入它的整个工作集</strong>。</p>
<p>问题在于，用预调页面的成本是否小于处理相应缺页错误的成本。预调页面可能掉入了很多不需要的页面。</p>
<p>假设预调s个页面，而且这s个页面的α部分被实际使用了（0≤α≤1）。问题是，节省的s×α个缺页错误的成本是大于还是小于预调其他s×（1－α）个不必要页面的成本。如果α接近0，那么预调页面失败；如果α接近1，那么预调页面成功。</p>
<h4 id="9-9-2-页面大小"><a href="#9-9-2-页面大小" class="headerlink" title="9-9-2 页面大小"></a>9-9-2 页面大小</h4><p>很遗憾，没有最优的页面大小。页面大小总是2的幂。</p>
<p>一个关注点是<strong>页表的大小</strong>。对于给定的虚拟内存空间, <strong>减小页面大小增加了页面的数量，从而增加了页表的大小</strong>。例如，对于4MB（2^22 ）的虚拟内存，如页面大小为1024字节，则有4096个页面；而页面大小为8192字节，就只有512个页面。因为<strong>每个活动进程必须有自己的页表，所以期望大的页面</strong>。</p>
<p>然而, <strong>较小的页面可以更好地利用内存</strong>。平均来看，每个进程最后页面的一半会被浪费。对于512字节的页面，损失为256字节；对于8192字节的页面，损失为4096字节。这样，为了<strong>最小化内部碎片，需要一个较小的页面</strong>。</p>
<p>另一个问题是<strong>读取或写入页面所需时间</strong>. <strong>I&#x2F;O时间包括寻道、延迟和传输时间</strong>。传输时间与传输数量（即页面大小）成正比, 似乎需要较小的页面。但是<strong>延迟和寻道时间通常远远超过传输时间</strong>。更大的页面带来了更少的页表项，因此I&#x2F;O的的数量减少了。因此, <strong>最小化I&#x2F;O时间期望较大的页面大小</strong>。</p>
<p><strong>然而，采用较小页面大小应该减少总的I&#x2F;O</strong>，因为<strong>局部性会被改进</strong>。<strong>较小页面</strong>允许每个页面更<strong>精确地匹配程序的局部性</strong>。例如，考虑一个大小为200KB的进程，其中只有一半（100KB）用于实际执行。如果只有一个大的页面，则必须调人整个页面，总共传输和分配200KB。相反，如果每个页面只有1字节，则可以只调入实际使用的100KB，导致只传输和分配100KB。因此, <strong>较小页面应导致更少的I&#x2F;O和更少的总的分配内存</strong>。</p>
<p>然而，采用<strong>1字节的页面会导致每个字节引起缺页错误</strong>. 对于大小为200KB的只使用一半内存的进程，采用200KB的页面只产生一个缺页错误，而采用1字节的页面会<strong>产生102400个缺页错误</strong>。每个<strong>缺页错误产生大量开销</strong>，以便处理中断、保存寄存器、置换页面、排队等待调页设备和更新表。为了<strong>最小化缺页错误的数量，需要有较大的页面</strong>。</p>
<h4 id="9-9-3-tlb范围"><a href="#9-9-3-tlb范围" class="headerlink" title="9-9-3 tlb范围"></a>9-9-3 tlb范围</h4><p>更高的TLB命中率能减少有效访问时间，但是这需要更大的TLB储存而这是很贵的。</p>
<p>与命中率相关的另一类似的度量是<strong>TLB范围</strong>（TLB reach）。TLB范围指的是<strong>通过TLB访问的内存量</strong>，即<strong>TLB条数与页面大小的乘积</strong>。增加TLB条数能增加TLB范围，但这可能还不足以满足需求。</p>
<p>还可以<strong>增加页面大小来扩大TLB范围</strong>。不过更大的页面会带来更多的内部碎片。或者<strong>可以提供多种页面大小</strong>以适应不同需求的进程。</p>
<p><strong>支持多个大小的页面要求操作系统（而不是硬件）来管理TLB</strong>。例如，TLB条目的一个域应用于表示对应TLB条目的页面大小. <strong>通过软件</strong>而不是硬件来管理TLB会<strong>降低性能</strong>。然而, <strong>命中率和TLB范围的增加会提升性能</strong>。最近的趋势倾向于由软件来管理TLB和由操作系统来支持不同大小的页面。</p>
<h4 id="9-9-4-倒置页表"><a href="#9-9-4-倒置页表" class="headerlink" title="9-9-4 倒置页表"></a>9-9-4 倒置页表</h4><p><strong>普通页表通过页表指向物理地址，而倒置页表将物理地址指向页表。这导致单个物理地址只能被单一虚拟地址占有</strong></p>
<p>倒置页表通过创建一个表，该表为每个物理内存页面设置一个条目，且可根据（进程ID，页码）来索引来<strong>节省内存</strong>。整个系统只依赖这一张表。</p>
<p>然而, <strong>倒置页表不再包括进程逻辑地址空间的完整信息</strong>；但是当所引用页面不在内存中时，又需要这种信息。请求调页需要这种信息来处理缺页错误. <strong>为了提供这种信息，每个进程必须保留一个外部页表</strong>。每个这样的页表看起来像传统的进程页表，并且<strong>包括每个虚拟页面的位置信息</strong>。</p>
<p>由于<strong>这些页表</strong>仅在出现缺页错误时才需要引用，因此<strong>不需要快速可用</strong>。事实上，它们本身<strong>可根据需要调进或调出内存</strong>. 然而，当<strong>一个缺页错误出现</strong>时，可能导致虚拟内存管理器<strong>生成另一个缺页错误</strong>，以便<strong>调入用于定位最初虚拟页面所需的位于外存的页表</strong>，这种特殊情况要求仔细处理内核和页面查找延迟。</p>
<h4 id="9-9-5-程序结构"><a href="#9-9-5-程序结构" class="headerlink" title="9-9-5 程序结构"></a>9-9-5 程序结构</h4><p>有意识的考虑请求调页可以改进程序性能。</p>
<p>假设页面大小为128个字。考虑一个C程序，其功能是将128×128数组的所有元素初始化为0。以下代码是很典型的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> data[<span class="number">128</span>][<span class="number">128</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">128</span>; ++j)&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">128</span>; ++i)&#123;</span><br><span class="line">    data[i][j] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意，数组是按行存放的，也就是说，数组存储顺序为data[0][0]，data[0][1]，··· ，data[0][127]，data[1][0]，data[1][1]，··· ，data[127][127]。如果面大小为128字，那么每行需要一个页面。如果整个程序由操作系统分配的帧数少于128，那么它的执行会产生128×128&#x3D;16384个缺页错误。相反，假设将代码修改为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> data[<span class="number">128</span>][<span class="number">128</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">128</span>; ++i)&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">128</span>; ++j)&#123;</span><br><span class="line">    data[i][j] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>则只会产生128个缺页错误，因为每次都在初始化完一页后才进入下一页。</p>
<p>仔细选择数据结构和编程结构可以增加局部性，进而<strong>降低缺页错误率和工作集的页面数</strong>。例如，<strong>堆栈具有良好的局部性</strong>，因为<strong>访问总是在顶部进行的</strong>。相反，<strong>哈希表设计成分散引用，从而局部性差</strong>。当然，引用局部性仅仅是数据结构使用效率的测度之一。其他重要的加权因素包括搜索速度、内存引用的总数、涉及页面的总数。</p>
<p>在稍后阶段, <strong>编译器和加载器对调页有重要的影响</strong>。代码和数据的<strong>分离和重入代码</strong>的生成意味着，代码页面可以是<strong>只读</strong>的，因此永远<strong>不会被修改</strong>。干净页面<strong>不必调出以被置换</strong>。加载器可以<strong>避免跨越页面边界放置程序，以将每个程序完全保存在一个页面</strong>内。互相多次调用的程序可以<strong>包装到同一个页面中</strong>。这种包装是操作研究的包装二进制问题的一种变体：试图将可变大小的代码段打包到固定大小的页面中，以便最小化页面间引用。这种方法对于大页面尤其有用。</p>
<h4 id="9-9-6-i-o联锁与页面锁定"><a href="#9-9-6-i-o联锁与页面锁定" class="headerlink" title="9-9-6 i&#x2F;o联锁与页面锁定"></a>9-9-6 i&#x2F;o联锁与页面锁定</h4><p>当使用<strong>请求调页</strong>时，有时<strong>需要允许有些页面被锁定（locked）在内存中</strong>. 当对用户（虚拟）内存进行I&#x2F;O时，会发生这种情况。I&#x2F;O通常采用单独的I&#x2F;O处理器来实现。例如，USB存储设备的控制器通常需要设置所需传输的字节数量和缓冲区的内存地址（图9-28）。当传输完成后，CPU被中断。</p>
<center> <img src="./osimg/9-28.png" > </center>

<p>我们<strong>必须确保不发生以下事件序列</strong>：进程发出I&#x2F;O请求，并被添加到这个I&#x2F;O设备的队列上。同时，CPU被交给了其他一些进程，这些进程会引起缺页错误。有的采用全局置换算法以便置换等待进程的I&#x2F;O缓存页面，这些页面被调出。稍后，当I&#x2F;O请求前进到设备队列的头部时，就针对指定地址进行I&#x2F;O。然而，此帧现在正用于另一进程的不同页面</p>
<p><strong>即确保不在进行异步I&#x2F;O时切换线程并置换页面</strong></p>
<p>有两个常见解决方案:</p>
<ul>
<li><strong>不对用户内存执行I&#x2F;O</strong>。相反，数据总是<strong>在系统内存和用户内存之间复制</strong>。I&#x2F;O<strong>仅在系统内存和I&#x2F;O设备之间进行</strong>。当需要在磁带上写入块时，首先将块复制到系统内存，然后将其写入磁带。这种额外的复制可能导致不可接的<strong>高开销</strong>。</li>
<li>是<strong>允许将页面锁定到内存</strong>。这里，每个<strong>帧都有一个关联的锁定位</strong>。如果帧<strong>被锁定</strong>，则它<strong>不能被选择置换</strong>为了在磁带上写入块，我们将包含该块的页面锁定到内存，然后系统可以照常继续，异步的I&#x2F;O会继续向这块内存写入数据而不对其他造成影响。当<strong>I&#x2F;O完成后，页面被解锁</strong>。</li>
</ul>
<p><strong>通常，操作系统内核的部分或全部被锁定在内存中。许多操作系统不能容忍由内核或特定内核模块（包括执行内存管理的模块）引起的缺页错误</strong>.</p>
<p>用户进程也可能需要将页面锁定到内存。数据库进程可能想要管理一块内存，例如，在磁盘和内存之间自己移动数据块，因为它具有如何使用数据的最佳知识.</p>
<p>锁定位也可以用来<strong>保护低优先级进程刚调入的页面</strong>不被抢占的高优先级进程置换，直到它被锁定他的进程使用一次。这有利有弊，置换与否的开销需要权衡。</p>
<p><strong>锁定位的使用有危险</strong>，可能导致页面锁加上后从未关闭，这也就造成了内存不可用（对其他进程不可用）。</p>
<h3 id="9-10-操作系统例子"><a href="#9-10-操作系统例子" class="headerlink" title="9-10 操作系统例子"></a>9-10 操作系统例子</h3><p>P319</p>
<h2 id="10-文件系统"><a href="#10-文件系统" class="headerlink" title="10 文件系统"></a>10 文件系统</h2><h3 id="10-1-文件概念"><a href="#10-1-文件概念" class="headerlink" title="10-1 文件概念"></a>10-1 文件概念</h3><p>计算机可以在各种介质上存储信息，而操作系统提供了这些信息的统一视图. <strong>文件</strong>就是操作系统对存储设备的物理属性抽象化得到的<strong>逻辑存储单位</strong>。</p>
<p>文件是记录在外存上的相关信息的命名组合。从用户角度来看，文件是逻辑外存的最小分配单元. </p>
<p>文件可存储许多不同类型的信息, 有某种定义的结构，这取决于其类型。<strong>文本文件</strong>（text file）为<strong>按行（可能还有页）组织的字符序列</strong>, <strong>源文件</strong>（source file）为<strong>函数序列</strong>，而每个函数包括声明和可执行语句. <strong>可执行文件</strong>（executable file）为<strong>一系列代码段</strong>，以供加载程序调入内存并执行。</p>
<h4 id="10-1-1-文件属性"><a href="#10-1-1-文件属性" class="headerlink" title="10-1-1 文件属性"></a>10-1-1 文件属性</h4><p>文件被命名后可以方便使用，文件名通常为字符串. <strong>文件被命名后，它就独立于进程、用户，甚至创建它的系统</strong>。即不需要额外的信息来发挥作用，即使被不同用户，不同机器使用，也没有任何性质变化。</p>
<p>文件属性通常包括：</p>
<ul>
<li><strong>名称</strong>：符号文件名是以人类可读形式来保存的唯一信息。</li>
<li><strong>标识符</strong>：这种<strong>唯一标记</strong>（通常为数字）标识文件系统的文件；它是文件的<strong>非人类可读的名称</strong>。</li>
<li><strong>类型</strong>：支持不同类型文件的系统需要这种信息。</li>
<li><strong>位置</strong>：该信息为指向设备与设备上<strong>文件位置的指针</strong>。</li>
<li><strong>尺寸</strong>：该属性包括文件的<strong>当前大小（以字节、字或块为单位）</strong>以及<strong>可能允许的最大尺寸</strong>。</li>
<li><strong>保护</strong>：访问控制信息确定谁能进行读取、写入、执行等。</li>
<li><strong>时间、日期和用户标识</strong>：文件创建、最后修改和最后使用的相关信息可以保存。用于保护、安全和使用监控。</li>
</ul>
<p>较新的文件系统还支持<strong>扩展文件属性</strong>（extended file attribute），包括文件的<strong>字符编码</strong>和安全功能，如<strong>文件校验和</strong>.</p>
<p>所有<strong>文件的信息</strong>保存在<strong>目录结构中</strong>，该<strong>目录结构也保存在外存</strong>上, 由于其占用体积可能较大，需要<strong>按需调入内存</strong>。通常, <strong>目录条目由文件的名称及其唯一标识符组成</strong>。根据<strong>标识符可定位其他文件属性</strong>.</p>
<h4 id="10-1-2-文件操作"><a href="#10-1-2-文件操作" class="headerlink" title="10-1-2 文件操作"></a>10-1-2 文件操作</h4><p>有6个基本文件操作：</p>
<ul>
<li><strong>创建文件</strong>：创建文件需要两个步骤:<ul>
<li>首先，必须在<strong>文件系统中为文件找到空间</strong></li>
<li>其次，必须在<strong>目录中创建新文件的条目</strong></li>
</ul>
</li>
<li><strong>写文件</strong>：为了写文件，使用一个<strong>系统调用</strong>指定文件名称和要写入文件的信息。根据给定的文件名称，系统<strong>搜索目录以查找文件位置</strong>。系统应<strong>保留写指针</strong>（write pointer），用于<strong>指向需要进行下次写操作的文件位置</strong>。每当发生写操作时，写指针必须被更新。</li>
<li><strong>读文件</strong>：为了读文件，使用一个<strong>系统调用</strong>，指明文件名称和需要文件的下一个块应该放在哪里（在内存中）。同样, <strong>搜索目录以找到相关条目</strong>，系统需要<strong>保留一个读指针</strong>（read pointer），指向要进行<strong>下一次读取操作的文件位置</strong>。一旦发生了读取，读指针必须被更新。因为进程通常从文件读取或写到文件，所以<strong>当前操作位置可以作为进程的当前文件位置指针</strong>（current-file-position pointer）。读和写操作<strong>都使用相同的指针</strong>，可节省空间并降低系统复杂性。</li>
<li><strong>重新定位文件</strong>: <strong>搜索目录以寻找适当的条目</strong>，并且将<strong>当前文件位置指针重新定位到给定值</strong>。重新定位文件<strong>不需要涉及任何实际的I&#x2F;O</strong>。这个文件操作也称为<strong>文件定位</strong>(file seek)。</li>
<li><strong>删除文件</strong>：为了删除文件，在<strong>目录中搜索给定名称的文件</strong>。找到关联的目录条目后，释放所有文件空间，以便它可以被其他文件重复使用，并<strong>删除目录条目</strong>。</li>
<li><strong>截断文件</strong>：用户可能想要<strong>删除文件的内容，但保留它的属性</strong>。不是强制用户删除文件再创建文件，这个功能<strong>允许所有属性保持不变，（除了文件长度），但让文件重置为零，并释放它的文件空间</strong>。</li>
</ul>
<p>以上的文件操作组成了文件操作的最小集合。其他的<strong>高级操作可以通过他们的组合实现</strong>，比如复制文件可以通过创建新文件加读取旧文件实现。</p>
<p>大部分文件操作涉及<strong>搜索目录条目</strong>，这在大量文件的系统上<strong>会影响性能</strong>。为此，操作系统有一个<strong>打开文件表</strong>（open-file table）以用于<strong>维护所有打开文件的信息</strong>。当请求文件操作时，可<strong>通过该表的索引指定文件，而不需要搜索</strong>。当文件<strong>最近不再使用</strong>时，进程关闭它，操作系统从打开文件表中<strong>删除它的条目</strong>。因为打开文件表达存在，系统一般要求使用文件前先使用系统调用open(), 部分系统会隐式的调用它. <strong>系统调用open()通常返回一个指针</strong>，以<strong>指向打开文件表的对应条目</strong>。这个指针，而不是实际的文件名，会<strong>用于所有I&#x2F;O操作</strong>，以<strong>避免任何进一步搜索</strong>，并简化系统调用接口。</p>
<p>对于<strong>多个进程可以同时打开文件的环境</strong>，操作open()和close()的实现更加复杂. 操作系统<strong>采用两级的内部表</strong>：每个<strong>进程表</strong>和整个<strong>系统表</strong>。</p>
<p><strong>每个进程表</strong>跟踪它打开的所有文件。该<strong>表所存的是进程对文件的使用信息</strong>。例如，每个文件的<strong>当前文件指针</strong>就存在这里，文件<strong>访问权限和记账信息</strong>也存在这里。</p>
<p><strong>单个进程表的每个条目</strong>相应地<strong>指向整个系统的打开文件表</strong>。系统表包含<strong>与进程无关的信息</strong>，如文件在磁盘上的<strong>位置</strong>、<strong>访问日期</strong>和<strong>文件大小</strong>。一旦有<strong>进程打开了一个文件</strong>，系统表就<strong>包含该文件的条目</strong>。通常，系统打开文件表<strong>为每个文件关联一个打开计数</strong>（open count），用于表示多少进程打开了这个文件，当打开计数为0时，可以从系统打开文件表中<strong>删除这个文件条目</strong>。（调用open()就+1，close()就-1）</p>
<p>每个文件有以下的<strong>关联信息</strong>：</p>
<ul>
<li>文件的属性当然属于文件的关联属性(<s>但书上没写</s>)</li>
<li><strong>文件指针</strong>：若系统调用read(),write()不提供偏移值，那么需要跟踪上次读写位置，作为<strong>当前文件位置指针</strong>。该指针对操作文件的<strong>每个进程是唯一的，因此必须与磁盘文件属性分开保存</strong>。</li>
<li><strong>文件打开计数</strong>：在文件打开为0时删除在系统打开文件表的条目以节省空间。</li>
<li><strong>文件的磁盘位置</strong>: <strong>查找</strong>磁盘上的文件所需的<strong>信息保存在内存中</strong>，以便系统<strong>不必为每个操作从磁盘上读取该信息</strong>。</li>
<li><strong>访问权限</strong>：每个进程采用访问模式打开文件。这种信息<strong>保存在进程的打开文件表</strong>中，因此<strong>操作系统可以允许或拒绝后续的I&#x2F;O请求</strong>。(因为进程表指向系统表，要去系统表里进行下一步访问)</li>
</ul>
<p>有的系统提供<strong>文件锁</strong>，以<strong>阻止其他进程访问该文件</strong>。</p>
<p>另外，操作系统可以提供<strong>强制</strong>（mandatory）或<strong>建议</strong>（advisory）文件<strong>锁定机制</strong>。对于<strong>强制性的文件锁定</strong>，进程<strong>获得独占锁</strong>后，其他进程的访问<strong>无论有没有获取锁这一步骤，都会被拒绝</strong>。对于<strong>建议性的文件锁定</strong>，则需要<strong>访问文件的进程手动获取锁</strong>。换句话说，如果锁定方案是强制性的，则操作系统确保锁定完整性。对于建议锁定，软件开发人员应确保适当地获取和释放锁。</p>
<p>同样的，文件锁也会导致<strong>死锁</strong>。</p>
<h4 id="10-1-3-文件类型"><a href="#10-1-3-文件类型" class="headerlink" title="10-1-3 文件类型"></a>10-1-3 文件类型</h4><p><strong>实现文件类型</strong>的常见技术是将<strong>类型作为文件名的一部分</strong>。文件名分为两部分，即名称和扩展，通常由句点分开（图10-3）。这样，用户和操作系统仅从文件名就能得知文件的类型。</p>
<center> <img src="./osimg/10-3.png"> </center>

<p><strong>扩展名</strong>可以用来<strong>指示文件类型和可用于文件的操作</strong>。例如，只有扩展名为.com, .exe或.sh的文件才能执行。.com和.exe文件是两种形式的二进制可执行文件，而.sh文件是外壳脚本（shell script），包含ASCII格式的操作系统命令。</p>
<p><strong>应用程序</strong>也使用<strong>扩展名</strong>来<strong>表示所感兴趣的文件类型</strong>. 例如，Java编译器的源文件具有.java扩展名，Microsoft Word字处理程序的文件以.doc或.docx扩展名来结束。在搜索时也可以不添加类型名，应用会自动查找符合的文件。因为<strong>这些扩展名没有操作系统的支持</strong>，所以它们只能作为<strong>应用程序的“提示”</strong>。</p>
<p>UNIX系统采用<strong>位于文件开头</strong>的<strong>幻数</strong>(magic number)来<strong>大致的表示文件类型</strong>。比如若文件以#114514开头，那这个文件是.avi类型的。当然也<strong>不是所有文件都有幻数</strong>，因此不能仅靠这一种机制确定类型。UNIX也不记录创建程序的名称。UNIX允许应用程序扩展名提示。</p>
<h4 id="10-1-4-文件结构"><a href="#10-1-4-文件结构" class="headerlink" title="10-1-4 文件结构"></a>10-1-4 文件结构</h4><p><strong>文件类型</strong>也可用于<strong>指示文件的内部结构</strong>。如10.1.3节所述，源文件和目标文件具有一定结构，以便<strong>匹配读取它们的程序的期望</strong>。此外, <strong>有些文件必须符合操作系统理解的所需结构</strong>, 一般是基础的文件类型。例如，操作系统要求<strong>可执行文件具有特定的结构</strong>，以便可以确定将文件加载到内存的哪里以及第一条指令的位置是什么。</p>
<p>让<strong>操作系统支持多个文件结构</strong>带来一个缺点：操作系统会变得<strong>太复杂</strong>。如果<strong>新应用程序</strong>需要按操作系统不支持的方式来组织信息，则可能导致严重的问题。(兼容性差)</p>
<p>有些操作系统<strong>强加（并支持）最小数量的文件结构</strong>。UNIX、Windows等都采用这种方案。UNIX认为每个文件为8位字节序列；而操作系统并<strong>不对这些位做出解释</strong>，而是<strong>让应用程序必须包含自己的代码</strong>，以便按适当结构来<strong>解释输入文件</strong>(parser)。但是，所有操作系统<strong>必须支持至少一种结构，即可执行文件的结构</strong>，以便系统能够加载和运行程序。</p>
<h4 id="10-1-5-内部文件结构"><a href="#10-1-5-内部文件结构" class="headerlink" title="10-1-5 内部文件结构"></a>10-1-5 内部文件结构</h4><h5 id="逻辑记录和物理记录"><a href="#逻辑记录和物理记录" class="headerlink" title="逻辑记录和物理记录"></a>逻辑记录和物理记录</h5><p>逻辑记录: </p>
<ul>
<li><strong>定义</strong>：逻辑记录是指在<strong>应用程序中定义的数据记录或信息单位</strong>。它<strong>通常是用户或应用程序所关注的数据的最小单位</strong>。逻辑记录的大小和格式是由应用程序或数据模型来决定的，和文件存储的具体实现无关。</li>
<li><strong>举例</strong>：假设你有一个包含<strong>学生信息的数据库</strong>，其中每个<strong>学生的信息（如姓名、学号、成绩等）构成一个逻辑记录</strong>。逻辑记录的<strong>大小可以是可变的或固定的</strong>，取决于具体的需求。</li>
</ul>
<p>物理记录:</p>
<ul>
<li><strong>定义</strong>：物理记录是<strong>指数据在存储介质（如硬盘、SSD等）上的实际存储单位</strong>。物理记录<strong>与存储设备的特性密切相关</strong>，通常<strong>受限于文件系统的块（block）大小</strong>或<strong>存储设备的扇区（sector）大小</strong>。一个物理记录可以包含一个或多个逻辑记录。</li>
<li><strong>举例</strong>：在硬盘中，数据通常以块（block）为单位存储。如果每个块的大小是4KB，而一个逻辑记录的大小是1KB，那么一个物理记录可以包含4个逻辑记录。</li>
</ul>
<p>在内部, <strong>定位文件的偏移对操作系统来说可能是比较复杂的</strong>。磁盘系统通常具有明确定义的块大小，这是由扇区大小决定的。所有<strong>磁盘I&#x2F;O按块（物理记录）为单位</strong>执行，而所有块的大小相同. <strong>物理记录大小不太可能刚好匹配期望的逻辑记录的长度</strong>。逻辑记录的长度甚至可能不同。这个问题的常见解决方案是，将多个逻辑记录包装到物理块中。</p>
<p>例如，UNIX操作系统将所有文件定义为<strong>简单的字节流</strong>。每个字节可以通过距文件的开始（或结束）的偏移来单独寻址。在这种情况下，逻辑记录<strong>大小为1字节</strong>。根据需要，文件系统通常会自动将字节打包以存入物理磁盘块，或从磁盘块中解包得到字节（每块可为512字节）。</p>
<p>所有基本I&#x2F;O功能都以块为单位来进行。从逻辑记录到物理块的转换是个相对简单的软件问题。逻辑记录大小、物理块大小和打包技术确定了每个物理块可有多少逻辑记录。</p>
<p><strong>虽然I&#x2F;O功能都以块为单位来进行，当我们还是可以访问到字节层面。操作系统将包含所需字节的块读入内存, 系统会将他们放入缓冲区，之后可以进行字节的读取，这些访问都是面向内存的</strong></p>
<h3 id="10-2-访问方法"><a href="#10-2-访问方法" class="headerlink" title="10-2 访问方法"></a>10-2 访问方法</h3><h4 id="10-2-1-顺序访问"><a href="#10-2-1-顺序访问" class="headerlink" title="10-2-1 顺序访问"></a>10-2-1 顺序访问</h4><p>最简单的访问方法是<strong>顺序访问</strong>（sequential access）。文件信息按顺序（即一个记录接着一个记录地）加以处理. 这种访问模式是目前最常见的；例如，编辑器和编译器通常以这种方式访问文件。</p>
<p>读和写构成文件的大部分操作。读操作，如read_next（），读取文件的下一部分，并且自动前移文件指针以便跟踪I&#x2F;O位置。类似地，写操作，如write_next（），会对文件的结尾附加内容，并前移到新写材料的末尾（文件的新结尾）。这样的文件可以被重置到开始；图10-4所示的顺序访问是<strong>基于文件的磁带模型</strong>；它不但适用于顺序访问设备，也适用于随机访问设备。</p>
<center> <img src="./osimg/顺序访问.png"> </center>

<h4 id="10-2-2-直接访问"><a href="#10-2-2-直接访问" class="headerlink" title="10-2-2 直接访问"></a>10-2-2 直接访问</h4><p><strong>要求文件由固定长度的逻辑记录组成</strong><br><strong>磁盘支持随机访问</strong></p>
<p><strong>直接访问</strong>（direct access）或<strong>相对访问</strong>（relative access）。这里, <strong>文件由固定长度的逻辑记录（logical records）组成</strong>，以允许程序按<strong>任意顺序进行快速读取和写入记录</strong>。直接访问方法<strong>基于文件的磁盘模型</strong>，因为磁盘允许对任何文件块的随机访问。</p>
<p>对于<strong>大量信息的立即访问</strong>，直接访问文件极为有用。数据库通常是这种类型的。当需要查询特定主题时，首先计算哪个块包含答案，然后<strong>直接读取相应块以提供期望的信息</strong>。</p>
<p>作为一个简单的例子，对于一个航班订票系统，可以将特定航班（如航班713）的所有信息存储在由航班号标识的块中。因此，航班713的空位数量保存在订票文件的块713上。为了存储关于更大的集合（例如人群）的信息，可以根据人名计算一个哈希函数，或者搜索位于内存的索引以确定需要读取和搜索的块。</p>
<p>对于直接访问方法，必须修改文件操作以便<strong>包括块号作为参数</strong>。因此，有read（n），其中n是块号，而不是read_next（）；write同理。一种方法是保留read_next（）和write_next（）来进行顺序访问；并增加操作position_file（n），其中n是块号。这样，为了实现read（n），可先position_file（n），再read_next（）。</p>
<p><strong>用户提供给操作系统</strong>的块号，通常为<strong>相对块号</strong>, 是相对于文件开头的<strong>索引</strong>. 。因此，文件的第一相对块是0，下一块是1，等等，尽管第一块的真正绝对磁盘地址可能为14703，下一块为3192等。这种操作<strong>允许操作系统选择文件的放置位置</strong>(分配问题)。</p>
<p>若需要<strong>访问某个文件的记录N</strong>，假设逻辑记录长度为L字节，则记录N的访问转化为对从文件开始位置的L*N偏移后的L字节读取。(第一记录N &#x3D; 0).</p>
<p>并不是所有系统都实现了两种访问，部分系统要求在创建文件时定义其访问方式，之后只能按这种方式访问。两种访问都可以互相模拟，但是<strong>顺序访问模拟直接访问非常低效</strong>。</p>
<center> <img src="./osimg/模拟访问.png"> </center>

<h4 id="10-2-3-其他访问方法"><a href="#10-2-3-其他访问方法" class="headerlink" title="10-2-3 其他访问方法"></a>10-2-3 其他访问方法</h4><p><strong>其他访问方法可建立在直接访问上</strong>，通常设计创建<strong>索引</strong>，包括各块的指针。为了查找文件记录，首先查找索引，之后通过索引提供的指针访问记录。</p>
<p><strong>若索引可以按顺序进行有意义的编排，可以优化搜索时间为logn</strong></p>
<p>对于大文件，索引文件本身可能变得太大而无法保存在内存中。一种解决方案是为索引文件创建索引。主索引文件包含指针，以指向辅助索引文件；而辅助索引文件包括指针，以指向实际的数据项。</p>
<h3 id="10-3-目录与磁盘的结构"><a href="#10-3-目录与磁盘的结构" class="headerlink" title="10-3 目录与磁盘的结构"></a>10-3 目录与磁盘的结构</h3><p>该考虑如何储存文件了，文件都存储于随机存取存储设备上，包括磁盘，光盘和固态盘。</p>
<p>一个<strong>存储设备可以按整体来用于文件系统, 也可以细分</strong>，以提供更细粒度的控制。例如，一个磁盘可以划分为4个<strong>分区</strong>（partition），每个<strong>分区可以有单独的文件系统</strong>。存储设备还可以<strong>组成RAID集</strong>，一起<strong>提供保护以免受单个磁盘故障</strong>（如12.7节所述）。有时，磁盘会被分区并且组成RAID集。</p>
<p>分区可用于<strong>限制单个文件系统的大小</strong>，将<strong>多个类型的文件系统放在同一设备上</strong>，或<strong>留下设备的一部分以为他用</strong>，例如交换空间或未格式化（原始）的磁盘空间。</p>
<p><strong>包含文件系统</strong>的<strong>分区</strong>通常称为<strong>卷</strong>（volume），多个分区也可以组成一个卷。卷可以是设备的一部分，或整个设备，或由多个设备组成的RAID集。每个<strong>卷可以作为虚拟磁盘</strong>。卷还<strong>可以存储多个操作系统</strong>，以允许引导和运行多个操作系统。</p>
<p><strong>包含文件系统的每个卷</strong>也应包含有关系统内的<strong>文件信息</strong>。这些信息保存在<strong>设备目录</strong>（device directory）或<strong>卷目录表</strong>（volume table of content）中。</p>
<p>设备目录（更常称为<strong>目录</strong>（directory））记录卷上的所有文件的信息，如名称、位置、大小和类型等。图10-7显示了一个典型的文件系统结构。</p>
<center> <img src="./osimg/典型文件系统结构.png"> </center>

<p>除通用文件系统外，还有专门的文件系统，如Solaris文件系统</p>
<center> <img src="./osimg/solaris文件系统.png"> </center>

<p>一下简述Solaris示例的文件系统类型：</p>
<center> <img src="./osimg/solaris.png"> </center>

<p>文件系统可以包含在另一个文件系统中。</p>
<h4 id="10-3-2-目录概述"><a href="#10-3-2-目录概述" class="headerlink" title="10-3-2 目录概述"></a>10-3-2 目录概述</h4><p><strong>目录</strong>可视为符号表，可<strong>将文件名称转成目录条目</strong>, 是<strong>目录条目的容器</strong>.</p>
<p><strong>目录条目包含更多的文件属性和关联信息</strong></p>
<p>当考虑特定目录结构时，不能忘记<strong>可对目录执行的操作</strong>：</p>
<ul>
<li><strong>搜索文件</strong>：需要能够搜索目录结构，以查找特定文件的条目。也可能需要搜索符合条件的所有文件。</li>
<li><strong>创建文件</strong>：需要创建新的文件，并<strong>添加到目录</strong>。</li>
<li><strong>删除文件</strong>：当不再需要文件时，希望能够<strong>从目录中删除它</strong>。</li>
<li><strong>遍历目录</strong>：需要能够<strong>遍历目录内的文件</strong>，及其目录内<strong>每个文件的目录条目的内容</strong>。</li>
<li><strong>重命名文件</strong>：文件可改变名称，目录和目录条目也应该改变。重命名文件也<strong>允许改变其在目录结构内的位置</strong>。</li>
<li><strong>遍历文件系统</strong>：可能希望<strong>访问每个目录和目录结构内的每个文件</strong></li>
</ul>
<h4 id="10-3-3-单级目录"><a href="#10-3-3-单级目录" class="headerlink" title="10-3-3 单级目录"></a>10-3-3 单级目录</h4><p>最简单的目录结构是<strong>单级目录</strong>。所有文件<strong>都包含在同一目录中</strong>. </p>
<center> <img src="./osimg/单级目录.png"> </center>

<p>当文件数量增加或系统有多个用户时，单级目录有重要的限制。因为所有文件位于同一目录中，它们必须具有唯一的名称。如果两个用户都命名数据文件为test.txt，则违反唯一名称规则. </p>
<p>幸运的是，大多数文件系统支持长达255个字符的文件名，因此选择唯一的文件名称还是相对容易的。(将重名的test.txt命名为test1.txt)</p>
<h4 id="10-3-4-两级目录"><a href="#10-3-4-两级目录" class="headerlink" title="10-3-4 两级目录"></a>10-3-4 两级目录</h4><p><strong>单级目录常常导致混乱的文件名</strong>。标准的解决方案是为<strong>每个用户创建一个单独的目录</strong>。</p>
<p>两级目录结构的<strong>每个用户都有自己的用户文件目录</strong>（User File Directory,<strong>UFD</strong>）。每个UFD内为单个用户文件的单级目录. <strong>用户作业开始或用户登录时</strong>，搜索<strong>系统的主文件目录</strong>（Master File Directory, <strong>MFD</strong>）。通过<strong>用户名或账户可索引MFD</strong>，每个条目指向该用户的UFD（图10-10）。</p>
<center> <img src="./osimg/两级目录.png"> </center>

<p>当<strong>用户引用特定文件时，只搜索他自己的UFD</strong>。因此，不同用户可能拥有相同名称的文件，只要每个UFD中的所有文件名都是唯一的。用户<strong>增删文件都只会在当前的UFD中进行检查</strong>。不会删除别的用户的同名文件。</p>
<p><strong>用户目录本身必须根据需要加以创建和删除</strong>。这可运行一个<strong>特别的系统程序</strong>，再加上适当的用户名和账户信息。该<strong>程序创建一个新的UFD，并在MFD中为其增加一项</strong>。这个程序的执行可能仅限于系统管理员。</p>
<p>虽然两级目录结构解决了名称碰撞问题，但是它仍然有缺点。这种结构有效地<strong>将不同用户隔离</strong>。用户需要完全独立时，隔离是个优点。当用户需要在某个任务上进行合作并且访问彼此的文件时，隔离却是个缺点。部分系统不允许其他用户访问自己的文件。</p>
<p>若要<strong>访问其他用户的文件</strong>，可以采用其他用户的用户名+文件名来访问。两级目录可以视作高度为2的树或倒置树。树根是MFD；树根的直接后代为UFD；UFD的后代为文件本身，文件为树的叶。指定用户名和文件名，定义了在树中从根（MFD）到叶（指定的文件）的路径。因此, <strong>用户名和文件名定义了路径名</strong>. 系统内的每个文件都有一个路径名。为了<strong>唯一地命名文件，用户必须知道所需文件的路径名</strong>。</p>
<p>此外，对于系统文件，若在每个UFD里都创建一个副本，那十分浪费空间。<br>这时，我们可以<strong>创建一个特殊用户</strong>，它内部存储系统文件。每当<strong>需要加载给定名称的文件时</strong>，操作系统<strong>首先搜索本地UFD</strong>。如果找到，则使用它。如果没有找到，系统<strong>自动搜索包含系统文件的特殊用户目录</strong>。用于搜索给定名称的文件所用的<strong>目录序列</strong>称为<strong>搜索路径</strong>（search path）。</p>
<h4 id="10-3-5-树形目录"><a href="#10-3-5-树形目录" class="headerlink" title="10-3-5 树形目录"></a>10-3-5 树形目录</h4><p>树形目录<strong>允许用户创建自已的子目录并相应地组织文件</strong>. 是最常见的目录结构，有一个根目录，系统内的每个文件都有唯一的路径名。</p>
<center> <img src="./osimg/树形目录.png"> </center>

<p><strong>目录（或子目录）包括一组文件或子目录</strong>。目录只不过<strong>是特殊方式处理的文件</strong>。所有<strong>目录具有同样的内部格式</strong>。每个<strong>目录条目都有一位来将条目定义为文件（0）或子目录（1）</strong>。通过特殊的系统调用，可创建和删除目录。</p>
<p>在常规使用时，每个<strong>进程</strong>都有一个<strong>当前目录</strong>。当前目录(current directory)<strong>包括进程当前感兴趣的大多数文件</strong>。当引用一个文件时，就搜索当前目录。如果所需文件<strong>不在当前目录</strong>中，那么用户<strong>通常必须指定一个路径名</strong>或<strong>将当前目录改变为包括所需文件的目录</strong>。为了改变目录，用户可使用<strong>系统调用以重新定义当前目录</strong>，该系统调用需要有一个目录名作为参数。因此，每当需要时，用户就可以改变当前目录。从一个系统调用change_directory()到下一个，所有<strong>open()系统调用搜索当前目录，以查找指定文件</strong>。注意，搜索路径可以包含或不包含代表当前目录的一个特殊条目。</p>
<p>当用户进程开始时或用户登录时，用户<strong>登录shell的初始当前目录是指定的</strong>。操作系统搜索<strong>账户文件</strong>（或其他预先定义的位置），以得到该用户的相关条目（以便于记账）。账户文件有<strong>用户初始目录的指针</strong>（或名称）。该指针可<strong>复制到此用户的局部变量，以指定初始当前目录</strong>(让他指向指定当前目录)。这个外壳可以产生其他进程。任何<strong>子进程的当前目录通常是生成它时的父进程的当前目录</strong>。</p>
<p>路径名可有两种形式: <strong>绝对路径名和相对路径名</strong></p>
<ul>
<li><strong>绝对路径名</strong>: 遵循一个路径到指定文件，并<strong>给出路径上的目录名</strong>。</li>
<li><strong>相对路径名</strong>: 从<strong>当前目录开始</strong>，定义一个路径</li>
</ul>
<p>如果当前目录是root&#x2F;spell&#x2F;mail，则相对路径名为prt&#x2F;first与绝对路径名root&#x2F;spell&#x2F;mail&#x2F;prt&#x2F;first指向同一文件。</p>
<p>树形目录的删除有两种，第一种要求<strong>目录仅当为空</strong>时, <strong>包含他的目录条目可以删除</strong>. 这就要求<strong>递归的删除</strong>目录下的所有子目录和文件。另一种，如UNIX的rm命令，提供选项：请求删除目录时，所有目录的文件和子目录也被删除。尽管后一种方便，但是会删除整个目录结构，误用会导致大量的恢复工作。</p>
<h4 id="10-3-6-无环图目录"><a href="#10-3-6-无环图目录" class="headerlink" title="10-3-6 无环图目录"></a>10-3-6 无环图目录</h4><h5 id="共享文件"><a href="#共享文件" class="headerlink" title="共享文件"></a>共享文件</h5><p>有时我们希望一个目录能<strong>被多个用户共享</strong>。这<strong>要求目录同时存在于文件系统的多个地方</strong>。</p>
<p><strong>树结构禁止共享文件或目录</strong>. <strong>无环图</strong>（acyclic graph），即没有循环的图, <strong>允许目录共享子目录和文件</strong>（图10-12）。同一文件或子目录可出现在两个不同目录中。无环图<strong>是树形目录方案的自然扩展</strong>. </p>
<center> <img src="./osimg/无环图目录.png"> </center>

<p><strong>共享的文件（或目录）不同于该文件的两个副本</strong>, 对于一个共享文件，只存在一个实际的文件因此一个用户所做的<strong>任何更改都会立即为其他用户所看到</strong>。共享对于子目录尤其重要；由一个用户创建的新文件会自动地出现在所有的共享子目录。</p>
<p>共享文件和目录的实现方法可以有多个。一种常见的方式是<strong>创建一个名为链接的新目录条目</strong>, 链接（link）实际上<strong>是另一文件或子目录的指针</strong>。例如，链接可以用绝对路径或相对路径的名称来实现。当引用一个文件时，就搜索目录。如果目录条目标记为链接，则真实文件的名称包括在链接信息中。通过采用该路径名来解决（resolve）链接，定位真实文件。在<strong>遍历目录树</strong>时，操作系统<strong>忽略这些链接以维护系统的无环结构</strong>。</p>
<p><strong>也就是说发现目录条目为链接时，会继续寻找里面的真实地址，共享文件可以在任意位置有一个物理实体，其他地方只是链接到这里。这可以通过绝对地址导航做到</strong></p>
<p>另一个常见方法是在两个共享目录中<strong>复制有关它们的所有信息</strong>。两个<strong>条目相同且相等</strong>，但<strong>链接显然不同于原来的目录条目</strong>。因此，两者不相等。复制目录条目的一个主要问题是，在修改文件时要<strong>维护一致性</strong>。修改需要即时更新。</p>
<p>无环图目录的结构比简单的树结构更灵活但也更复杂. 文件现在可以<strong>有多个绝对路径名</strong>。因此，不同的文件名可以指相同的文件。当试图遍历整个文件系统，如查找一个文件、统计所有文件或将所有文件复制到备份存储等，这个问题变得重要，因为<strong>我们不想不止一次地遍历共享结构</strong>。(采用链接可以较为简单的解决这个问题)</p>
<h5 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a>删除文件</h5><p>另一个问题涉及删除。一种可能性是，只要<strong>有用户删除它时，就删除它</strong>；但是这种操作<strong>可能留下悬挂指针</strong>，以<strong>指向现在不存在的文件</strong>(共享链接未删除)。更糟糕的是，如果<strong>剩余文件指针包含实际磁盘地址</strong>，而空间随后被<strong>重用</strong>于其他文件，这些<strong>悬挂指针可能指向其他文件的中间</strong>。</p>
<p>在通过<strong>符号链接</strong>(就是链接)实现共享的系统中，这种情况较易处理。删除链接不需要影响原始文件：而只有链接被删除。如果<strong>文件条目本身被删除，文件的空间就被释放，链接就悬空</strong>。我们可以<strong>搜索这些链接</strong>并<strong>删除</strong>它们，但是除非每个文件都保持一个关联的链接列表，否则这种<strong>搜索可能是昂贵</strong>的。或者，可以<strong>先不管这些链接</strong>，直到<strong>尝试使用</strong>它们时可以<strong>检测由链接给出名称的文件不存在</strong>，从而不能解析链接名称；访问被视作文件名称是非法的。(懒更新)</p>
<p>另一种删除方法是<strong>保留文件，直到它的所有引用都被删除</strong>。为了实现这种方法，必须有一种机制来确定文件的最后一个引用已被删除。为每个文件（目录条目或符号链接），可以保留所有引用的一个列表。当<strong>创建目录条目的链接或副本时，会向文件引用列表添加一个新的条目</strong>。当删除链接或目录条目时，会从列表上删除它的条目。当文件引用列表为空时，会删除这个文件。</p>
<p><strong>引用个数就是能到达文件节点的路径数，每个文件节点初始引用为1，肯定存在一条到它的路</strong></p>
<p>由于保留列表太占空间，可以使用计数替换。</p>
<h4 id="10-3-7-通用图目录"><a href="#10-3-7-通用图目录" class="headerlink" title="10-3-7 通用图目录"></a>10-3-7 通用图目录</h4><p><strong>通用图目录可能有环</strong></p>
<center> <img src="./osimg/通用图目录.png"> </center>

<p><strong>无环图的主要优点</strong>是，有相对简单的算法以遍历图并确定何时没有更多的文件引用.</p>
<p>需要避免重复遍历无环图的共享部分，主要出于性能原因。如果刚刚搜索了一个主要的共享子目录以查找特定文件，但是没有找到它，则需要避免再次搜索该子目录；再次搜索会浪费时间。</p>
<p>如果允许目录中有环, 更需要注意重复遍历和搜索的问题，可能导致无穷搜索。一种解决方案是可以<strong>限制在搜索时访问目录的数量</strong>(超过限制直接退出)。</p>
<p>当<strong>试图确定什么时候可删除某个文件</strong>时，类似问题也存在。对于无环图目录结构，引用计数为0意味着没有文件或目录的引用，可以删除该文件。然而，当<strong>存在环</strong>时，即使<strong>不再可能引用一个目录或文件时，引用计数也可能不为0</strong>。这种异常源自目录中可能<strong>存在自我引用</strong>的缘故。这时需要使用<strong>垃圾收集</strong>（garbage collection）方案，以确定何时最后引用已被删除并重新分配磁盘空间。垃圾收集涉及遍历整个文件系统，并标记所有可访问的。接着，第二次遍历收集所有未标记的到空闲空间列表。这<strong>非常费时</strong>。</p>
<h3 id="10-4-文件系统安装"><a href="#10-4-文件系统安装" class="headerlink" title="10-4 文件系统安装"></a>10-4 文件系统安装</h3><p>文件系统在用于系统的进程之前必须先安装（mount）。</p>
<p>安装过程很简单。操作系统<strong>需要知道设备的名称</strong>和<strong>安装点</strong>（mount point）（附加文件系统在原来文件结构中的位置）。有的操作系统要求提供文件系统类型；而其他检查设备结构并确定文件系统的类型。通常，安装点是<strong>空目录</strong>。</p>
<p>例如，在UNIX系统上，包含用户主目录的文件系统可能安装到&#x2F;home；然后，当<strong>访问该文件系统的目录结构</strong>时，只要在目录名称之前加上&#x2F;home，如&#x2F;home&#x2F;jane。当该文件系统安装在&#x2F;users下时，通过路径名&#x2F;users&#x2F;jane可以使用同一个目录。</p>
<p>接下来，操作系统<strong>验证设备包含一个有效的文件系统</strong>。验证可这样进行：通过设备驱动程序读入设备目录，并验证目录具有预期格式。最后，操作系统<strong>在其目录结构中记录如下信息：一个文件系统已安装在给定安装点上</strong>。</p>
<p>为了说明文件系统的安装，考虑如图10-14所示的文件系统，其中三角形表示所感兴趣的目录子树。图10-14a显示了一个现有文件系统，而图10-14b显示了一个未安装的位于&#x2F;device&#x2F;dsk上的文件系统。这时，只有现有文件系统上的文件可被访问。图10-15显示了将&#x2F;device&#x2F;dsk上的卷安装到&#x2F;users后的文件系统的效果。如果该卷被卸载，则文件系统将还原到如图10-14所示的情况。</p>
<center> <img src="./osimg/安装文件系统.png"> </center>

<p><strong>系统通过语义可以清楚地表达功能</strong>。例如，系统可能不允许在包含文件的目录上进行安装；或者可以使安装的文件系统在该目录处可用，并隐藏目录的原有文件；直到文件系统被卸载，进而终止使用文件系统，并且允许访问该目录中的原有文件. (按系统的要求可以有不同的需求和表现)</p>
<h3 id="10-5-文件共享"><a href="#10-5-文件共享" class="headerlink" title="10-5 文件共享"></a>10-5 文件共享</h3><h4 id="10-5-1-多用户"><a href="#10-5-1-多用户" class="headerlink" title="10-5-1 多用户"></a>10-5-1 多用户</h4><p>当操作系统支持多个用户时，文件共享、文件命名和文件保护等问题就尤其突出了。对于允许用户共享文件的目录结构，系统必须调控文件共享。可以默认允许共享或需要许可。</p>
<p>多用户系统需要更多的属性以保证<strong>保护和共享</strong>，大多数系统都采用了文件（或目录）所有者（owner）（或用户（user））和组（group）的概念来进行实现：</p>
<ul>
<li>文件(或目录)<strong>所有者&#x2F;用户</strong>: 能更改属性和授予访问权限，拥有<strong>最高控制</strong></li>
<li><strong>组</strong>: 属性定义<strong>用户子集</strong>，他们拥有<strong>相同的访问权限</strong></li>
<li><strong>其他用户</strong>: 执行另一操作子集, 有<strong>不同与组成员的权限</strong></li>
</ul>
<p>给定文件（或目录）的所有者和组ID，与其他文件属性一起存储。当用户请求操作文件时，用户ID可以与所有者属性进行比较，以便确定该请求用户是否是文件所有者。同样，可以比较组ID。结果表明哪些权限适用. (<strong>根据ID决定操作</strong>)</p>
<h4 id="10-5-2-远程文件系统"><a href="#10-5-2-远程文件系统" class="headerlink" title="10-5-2 远程文件系统"></a>10-5-2 远程文件系统</h4><p>有三种主要实现方法：</p>
<ul>
<li>通过<strong>如ftp程序</strong>在机器之间<strong>手动传送文件</strong>。</li>
<li>通过<strong>分布式文件系统</strong>（Distributed File System, <strong>DFS</strong>），<strong>远程目录从本机上可直接访问</strong></li>
<li><strong>万维网</strong>（World Wide Web, <strong>WWW</strong>），在某些方面回到了第一种. <strong>通过浏览器才能访问远程文件</strong>，每次文件<strong>传输需要一个单独操作</strong>（基本上是fip的封装）。</li>
</ul>
<p>云计算（1.11.7节）也越来越多地用于文件共享。</p>
<p>ftp用于<strong>匿名和认证的访问</strong>. <strong>匿名访问</strong>（anonymous access）允许用户在<strong>没有远程系统账户</strong>的情况下传输文件. WWW几乎完全采用<strong>匿名的文件交换</strong>。DFS在访问远程文件的机器和提供文件的机器之间提供了更加紧密的集成. 增加了复杂性。</p>
<h5 id="10-5-2-1-客户机-服务器模型"><a href="#10-5-2-1-客户机-服务器模型" class="headerlink" title="10-5-2-1 客户机-服务器模型"></a>10-5-2-1 客户机-服务器模型</h5><p>远程文件系统<strong>允许一台计算机安装一台或多台远程机器上的一个或多个文件系统</strong>. 在这种情况下，包含文件的机器是<strong>服务器</strong>（server），需要访问文件的机器是<strong>客户机</strong>（client）. 一台服务器可以服务多台客户机，而一台客户机可使用多台服务器，具体取决于给定客户机一服务器的实现细节。</p>
<p>服务器通常根据<strong>卷或目录的级别</strong>来<strong>指定哪些文件可用</strong>。识别客户更加困难。指定客户可以采用网络名称或其他标识符，例如IP地址，但是这些<strong>可以被欺骗（spoofed）或模仿</strong>。更加安全的解决方案包括通过加密密钥来安全认证客户端，但是<strong>确保客户机和服务器的兼容性(使用相同的加密算法)，密钥交换的安全性(密钥可能被拦截)1</strong>是新的困难。因此大多认证是非安全的。</p>
<p>对于UNIX及其网络文件系统（NFS），认证默认通过客户网络信息来进行。客户端和服务器的用户ID必须匹配，否则拒绝访问。</p>
<p>安装了远程文件系统，用户的<strong>文件操作请求通过网络按照DFS协议发送到服务器</strong>。通常，一个文件打开请求与其请求用户的ID会一起发送. 如果允许， 则<strong>文件句柄(指针)会返回到客户机的应用程序</strong>，然后应用程序就可以对文件执行读、写和其他操作。</p>
<h5 id="10-5-2-2-分布式信息系统"><a href="#10-5-2-2-分布式信息系统" class="headerlink" title="10-5-2-2 分布式信息系统"></a>10-5-2-2 分布式信息系统</h5><p>为了<strong>更易管理客户机-服务器系统</strong>, <strong>分布式信息系统</strong>（distributed information system）也称为<strong>分布式命名服务</strong>（distributed naming service），对远程计算所需信息提供统一访问. </p>
<p>其他分布式信息系统为分布式应用提供了用户名称&#x2F;密码&#x2F;用户ID&#x2F;组ID空间。UNIX系统采用了各种各样的分布式信息方法</p>
<p>以下为几种分布式信息系统的例子</p>
<p>Sun Microsystems（现在是Oracle公司的一部分）引人了<strong>黄页</strong>（yellow page）（后来改名为<strong>网络信息服务</strong>（Network Information Service，NIS）），并且业界大多数都采用了它。它集中存储用户名、主机名、打印机信息等。使用的是<strong>非安全的认证</strong>方法，包括发送未加密的用户密码（以<strong>明文</strong>形式）和通过<strong>IP地址标识主机</strong>. NIS+是更为安全的NIS升级，但是也更为复杂，且并未得到广泛使用。</p>
<p>Microsoft的<strong>通用互联网文档系统</strong>（Common Internet File System, <strong>CIFS</strong>），网络信息与<strong>用户认证信息（用户名和密码）一起进行网络登录</strong>，以便服务器确定是否允许或拒绝对所请求文件系统的访问. 为了使得认证有效，用户名必须在机器之间匹配（如同NFS一样）。Microsoft使用<strong>活动目录</strong>（active directory）作为分布式命名结构，以便为用户提供单一的名称空间。</p>
<p>业界正在采用<strong>轻量级目录访问协议</strong>（Lightweight Directory Access Protocol, <strong>LDAP</strong>）作为安全的分布式命名机制。事实上，活动目录是基于LDAP的。</p>
<h5 id="10-5-2-3-故障模式"><a href="#10-5-2-3-故障模式" class="headerlink" title="10-5-2-3 故障模式"></a>10-5-2-3 故障模式</h5><p>本地文件系统的故障原因可能很多，如包含文件系统的磁盘故障、<strong>目录结构或其他磁盘管理信息</strong>（总称为<strong>元数据</strong>（metadata））的损坏、磁盘控制器的故障、电缆故障和主机适配器故障等。</p>
<p>远程文件系统的故障模式甚至更多。由于网络系统的复杂性和远程机器之间的所需交互，更多的问题可能会干扰远程文件系统的正确操作. 任何单个故障都可以中断DFS命令流。</p>
<p>考虑一个客户机正在使用远程文件系统。它打开了远程主机的文件；除了许多其他动作，它可能执行目录查找以打开文件、读写文件数据和关闭文件。现在，假设<strong>网络断开、服务器故障，甚至服务器的计划关机等</strong>。突然，远程文件系统不再可用。这种情况相当普遍，所以<strong>客户系统不应将其按本地文件系统的丢失一样来处理</strong>。相反，系统<strong>可以终止对丢失服务器的所有操作，或延迟操作，直到服务器再次可用</strong>为止。这种故障语义作为远程文件系统协议的一部分来定义和实现。所有<strong>操作的终止可以导致用户失去数据和耐心。因此，大多数DFS协议强制或允许延迟操作远程主机的文件系统，以寄希望于远程主机会再次可用</strong>. </p>
<p>为了<strong>实现这种故障恢复</strong>，可能要在客户机和服务器上<strong>维护一定的状态信息</strong>（state information）。如果服务器和客户机都拥有当前活动和打开文件的知识，则他们可以无缝地进行故障恢复。</p>
<p>当服务器崩溃但必须<strong>认识到它有被远程安装的已导出的文件系统和已打开的文件</strong>时，NFS采取了一种简单方法，即实现<strong>无状态（stateless）的DFS</strong>。</p>
<p>假设：除非已经远程安装了文件系统，且以前已打开了文件，否则有关文件读写的客户请求将不会发生。NFS协议携带所有需要的信息，以便定位适当文件并执行请求操作。同样，它并不跟踪哪个客户安装了导出卷，而是再次假设：如果来了请求，则它必须合法。然这种无状态方法使NFS具有弹性并容易实现，但是它并不安全, 可能允许伪造的读或写请求. 行业标准的NFS版本4解决了这些问题，这里的NFS是有状态的，以提高安全性、性能和功能。</p>
<h4 id="10-5-3-一致性语义"><a href="#10-5-3-一致性语义" class="headerlink" title="10-5-3 一致性语义"></a>10-5-3 一致性语义</h4><p><strong>一致性语义</strong>（consistency semantic）是评估支持文件共享的文件系统的重要准则。特别地，它们<strong>规定了一个用户的数据修改何时为另一用户可见</strong>。这些语义通常由<strong>文件系统代码来实现</strong>的。</p>
<p>一致性语义与第6章的进程同步算法直接相关。然而，由于磁盘和网络的巨大延迟和很慢的传输速率，第6章的复杂算法往往并不适合文件I&#x2F;O操作。例如，对远程磁盘执行一个原子事务可能涉及多次网络通信(因为丢包)、多次磁盘读写，或两者。成功实现了复杂共享语义的一个文件系统是Andrew文件系统（AFS）。</p>
<p>在下面的讨论中，假设用户尝试的一系列文件访问（即读取和写人）总是包含在操作open（）和close（）之间。在<strong>操作open（）和close（）之间的一系列访问称为文件会话</strong>（file session）。为了说明语义概念，下面简要介绍几个典型的一致性语义示例。</p>
<h5 id="10-5-3-1-unix语义"><a href="#10-5-3-1-unix语义" class="headerlink" title="10-5-3-1 unix语义"></a>10-5-3-1 unix语义</h5><p>UNIX系统使用以下的一致性语义：</p>
<ul>
<li>一个用户对已打开文件的<strong>写入</strong>，对于打开同一文件的<strong>其他用户立即可见</strong></li>
<li>一种共享模式<strong>允许用户共享文件的当前位置指针</strong>。因此，一个用户前移指针就会<strong>影响所有共享用户</strong>。这里，一个文件具有单个图像，允许来自不同用户的交替访问。</li>
</ul>
<p>采用UNIX语义，一个<strong>文件与单个物理图像相关联</strong>，可作为独占资源访问。争用这种单个图像<strong>导致用户进程的延迟</strong>。</p>
<h5 id="10-5-3-2-会话语义"><a href="#10-5-3-2-会话语义" class="headerlink" title="10-5-3-2 会话语义"></a>10-5-3-2 会话语义</h5><p>Andrew文件系统（OpenAFS）采用以下一致性语义：</p>
<ul>
<li>一个用户对已打开文件的<strong>写入</strong>，对于打开同一文件的<strong>其他用户不是立即可见</strong>。</li>
<li>一旦<strong>文件关闭</strong>，对其所做的<strong>更改只能被后来打开的会话可见</strong>。已打开的文件实例并不反映这些变化。</li>
</ul>
<p>根据这类语义，一个<strong>文件在同一时间可以临时关联多个（可能不同的）图像</strong>。因此，允许多个用户<strong>同时对它们的文件图像执行读写访问</strong>，没有延迟。调度访问几乎没有强制约束。</p>
<h5 id="10-5-3-3-不可变共享文件语义"><a href="#10-5-3-3-不可变共享文件语义" class="headerlink" title="10-5-3-3 不可变共享文件语义"></a>10-5-3-3 不可变共享文件语义</h5><p>一旦一个<strong>文件由创建者声明为共享</strong>，它就<strong>不能被修改</strong>。</p>
<p>有两个关键属性：</p>
<ul>
<li>它的名称不可以重用</li>
<li>它的内容不可以改变。</li>
</ul>
<p>这种语义的实现在分布式系统较为简单，但感觉好废。</p>
<h3 id="10-6-保护"><a href="#10-6-保护" class="headerlink" title="10-6 保护"></a>10-6 保护</h3><h4 id="10-6-1-访问类型"><a href="#10-6-1-访问类型" class="headerlink" title="10-6-1 访问类型"></a>10-6-1 访问类型</h4><p>保护机制<strong>通过限制可以进行的文件访问类型提供受控访问</strong>。访问的允许或拒绝取决于多个因素，其中之一是<strong>请求访问的类型</strong>。可以控制多个不同的操作类型：</p>
<ul>
<li><strong>读</strong>：从文件中读取</li>
<li><strong>写</strong>：写或重写文件</li>
<li><strong>执行</strong>：加载文件到内存并执行它</li>
<li><strong>附加</strong>：在文件末尾写入新的信息</li>
<li><strong>删除</strong>：删除文件，并释放空间以便重复使用</li>
<li><strong>列表</strong>：列出文件的名称和属性。</li>
</ul>
<p><strong>更高级的控制可以由这些低级的系统调用实现</strong>，复制文件的请求可以由一系列读请求实现。此时，具有读访问权限的用户也可以复制文件和打印。</p>
<h4 id="10-6-2-访问控制"><a href="#10-6-2-访问控制" class="headerlink" title="10-6-2 访问控制"></a>10-6-2 访问控制</h4><p><strong>访问控制列表 | 所有者、组和其他的访问控制 | 位记录用户权限</strong></p>
<p>最常见的就是<strong>根据用户身份</strong>控制访问。</p>
<p>基于身份访问的最为普通的实现方法是，为每个<strong>文件和目录关联一个访问控制列表</strong>（Access-ControlList, <strong>ACL</strong>），以<strong>指定每个用户的名称及其允许的访问类型</strong>。操作系统将检查与该文件关联的访问列表来确定是否允许访问。</p>
<p>这种方法的<strong>优点能够进行复杂的访问方法</strong>。访问列表的<strong>主要问题是它们的长度</strong>。如果允许每个用户都能读取一个文件，则必须列出所有具有读取访问权限的用户。这种技术有两个不可取的后果：</p>
<ul>
<li><strong>构造列表</strong>可能是一个长乏味的任务，尤其是在事先不知道系统的用户列表时。</li>
<li><strong>目录条目</strong>，以前是固定大小的，现在必须是<strong>可变大小</strong>的，从而导致<strong>更为复杂的空间管理</strong>。</li>
</ul>
<p>通过采用精简的访问列表，可以解决这些问题. 为了精简访问列表，许多系统为每个文件采用了三种用户类型：</p>
<ul>
<li><strong>所有者</strong>：创建文件的用户为所有者, 有<strong>最高权限</strong>。</li>
<li><strong>组</strong>：共享文件并且<strong>需要类似访问</strong>的一组用户是组或工作组（work group）。</li>
<li><strong>其他</strong>：系统内的所有其他用户。</li>
</ul>
<p>现在，最为常用的方法是，将<strong>访问控制列表与所有者、组和其他的访问控制方案一起组合使用</strong>。例如，Solaris缺省使用三种类型的访问；但是，当需要<strong>更细粒度</strong>的访问控制时，可以允许为特定的文件和目录**添加访问控制列表(ACL)**。</p>
<p>这种方案工作必须严格控制许可和访问的列表，对于UNIX系统，只有管理员或超级用户可以创建和修改组。</p>
<p>对于<strong>更为有限的保护分类</strong>，只需要<strong>三个域</strong>就可定义保护。例如，UNIX系统定义了三个域，每个域为三个位：rwx，其中r控制读访问，w控制写访问，而x控制执行。文件的<strong>所有者、文件的组以及所有其他用户各有一个单独的域</strong>。采用这种方法，每个<strong>文件需要9位来记录保护信息</strong></p>
<p>组合方法的困难之一是用户接口。用户必须能够<strong>区分一个文件是否有可选的ACL许可</strong>。在Solaris例子中，普通许可之后的“+”表示有可选的ACL许可。如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">19 -rw-r--r--+ 1 jim staff 130 May 25 22:13 file1</span><br><span class="line">rw- | r-- | r-- 三个</span><br></pre></td></tr></table></figure>
<p>Windows则可通过GUI管理访问控制列表。</p>
<p>另一个困难是，当<strong>权限和ACL冲突时哪个优先</strong>, 一般都允许ACL优先，毕竟特殊性应该优先。</p>
<h4 id="10-6-3-其他保护方式"><a href="#10-6-3-其他保护方式" class="headerlink" title="10-6-3 其他保护方式"></a>10-6-3 其他保护方式</h4><p>为每个文件加上密码，这也是一种保护，但很显然不切实际。</p>
<p>对于<strong>多级目录结构</strong>，不仅需要保护单个文件，而且<strong>需要保护子目录的文件集合</strong>；也就是说，需要<strong>提供目录保护</strong>的一种机制。需要<strong>控制在目录中创建和删除文件</strong>。此外，可能需要<strong>控制一个用户能否确定在某个目录中存在某个文件</strong>。这需要提供<strong>列表</strong>（列出目录内容）操作的权限限制。若用户没有访问一个目录的权限，它也不能访问目录内的子目录和文件。</p>
<p>对于<strong>支持一个文件可有多个路径名的系统</strong>（采用无环图和一般图），根据<strong>所用路径名</strong>的不同，对<strong>同一个文件，一个用户可能具有不同的访问权限</strong>。</p>
<h2 id="11-文件系统实现"><a href="#11-文件系统实现" class="headerlink" title="11 文件系统实现"></a>11 文件系统实现</h2><p><strong>构思编排，建议先看12章</strong></p>
<h3 id="11-1-文件系统结构"><a href="#11-1-文件系统结构" class="headerlink" title="11-1 文件系统结构"></a>11-1 文件系统结构</h3><p>磁盘提供大多数的外存，以便维护文件系统。磁盘具有两个优势：</p>
<ul>
<li>可以<strong>原地重写</strong>；可以从磁盘上读取一块，修改该块，并写回到原来的位置。</li>
<li>可以<strong>直接访问它包含信息的任何块</strong>(允许随机访问)。因此，可以简单按顺序或随机地访问文件；并且从一个文件切换到另一个文件只需移动读写磁头，并且等待磁盘旋转。</li>
</ul>
<p>为了<strong>提高I&#x2F;O效率</strong>，内存和磁盘之间的I&#x2F;O传输以<strong>块（block）为单位</strong>执行。每个<strong>块具有一个或多个扇区</strong>。根据磁盘驱动器的不同，扇区大小从32字节到4096字节不等，通常为512字节。</p>
<p><strong>文件系统</strong>（file system）提供高效和便捷的磁盘访问，以便允许轻松存储、定位、提取数据。其设计主要有两个问题。</p>
<p>第一个问题是，如何<strong>定义文件系统的用户接口</strong>。这个任务涉及定义文件及其属性、所允许的文件操作、组织文件的目录结构。</p>
<p>第二个问题是，创建<strong>算法和数据结构</strong>，以便<strong>映射逻辑文件系统到物理外存设备</strong>。</p>
<p>文件系统通常分层设计，以方便支持更多的设计并减少重复代码。</p>
<center> <img src="./osimg/分层设计的文件系统.jpg"> </center>

<p>这些层从下到上分为：</p>
<ul>
<li><strong>I&#x2F;O控制</strong>（I&#x2F;O control）层: 包括<strong>设备驱动程序</strong>和<strong>中断处理程序</strong>，以在<strong>主内存和磁盘系统之间传输信息</strong>。<ul>
<li><strong>设备驱动程序</strong>可以作为<strong>翻译器</strong>。它的<strong>输入为高级命令</strong>，如“检索块123”。它的<strong>输出由底层的、硬件特定的指令组成</strong>, <strong>硬件控制器</strong>利用这些指令来使I&#x2F;O设备与系统其他部分相连。设备驱动程序通常在I&#x2F;O控制器的特定位置写入特定位格式，告诉控制器对设备的什么位置采取什么动作。</li>
</ul>
</li>
<li><strong>基本文件系统</strong>（basic filesystem）: 向适当设备驱动程序<strong>发送通用命令</strong>，以读取和写入磁盘的物理块。每个物理块由磁盘的数字地址来标识（例如，驱动器（device）1、柱面（cylinder）73、磁道（track）3、扇区（sector）10）。<ul>
<li>也<strong>管理内存缓冲区</strong>和<strong>保存各种文件系统、目录和数据块的缓存</strong>。在进行磁盘块传输之前，分配一块缓冲区。当缓冲区已满时，缓冲管理器必须找到更多缓冲内存或释放缓冲空间，以便允许完成I&#x2F;O请求。缓存用于保存常用的文件系统元数据，以提高性能；因此管理它们的内容对于系统性能优化至关重要。</li>
</ul>
</li>
<li><strong>文件组织模块</strong>（file-organization module）: 知道文件及其逻辑块以及物理块. 可以<strong>将逻辑块地址转成物理块地址</strong>，以供基本文件系统传输。<ul>
<li>文件组织模块还<strong>包括可用空间管理器</strong>，以跟踪未分配的块并根据要求提供给文件组织模块。</li>
</ul>
</li>
<li><strong>逻辑文件系统</strong>（logical file system）: <strong>管理元数据信息</strong>。元数据<strong>包括文件系统的所有结构</strong>，而<strong>不包括实际数据</strong>（或文件内容）。逻辑文件系统<strong>管理目录结构</strong>，以便根据给定文件名称为文件组织模块提供所需信息。<ul>
<li>它通过<strong>文件控制块来维护文件结构</strong>。文件控制块（File Control Block, <strong>FCB</strong>）包含有关文件的信息，包括所有者、权限、文件内容的位置等逻辑文件系统也负责保护.</li>
</ul>
</li>
</ul>
<p>分层实现的文件系统可以减少代码重复，底层的I&#x2F;O控制和基本文件系统可以为多个文件系统共用。但是多级调用增加了系统开销，因为不能跨级通信。</p>
<h3 id="11-2-文件系统实现"><a href="#11-2-文件系统实现" class="headerlink" title="11-2 文件系统实现"></a>11-2 文件系统实现</h3><h4 id="11-2-1-概述"><a href="#11-2-1-概述" class="headerlink" title="11-2-1 概述"></a>11-2-1 概述</h4><p>在磁盘上，文件系统可能包括如下信息：如何启动存储在那里的操作系统、总的块数、空闲块的数量和位置、目录结构以及各个具体文件等。这里简述如下：</p>
<ul>
<li>(每个卷的)<strong>引导控制块</strong>（boot control block）: 含从该卷<strong>引导操作系统的所需信息</strong>。如果磁盘不包含操作系统，则这块的内容为空。它<strong>通常为卷的第一块</strong>. UFS称其为引导块，NTFS称其为<strong>分区引导扇区</strong></li>
<li>(每个卷的)<strong>卷控制块</strong>（volume control block）: 包括卷（或分区）的<strong>详细信息</strong>，如分区的块的数量、块的大小、空闲块的数量和指针、空闲的FCB数量和FCB指针等。UFS称其为<strong>超级块</strong>，NTFS中它存储在<strong>主控文件表</strong>中</li>
<li>(每个文件系统的)<strong>目录结构</strong>: 用于<strong>组织文件</strong>，UFS中，它包含<strong>文件名和相关的inode的号码</strong>；在NTFS中，它存储在<strong>主控文件表</strong>中。</li>
<li><strong>文件的FCB</strong>包括该文件的许多详细信息。它有一个<strong>唯一的标识号</strong>，以便<strong>与目录条目相关联</strong>。NTFS中，这些信息实际上存储在主控文件表中，它使用关系数据库结构，每个文件占一行。</li>
</ul>
<p><strong>内存中的信息</strong>用于管理文件系统并通过<strong>缓存来提高性能</strong>。这些数据在安装文件系统时被加载，在文件系统操作期间被更新，在卸载时被丢弃。这些结构的类型可能包括：</p>
<ul>
<li>内存中的<strong>安装表</strong>（mount table）包含<strong>每个安装卷的有关信息</strong>。</li>
<li>内存中的<strong>目录结构的缓存</strong>含有最近访问目录的信息（对于加载卷的目录，它可以包括一个指向卷表的指针。）</li>
<li><strong>整个系统的打开文件表</strong>，包括每个<strong>打开文件的FCB的副本</strong>以及其他信息。</li>
<li><strong>每个进程的打开文件表</strong>，包括一个<strong>指向整个系统的打开文件表中的适当条目的指针</strong>，以及其他信息(与进程相关的信息，如访问控制和当前文件指针)。</li>
<li>磁盘<strong>读出或写入</strong>时，缓冲区保存文件系统的块。</li>
</ul>
<p>为了<strong>创建新的文件</strong>，应用程序<strong>调用逻辑文件系统</strong>。逻辑文件系统知道目录的格式。它会分配一个新的FCB(若预先创建，则分配一个空闲的FCB)。然后，系统将<strong>相应的目录读到内存</strong>，使用新的文件名和FCB进行更新，并将更新的目录<strong>写回到磁盘</strong>.</p>
<center> <img src="./osimg/FCB.png"> </center>

<p>部分系统，如UNIX目录完全按文件来处理，而用一个类型域来表示是否为目录。Windows则分开目录和稳健的系统调用。</p>
<h5 id="更完整的open-调用在系统内的过程"><a href="#更完整的open-调用在系统内的过程" class="headerlink" title="更完整的open()调用在系统内的过程"></a>更完整的open()调用在系统内的过程</h5><p>现在，一旦文件被创建，它就能用于I&#x2F;O。不过，首先，它应被打开。系统调用open（）将<strong>文件名传递到逻辑文件系统</strong>。系统调用open（）首先搜索整个系统的打开文件表，以便确定这个文件是否已被其他进程使用。如果是，则在单个进程的打开文件表中创建一个条目，并让其指向现有整个系统的打开文件表。该算法能节省大量开销。如果这个<strong>文件尚未打开</strong>，则<strong>根据给定的文件名来搜索目录结构</strong>。部分的目录结构通常缓存在内存中，以加速目录操作。在找到文件后，它的<strong>FCB会复制到内存的整个系统的打开文件表中</strong>。该表不但存储FCB，而且还跟踪打开该文件的进程的数量。（打开文件表储存FCB）</p>
<p>接下来，在<strong>单个进程的打开文件表中会创建一个条目，指向整个系统打开文件表的条目的一个指针</strong>，以及其他一些域。这些域可能包含文件的当前位置的指针（用于接下来的read（）或write（）操作）和打开文件的访问模式。调用open（）返回单个进程的打开文件表的适当条目的一个指针。以后，所有文件操作通过这个指针执行。文件名不必是打开文件表的一部分，因为一旦<strong>完成对FCB在磁盘上的定位，系统就不再使用文件名了</strong>。不过，它<strong>可以被缓存</strong>起来，以节省同一文件的后续打开时间. <strong>打开文件表的条目有多种名称</strong>。UNIX称之为<strong>文件描述符</strong>（file descriptor），Windows称之为<strong>文件句柄</strong>（file handle）。</p>
<p>当进程关闭文件时，它的单个进程表的条目会被删除，并且整个系统的条目的打开数量会被递减。当<strong>所有打开该文件的用户关闭它</strong>时，任何<strong>更新的元数据会被复制到基于磁盘的目录结构</strong>，并且整个系统的打开文件表的条目会被删除。</p>
<center> <img src="./osimg/内存中的文件系统.png"> </center>

<p><em>这两张图根本看不出什么东西</em></p>
<h4 id="11-2-2-分区和安装"><a href="#11-2-2-分区和安装" class="headerlink" title="11-2-2 分区和安装"></a>11-2-2 分区和安装</h4><p>磁盘布局可有多种，具体取决于操作系统。一个磁盘可以分成多个分区，或者一个卷可以跨越多个磁盘的多个分区(RAID).</p>
<p>分区可以是“生的”（或原始的，空白的），没有文件系统；或者“熟的”，含有文件系统。</p>
<p>分区没有文件系统时，可以使用<strong>原始磁盘</strong>（raw disk）。例如交换空间和数据库都会使用原始磁盘来绕过文件系统，提供更高的效率。</p>
<p><strong>引导信息可以存储在各自分区</strong>中，参见12.5.2节。再者，它有自己的格式，因为在<strong>引导时系统没有加载的文件系统代码</strong>，因此不能解释文件系统的格式。因此，引导信息<strong>通常是一系列连续的块，可作为映像加载到内存</strong>。引导加载程序应了解文件系统的结构来找到并加载内核，并开始执行它。</p>
<p>许多系统可以<strong>双重引导</strong>（dual-booted），允许我们在<strong>单个系统上安装多个操作系统</strong>。了解多个文件系统和多个操作系统的<strong>启动加载程序</strong>，可以占用启动空间。一旦加载，它可以启动磁盘上可用的任一操作系统。磁盘可以有多个分区，每个包含不同类型的文件系统和不同的操作系统。</p>
<p><strong>根分区</strong>（root partition），包括操作系统<strong>内核和其他系统文件</strong>，在<strong>启动时安装</strong>。作为成功安装操作的一部分，操作<strong>系统验证设备包含有效的文件系统</strong>。操作系统通过<strong>设备驱动程序读入设备目录</strong>，并验证目录是否具有预期格式。如果格式无效，则必须检查分区的一致性，并根据需要自动或手动地加以纠正。最后，操作系统<strong>在内存的安装表中，注明已安装的文件系统及其类型</strong>。该功能的细节取决于操作系统。</p>
<h4 id="11-2-3-虚拟文件系统"><a href="#11-2-3-虚拟文件系统" class="headerlink" title="11-2-3 虚拟文件系统"></a>11-2-3 虚拟文件系统</h4><p>现代操作系统通常支持多个文件系统。</p>
<p>为了实现<strong>多个文件系统的支持</strong>，一个明显但欠佳的方法是，为每种类型编写目录和文件程序。</p>
<p>然而，取而代之的是，大多数操作系统，包括UNIX，采用面向对象的技术来简化、组织和模块化实现。数据结构和程序用于<strong>隔离基本系统调用</strong>的功能与实现细节。因此，文件系统的实现由<strong>三个主要层</strong>组成，如图11-4所示。</p>
<center> <img src="./osimg/虚拟文件系统示意.png"> </center>

<ul>
<li>第一层为<strong>文件系统接口</strong>，基于open（）、read（）、write（）和close（）调用及文件描述符。</li>
<li>第二层称为<strong>虚拟文件系统</strong>（VirtualFileSystem, <strong>VFS</strong>）层,有两个重要功能：<ul>
<li>定义一个清晰的VFS接口，它将<strong>文件系统的通用操作和实现分开</strong>。VFS接口的多个实现可以共存在同一台机器上，允许透明访问本地安装的不同类型的文件系统。</li>
<li>提供了一种机制，以<strong>唯一表示网络上的文件</strong>。VFS基于称为<strong>虚拟节点或v节点（vnode）的文件表示结构</strong>，它包含一个<strong>数字指示符</strong>以唯一表示网络上的一个文件. 内核为每个活动节点（文件或目录）保存一个vnode结构。</li>
</ul>
</li>
</ul>
<p>因此，VFS区分本地文件和远程文件，还根据文件系统类型进一步区分本地文件。</p>
<p><strong>VFS根据文件系统的类型来调用特定文件类型的操作以便处理本地请求</strong>，通过<strong>调用NFS协议程序来处理远程请求</strong>。文件句柄可以根据相应的vnode来构造，并作为参数传递给这些程序。</p>
<p>这种文件系统的<strong>第三层实现文件系统类型或远程文件系统协议</strong>。下面简要分析一下Linux的VFS架构。Linux VFS定义4种主要对象类型：</p>
<ul>
<li><strong>索引节点对象</strong>（inode object），表示一个单独的文件</li>
<li><strong>文件对象</strong>（fileobject），表示一个<strong>已打开的文件</strong></li>
<li><strong>超级块对象</strong>（super block object），表示整个文件系统</li>
<li><strong>目录条目对象</strong>（dentry object），表示单个目录条目。</li>
</ul>
<p>VFS为每种对象定义了一组操作。这些对象里都有一个函数表的指针以提供实现特定操作的函数地址。</p>
<p>因此，VFS在软件层面的操作无需知道对象类型，因为他所有的可用操作都包含在对象的成员内了。</p>
<h3 id="11-3-目录实现"><a href="#11-3-目录实现" class="headerlink" title="11-3 目录实现"></a>11-3 目录实现</h3><h4 id="11-3-1-线性列表"><a href="#11-3-1-线性列表" class="headerlink" title="11-3-1 线性列表"></a>11-3-1 线性列表</h4><p>目录实现的最简单方法是，采用<strong>文件名称和数据块指针的线性列表</strong>。但这种方式的增删查改都很费时，链表可以用来减少删除文件的所需时间。。对于<strong>重用目录条目</strong>，有三种方法：</p>
<ol>
<li>将目录条目标记为不再使用<ul>
<li>为其<strong>分配特殊名称</strong>，例如一个全为空白的名称</li>
<li>或通过为每个条目<strong>增加一个使用－非使用位</strong></li>
</ul>
</li>
<li>将它加到空闲目录条目的列表</li>
<li>将目录的最后一个条目复制到空闲位置，并减少目录的长度</li>
</ol>
<p><strong>软件缓存</strong>可以缓解搜索信息的时间问题，也避免了从很忙的磁盘得到信息. <strong>排序列表</strong>允许二分搜索，并且减少平均搜索时间。但维持排序的要求可能使文件的创建和删除复杂化，需要大量移动。更复杂的树数据结构，如<strong>平衡树</strong>，可能在这里更为有用。排序列表的一个<strong>优点</strong>是，不需要单独的排序步骤就可以<strong>生成排序的目录信息</strong>(因为本来就有序)</p>
<h4 id="11-3-2-哈希表"><a href="#11-3-2-哈希表" class="headerlink" title="11-3-2 哈希表"></a>11-3-2 哈希表</h4><p>哈希表根据文件名称获得一个值，并返回线性列表内的一个元素指针。因此，它大大地<strong>减少了目录搜索的时间</strong>。插入和删除也是比较直截了当的。问题就是要处理<strong>哈希碰撞</strong>。</p>
<p>哈希表的主要困难是，它的<strong>通常固定的大小和哈希函数对大小的依赖</strong>。若当前的哈希函数可以映射至0 ~ 63，要是有更多的文件且不希望哈希碰撞的话就需要增大映射范围，这需要重新计算现有目录条目。</p>
<p>或者，可以采用<strong>溢出链接</strong>（chained-overflow）的哈希表。哈希表的<strong>每个条目可以是链表</strong>而不是单个值，可以采用向链表增加新的条目来解决冲突。代价是查找变慢，但是还是比线性列表快。</p>
<h3 id="11-4-分配方法"><a href="#11-4-分配方法" class="headerlink" title="11-4 分配方法"></a>11-4 分配方法</h3><p>磁盘空间分配的主要常用方法有三个：<strong>连续、链接和索引</strong>。各有优缺点。</p>
<h4 id="11-4-1-连续分配"><a href="#11-4-1-连续分配" class="headerlink" title="11-4-1 连续分配"></a>11-4-1 连续分配</h4><p><strong>连续分配</strong>（contiguous allocation）方法要求，每个<strong>文件在磁盘上占有一组连续的块</strong>. 这种方式分配的扇区都在同一个磁道，或者当磁道用完后转到邻近的磁道，这只需要移动一次磁头。显然，连续分配有<strong>最小的寻道时间</strong>。</p>
<p>文件的连续分配可以用<strong>首块的磁盘地址和连续的块数来定义</strong>. 假设文件从b位置开始，有n块，那他将占有块b，b+1，b+2，··· ，b+n-1。</p>
<p>连续分配文件的访问非常容易。对于<strong>顺序访问</strong>，文件系统会记住上次引用的块的磁盘地址，如需要可读入下一块。对于<strong>直接访问</strong>，一个文件的从块b开始的第i块，可以直接访问块b+i。因此, <strong>连续分配支持顺序访问和直接访问</strong>。</p>
<center> <img src="./osimg/连续分配.png"> </center>

<p>连续分配的一个问题是<strong>为新文件找到空间</strong>。用于管理空闲空间的系统决定了这个任务如何完成。</p>
<p>连续分配问题可以作为8.3节所述的<strong>通用动态存储分配问题</strong>的一个具体应用。即如何<strong>从一个空闲孔列表中寻找一个满足大小为n的空间</strong>。<br>常用的策略是，首次适合和最优适合。首次适合和最优适合在空间使用方面不相上下，但是首次适合一般更快。</p>
<p>但是所有这些方法都会<strong>留下外部碎片</strong>，使得可用空间越来越小。</p>
<p>为了防止外部碎片引起的大量磁盘空间的浪费, 可以定期<strong>紧缩</strong>。</p>
<p>将整个文件系统复制到另一个磁盘。原来的磁盘完全变成空的，从而创建了一个<strong>大的连续空闲空间</strong>。然后，通过从这个大的连续空闲空间采用连续分配方法，将这些文件<strong>复制回来</strong>。这种方案<strong>将所有空闲空间有效合并</strong>（compact）起来，解决了碎片问题。代价是时间，而且大硬盘的代价可能特别高。老系统要求线下执行，需要卸载文件系统且整理期间无法正常运行。现在的系统支持在线执行，但是性能下降可能很明显。</p>
<p>连续分配的另一个问题是，确定一个<strong>文件需要多少空间</strong>。文件的大小可能是可变的。如果为文件<strong>分配的空间太小</strong>，可能会发现<strong>文件无法扩展</strong>。特别是对于最优适合的分配策略。此时，以终止用户程序，并给出适当的错误消息，但重复运行的代价略高。另一种可能是，找一个更大的空间，将文件内容复制到新空间，并释放以前的空间。</p>
<p>为了最小化这些缺点，有些操作系统使用<strong>连续分配的修正方案</strong>。空间不够时，会<strong>添加另一块连续空间</strong>（称为<strong>扩展</strong>（extent））。然后，文件块的<strong>位置就记录为：地址、块数、下一扩展的首块的指针</strong>。<br>扩展块不能太大或太小，太大有内部碎片，太小需要多次分配性能太差。</p>
<h4 id="11-4-2-链接分配"><a href="#11-4-2-链接分配" class="headerlink" title="11-4-2 链接分配"></a>11-4-2 链接分配</h4><p><strong>没有外部碎片，无需担心分配空间大小的问题</strong></p>
<p><strong>链接分配</strong>（linked allocation）解决了连续分配的所有问题. 采用链接分配，每个<strong>文件是磁盘块的链表</strong>, 且磁盘块不要求连续。块都有下一块的一个指针, 用户不能使用这些指针的空间.</p>
<p>创建一个新文件，只需在目录中增加一个新的条目. 采用<strong>链接分配</strong>，每个<strong>目录条目都有文件首个磁盘块的一个指针</strong>。这个指针初始化为null（链表结束指针值），表示一个空的文件。大小字段也设置为0。</p>
<p><strong>写文件</strong>导致空<strong>闲空间管理系统找到一个空闲块</strong>，这个新块会被写入，并<strong>链接到文件的尾部</strong>。读文件，只需按照块到块的指针来读块。</p>
<center> <img src="./osimg/链接分配.png"> </center>

<p>链接分配的一个问题<strong>是只能有效用于顺序访问文件</strong>，要找到文件的第i个块，必须从文件的开始起，跟着指针，找到第i块。每个指针的访问都需要一个磁盘读，有时需要磁盘寻道。寻道时间太长，不适用于直接访问，效率低。</p>
<p>这个问题的通常解决方案是，将<strong>多个块组成簇</strong>（cluster），并<strong>按簇而不是按块来分配</strong>。移动次数更少带来了<strong>更短的寻道时间</strong>。分配单位的增大<strong>降低了块分配和空闲列表管理所需的空间</strong>，这样还<strong>减少了指针对空间的占用</strong>。但是会带来更多的<strong>内部碎片</strong>。</p>
<p>另一个问题是<strong>可靠性</strong>，如果其中一个指针丢失或损坏，将无法继续读取文件或读取到错误的文件。一个<strong>不完全</strong>的解决方案是，采用<strong>双向链表</strong>，只要下一个快的前向指针没错就能拿来判断是否后向指针出错；另一个是，在<strong>每块存储文件名称和相对块号</strong>。然而，这些方案为每个文件增加了更多<strong>额外开销</strong>。</p>
<h5 id="FAT"><a href="#FAT" class="headerlink" title="FAT"></a>FAT</h5><p><strong>文件分配表</strong>（File-AllocationTable, <strong>FAT</strong>）的使用是链接分配的重要变种。每<strong>卷的开头部分的磁盘用于存储该表</strong>。在该表中，每个<strong>磁盘块都有一个条目</strong>，并可按<strong>块号来索引</strong>。FAT的使用与链表相同。目录条目包含<strong>文件首块的块号</strong>。通过<strong>这个块号索引的表条目包含文件的下一块的块号</strong>。最后一块的表条目的值为文件结束值。未使用的块用0作为表条目的值来表示。为文件<strong>分配一个新块</strong>只要简单找到第一个值为0的FAT条目，用新块的地址替换前面文件结束值，用文件结束值替代。</p>
<center> <img src="./osimg/FAT.png"> </center>

<p>如果不对FAT采用<strong>缓存</strong>，可能导致大量的磁头寻道时间. 磁头必须移到卷的开头，读入FAT，找到所需块的位置，再移到块本身的位置。在<strong>最坏的情况下，每块都需要移动两次</strong>。但是由于FAT表的存在，对指定块的查找可以在表中迭代而不需要实际的磁盘访问，因此<strong>随机访问加快</strong>，对<strong>直接访问的支持更高效</strong>。</p>
<h4 id="11-4-3-索引分配"><a href="#11-4-3-索引分配" class="headerlink" title="11-4-3 索引分配"></a>11-4-3 索引分配</h4><p><strong>没有外部碎片，无需担心分配空间大小的问题</strong></p>
<p><strong>索引分配</strong>（indexed allocation）通过将所有指针放在一起，即<strong>索引块</strong>（indexblock），支持了<strong>高效的直接访问</strong>(没有FAT的链接访问做不到)。</p>
<p><strong>每个文件都有自已的索引块</strong>，这是一个<strong>磁盘块地址的数组</strong>。索引块的<strong>第i个条目指向文件的第i个块</strong>. <strong>目录包含索引块的地址</strong>（图11-8）。当查找和读取第i个块时，采用第i个索引块条目的指针.</p>
<center> <img src="./osimg/索引分配.png"> </center>

<p><em>-1(null)为结束和非法位置</em></p>
<p>当创建文件时，索引块的所有指针都设为null。当首次写入第i块时，先从空闲空间管理器中获得一块，再将其地址写到索引块的第i个条目。</p>
<p>索引分配的一个问题是<strong>浪费空间</strong>，若一个文件只有两个块，仍然需要分配整个块，然而其他的空间都被浪费了。链接分配则只需要按需分配指针而不会浪费(若有FAT表则可能浪费)。</p>
<p>因此，需要确定<strong>索引块的大小以贴合需求</strong>，有以下几种方案：</p>
<ul>
<li><strong>链接方案</strong>：为了支持大的文件，可以<strong>将多个索引块链接起来</strong>。例如，一个索引块可以包括一个含有文件名的头部和一组头100个磁盘块的地址。下一个地址（索引块的最后一个字）为null（对于小文件），或者另一个索引块的指针（对于大文件）。</li>
<li><strong>多级索引</strong>：通过第一级索引块指向一组第二级的索引块，它又指向文件块。可以添加更多级的索引，这根据文件大小而定。对于4096字节的块，可以在索引块中存入1024个4字节的指针。两级索引支持1048576个数据块和4GB的最大文件。</li>
<li><strong>组合方案</strong>：另一个选择，用于基于UNIX的文件系统，将索引块的前几个（如15）指针存在文件的inode中。这些指针的<strong>前12个指向直接块</strong>（direct block）；即它们包含存储文件数据的块的地址。因此，小的文件（不超过12块）不需要单独的索引块。如果块大小为4KB，则不超过48KB的数据可以直接访问。接下来的<strong>3个指针指向间接块</strong>（indirect block）。第一个指向<strong>一级间接块</strong>（single indirect block）。一级间接块为索引块，它包含的不是数据，而是真正包含数据的块的地址。第二个指向<strong>二级间接块</strong>（doubleindirectblock），它包含了一个块的地址，而这个块内的地址指向了一些块，这些块中又包含了指向真实数据块的指针。最后一个指针为<strong>三级间接块</strong>（triple indirect block）指针</li>
</ul>
<p>这样可以拓展到非常大的文件大小，许多UNIX和Linux现在支持64位的文件指针。这样的指针允许文件和文件系统为数艾字节。ZFS文件系统支持128位的文件指针</p>
<center> <img src="./osimg/UNIX_inode.png"> </center>

<p>索引分配方案与链接分配一样在<strong>性能方面有所欠缺</strong>。尤其是，虽然<strong>索引块可以缓存</strong>在内存中，但是<strong>数据块可能分布在整个卷</strong>上。</p>
<h4 id="11-4-4-性能"><a href="#11-4-4-性能" class="headerlink" title="11-4-4 性能"></a>11-4-4 性能</h4><p>以顺序访问为主的系统和以随机访问为主的系统，不应采用相同的分配方法。</p>
<p>对于<strong>任何类型的访问</strong>, <strong>连续分配</strong>只需<strong>访问一次就能获得磁盘块</strong>。由于可以<strong>在内存中容易地保存文件的开始地址</strong>，所以<strong>可以立即计算第i块（或下一块）的磁盘地址，并直接读取</strong>。</p>
<p>对于<strong>链接分配</strong>，也可以<strong>在内存中保留下一块的地址</strong>，并直接读取。对于<strong>顺序访问这种方法很好</strong>；然而，对于<strong>直接访问</strong>，对第i块的访问<strong>可能需要读i次磁盘</strong>。这个问题表明了，为什么<strong>链接分配不适用于需要直接访问</strong>的应用程序。</p>
<p>因此有的系统限制直接访问的应用不能使用链接分配(使用连续分配支持直接访问的文件, 链接分配支持顺序访问的文件)。文件创建时可以声明自己的访问类型。用于直接访问的文件可以连续分配，能支持直接访问和顺序访问，但是在创建时必须声明其最大的文件大小。</p>
<p><strong>索引分配</strong>更为复杂。如果索引块已在内存，则可以进行直接访问。然而，在内存中保存<strong>索引块需要相当大的空间</strong>。如果没有这个内存空间，则可能必须先读取索引块，再读取所需的数据块。多级索引更是要读取多次索引块。对于<strong>极大的文件</strong>，访问<strong>末尾附近的块需要读取所有的索引块</strong>(若不在内存中缓存那就要访问特别多次磁盘)。索引分配的<strong>性能取决于索引结构、文件大小以及所需块的位置</strong>。</p>
<h3 id="11-5-空闲空间管理"><a href="#11-5-空闲空间管理" class="headerlink" title="11-5 空闲空间管理"></a>11-5 空闲空间管理</h3><p>为了<strong>跟踪空闲磁盘空间</strong>，系统需要<strong>维护一个空闲空间列表</strong>（free-space list）。空闲空间列表记录了所有空闲磁盘空间，即未分配给文件或目录的空间。空闲空间列表虽然称为列表，但是<strong>不一定按列表来实现</strong>。</p>
<h4 id="11-5-1-位向量"><a href="#11-5-1-位向量" class="headerlink" title="11-5-1 位向量"></a>11-5-1 位向量</h4><p>通常，空闲空间列表按<strong>位图</strong>（bitmap）或<strong>位向量</strong>（bit vector）来实现。每块用一个位来表示。如果<strong>块是空闲的，位为1</strong>；如果<strong>块是分配的，位为0</strong>。</p>
<p>例如，假设一个磁盘，其中块2、3、4、5、8、9、10、11、12、13、17、18、25、26、27为空闲，而其他块为已分配。空闲空间的位图如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">001111001111110001100000011100000..</span><br></pre></td></tr></table></figure>
<p><strong>主要优点</strong>是，在<strong>查找</strong>磁盘上的<strong>第1个空闲块</strong>和<strong>n个连续的空闲块</strong>时相对<strong>简单和高效</strong>。</p>
<p>通过位图<strong>查找第一个空闲块</strong>来分配磁盘空间的一种技术是，按顺序检查位图的<strong>每个字</strong>(多个位)以查看其值是否为0，因为一个值为0的字只包含0位且表示一组已分配的块. <strong>扫描第一个非0的字，以查找值为1的位，它对应着第一个空闲块</strong>。该块号码(0开始)的计算如下：</p>
<center> <p> （每个字的位数）×（值为0的字数）+ 第一个值为1的位的偏移 </p> </center>

<p>将位向量完全保存在内存中，对于较小的磁盘是可能的，对于较大的就不一定。。具有4KB块的1TB磁盘要求256MB(1TB&#x2F;4KB)来存储位图。由于<strong>磁盘大小的不断增加，位向量的问题会继续升级</strong>。</p>
<h4 id="11-5-2-链表"><a href="#11-5-2-链表" class="headerlink" title="11-5-2 链表"></a>11-5-2 链表</h4><p>空闲空间管理的另一种方法是，将<strong>所有空闲磁盘块用链表链接起来</strong>，将<strong>指向第一空闲块的指针</strong>保存在磁盘的特殊位置上，同时也将其缓<strong>存在内存</strong>中。这种方案<strong>低效</strong>；在遍历整个列表时，需要读入每块，从而需要大量的I&#x2F;O时间。幸运的是，通常，操作系统只需一个空闲块以分配给文件，所以只使用分配空闲列表的第一块. </p>
<p><strong>FAT</strong>方法将<strong>空闲块的计算结合到分配数据结构中</strong>，不再需要单独的方法。(会自己找值为0的未分配的块)。</p>
<center> <img src="./osimg/链接空闲管理.png"> </center>

<h4 id="11-5-3-组"><a href="#11-5-3-组" class="headerlink" title="11-5-3 组"></a>11-5-3 组</h4><p>空闲列表方法的一个改进是，在<strong>第一个空闲块中存储n个空闲块的地址</strong>。这些<strong>块的前n-1个确实为空</strong>, <strong>最后一块包含另外n个空闲块的地址</strong>，如此继续。大量空闲块的地址可以很快地找到，这一点有别于标准链表方法。</p>
<p>进入一个大小为n的块可以得到n-1个空闲块地址，减少了块的遍历。</p>
<h4 id="11-5-4-计数"><a href="#11-5-4-计数" class="headerlink" title="11-5-4 计数"></a>11-5-4 计数</h4><p>另外一种方法利用了这样一个事实：通常，多个<strong>连续块可能需要同时分配或释放</strong>，尤其是采用连续区域分配算法或采用簇来分配空间更是如此. 因此，可以<strong>记录第一块的地址和紧跟第一块的连续空闲块的数量</strong>。虽然每个条目会比原来需要更多空间，但是表的总长度会更短，只要连续块的数量通常大于1。这些条目可以<strong>存储在平衡树而不是链表中</strong>，以便于<strong>高效查找、插入和删除</strong>。</p>
<h4 id="11-5-5-空间图"><a href="#11-5-5-空间图" class="headerlink" title="11-5-5 空间图*"></a>11-5-5 空间图*</h4><p>Oracle的ZFS文件系统（用于Solaris和其他操作系统）设计成包含大量的文件、目录，甚至文件系统（在ZFS中，可以创建文件系统层次结构）。在这种规模上，元数据I&#x2F;O对性能影响可能很大。例如，假设空闲列表按位图来实现，在分配和释放块时必须修改位图。在1TB磁盘上释放1GB数据可能需要更新位图的数千位，因为这些数据块可能会分散在整个磁盘上。显然，这种系统的数据结构可能很大而且效率低下。</p>
<p>对于空闲空间的管理，ZFS采用了组合技术，来控制数据结构的大小并<strong>最小化管理这些数据结构所需的I&#x2F;O</strong>。首先，ZFS创<strong>建metaslab</strong>，以将<strong>设备空间划分为若干可控尺寸的区域</strong>。给定的卷可以包括数百个metaslab。每个<strong>metaslab都有一个关联的空间图</strong>。ZFS<strong>使用计数算法，以存储有关空闲块的信息</strong>。它不是将计数结构写入磁盘，而是<strong>采用日志结构文件系统技术</strong>来记录它们。<strong>空闲图</strong>为<strong>按时间顺序</strong>和<strong>计数格式</strong>的所有<strong>块活动（分配和释放）的日志</strong>。</p>
<p>当ZFS决定从metaslab中分配或释放空间时，它将<strong>相关的空间图加载到内存中的按偏移索引的平衡树结构</strong>（以便操作高效），并将日志重装到该结构中。这样，内存的空间图精确表示metaslab中的分配和空闲空间。通过将连续的空闲块组合成单个条目，ZFS也尽可能地缩小空间图。最后，作为面向事务的操作，更新磁盘的空闲空间列表。在收集和排序阶段，块请求仍然可以发生，ZFS通过日志满足这些请求。实质上，日志加平衡树就是空闲列表。</p>
<h3 id="11-6-效率和性能"><a href="#11-6-效率和性能" class="headerlink" title="11-6 效率和性能"></a>11-6 效率和性能</h3><h4 id="11-6-1-效率"><a href="#11-6-1-效率" class="headerlink" title="11-6-1 效率"></a>11-6-1 效率</h4><p><strong>磁盘空间的有效使用</strong>在很大程度上<strong>取决于磁盘分配和目录算法</strong>。法。例如，UNIXinode预先分配在卷上。即使“空”的磁盘也有一定百分比的空间，用于存储inode。然而，通过预先分配inode并将它们分散在整个卷上，改进了文件系统的性能。算法试图保持一个文件的数据块靠近该文件的inode块，以便减少寻道时间。</p>
<p>作为另一个例子，下面再考虑11.4节讨论的<strong>簇技术</strong>，它通过<strong>以内部碎片为代价，改进了文件查找和文件传输的性能</strong>。为了降低这类碎片，BSDUNIX根据文件增长，调节簇的大小。当大簇能填满时，就用大簇；对小文件和文件最后一簇，就用小簇。附录A讨论了这种系统。</p>
<p>保存在文件目录条目（或inode）内的<strong>数据类型也需要加以考虑</strong>。通常，要记录“最后写日期”，以提供给用户，并确定是否需要备份给定文件。有些系统也<strong>保存“最后访问日期”</strong>，以便用户可以<strong>确定文件的最后读取时间</strong>。由于这个信息，每当<strong>读取文件时，目录结构的一个字段必须被更新</strong>。这意味着将相应块读入内存，修改相应部分，再将该块写到磁盘，因为磁盘操作是以块（或簇）为单位来进行的。因此，每当文件打开以便读取时，它的目录条目也必须读出和写入。对于经常访问的文件，这种要求是<strong>低效的</strong>；因此，在设计文件系统时，必须平衡优点和性能代价。通常，与文件关联的每个数据项都需要加以研究，以考虑它对效率和性能的影响。</p>
<p>例如，考虑用于访问数据的<strong>指针大小如何影响效率</strong>。大多数系统在整个操作系统中采用32位或64位的指针。采用<strong>32位指针将文件的大小限制为2^32 或4GB</strong>。采用64位指针允许非常大的文件，但是<strong>64位指针需要更多空间来存储</strong>。因此，分配和可用空间管理方法（链表、索引，等等）使用更多磁盘空间。</p>
<h4 id="11-6-2-性能"><a href="#11-6-2-性能" class="headerlink" title="11-6-2 性能"></a>11-6-2 性能</h4><p>即使选择了基本的文件系统算法，仍然能够从多种方式来提高性能。正如第13章将会讨论的，大多数<strong>磁盘控制器都包含本地内存</strong>，以形成足够大的<strong>板载高速缓存</strong>来<strong>同时存储整个磁道</strong>。一旦进行了寻道，就从磁头所处的扇区开始（以缓解延迟时间）将整个磁道读到磁盘缓存。然后，磁盘控制器将任何扇区请求传到操作系统。在数据块从磁盘控制器调到内存后，操作系统就可缓存它。</p>
<p>有些系统有一块<strong>独立内存</strong>以用作<strong>缓冲区缓存</strong>（buffer cache），假设其中的块将很快再次使用。其他系统<strong>采用页面缓存</strong>（page cache）来<strong>缓存文件数据</strong>。页面缓存采用<strong>虚拟内存技术</strong>，将文件<strong>数据按页面而不是按面向文件系统的块</strong>来缓存。采用虚拟地址来缓存文件数据，与采用物理磁盘块来缓存相比，更为高效，因为<strong>访问接口是通过虚拟内存而不是文件系统</strong>。用<strong>页面缓存</strong>来<strong>缓存进程页面和文件数据</strong>。这称为<strong>统一虚拟内存</strong>(unified virtual memory)</p>
<p>为了说明统一缓冲区缓存的优点，考虑<strong>文件打开和访问</strong>的两种方法:</p>
<ul>
<li><strong>内存映射</strong>: 如果没有统一缓冲区缓存，则情况会类似于图11-11。这里，系统调用read()和write()会通过缓冲区缓存。然而, <strong>内存映射调用需要使用两个缓存</strong>，即页面缓存和缓冲区缓存. 因为<strong>虚拟内存系统没有缓冲区缓存的接口</strong>，所以缓冲区缓存内的文件内容<strong>必须复制</strong>到页面缓存. 这种情况称为<strong>双缓存</strong>, 不仅浪费内存，而且浪费重要的CPU和I&#x2F;O时间. 另外，这两种<strong>缓存之间的不一致性也会导致文件破坏</strong>.</li>
<li><strong>采用标准系统调用read()和write()</strong>: 系统调用read()和write()会通过缓冲区缓存。</li>
</ul>
<center> <img src="./osimg/统一缓冲区.png"> </center>

<p>LRU算法看似是个对缓存磁盘块和缓存页面都合理的算法，然而对于Solaris系统，它允许进程于页面缓存共享内存，然而高频率的I&#x2F;O会让页面缓存抢占内存，使得进程的内存变少。Solaris 8 后限制了进程页面和文件系统页面缓存，避免了<strong>一方将另一方赶出内存</strong>。</p>
<p>能够<strong>影响I&#x2F;O性能</strong>的另一个问题是，文件系统的<strong>写入是同步的还是异步的</strong>. <strong>同步写</strong>（synchronous write）按磁盘子系统接收顺序来进行，并<strong>不缓冲写入</strong>。因此，调用程序必须等待数据写到磁盘驱动器，再继续。对于<strong>异步写</strong>（asynchronous write），将<strong>数据先存在缓存</strong>后，就将控制返回给调用者。大多数写是异步的。系统经常允许系统调用open包括一个标志，以允许进程请求写入同步执行。例如，数据库的原子事务使用这种功能，以确保数据按给定顺序存入稳定存储。</p>
<p><em>异步写可以在磁盘内排序，减少磁头的移动，缩短寻道延迟(12章)</em></p>
<p>有的系统<strong>根据文件访问类型采用不同的替换算法</strong>，以便优化页面缓存。</p>
<p>文件的<strong>顺序读写不应采用LRU页面替换</strong>，因为最近使用的页面最后才会使用或根本不用。顺序访问可以通过采用称为<strong>随后释放</strong>和<strong>预先读取</strong>的技术来加以优化。</p>
<ul>
<li><strong>随后释放</strong>: 一旦请求下一个页面，就从缓冲区中删除一个页面。以前的页面可能不再使用，并且浪费缓冲区空间</li>
<li><strong>预先读取</strong>: 请求的页面和一些<strong>之后的页面可以一起读取并缓存</strong>。</li>
</ul>
<p>页面缓存、文件系统和磁盘驱动程序有着有趣的联系。当数据写到磁盘文件时，页面先放在缓存中, <strong>磁盘驱动程序根据磁盘地址对输出队列进行排序</strong>。这两个操作允许磁盘驱动程序<strong>最小化磁盘头寻道</strong>，并根据磁盘旋转来优化写数据. 写比读更倾向于异步，对于大的传输，通过文件系统输出(写)到磁盘通常比输人(读)更快，这与直觉相反。</p>
<h3 id="11-7-恢复"><a href="#11-7-恢复" class="headerlink" title="11-7 恢复"></a>11-7 恢复</h3><p>系统崩溃可能导致磁盘文件系统数据结构（如目录结构、空闲块指针和空闲FCB（FileControlBlock）指针）的不一致。不修复会带来很多问题。</p>
<h4 id="11-7-1-一致性检查"><a href="#11-7-1-一致性检查" class="headerlink" title="11-7-1 一致性检查"></a>11-7-1 一致性检查</h4><p>无论损坏的原因，文件系统必须检测问题，并再纠正它们。对于检测，每个<strong>文件系统的所有元数据的扫描可以肯定或否定系统的一致性</strong>。不过这可能要几分钟到几小时。或者，文件系统可能在文件系统的<strong>元数据中记录其状态</strong>。在任何元数据修改的开始，设置<strong>状态位以表示元数据正在修改</strong>。如果<strong>所有元数据的更新成功完成</strong>，则文件系统可以<strong>清除位</strong>。然而，如果状态位保持<strong>置位，则运行一致性检查程序</strong>。</p>
<p><strong>一致性检查程序</strong>（consistency checker），如UNIX的系统程序fsck，比较目录结构的数据和磁盘的数据块，并且试图修复发现的不一致。</p>
<p><strong>分配和空闲空间管理的算法</strong>决定了检查程序能够发现什么类型的问题，及其如何成功修复问题。</p>
<ul>
<li>采用<strong>链接分配</strong>，从任何块到其下一个块有链接，则从数据块来重建整个文件，并且重建目录结构</li>
<li><strong>索引分配</strong>系统的目录条目的损坏可能是灾难性的，因为数据块彼此并不了解。为此，UNIX缓存目录条目。但是, <strong>导致空间分配或其他元数据更改的任何写是同步进行的</strong>(每空间了肯定要等分配了才能写)，并且<strong>在相应数据块写入之前</strong>。当然，如果<strong>同步写因系统崩溃而中断，则问题仍然可能出现</strong>。</li>
</ul>
<h4 id="11-7-2-基于日志的文件系统"><a href="#11-7-2-基于日志的文件系统" class="headerlink" title="11-7-2 基于日志的文件系统"></a>11-7-2 基于日志的文件系统</h4><p>从数据库的基于日志的恢复算法得到启发，实现了是称为<strong>基于日志的面向事务</strong>（log-based transaction-oriented）（或<strong>日志记录</strong>（journaling））的<strong>文件系统</strong>。</p>
<p>从上面一小节可知，一致性可能无法恢复，可能需要人为干预来解决。这个问题的解决方法是, <strong>将基于日志恢复技术应用到文件系统的元数据更新</strong>. NTFS和Veritas，Solaris UFS文件系统都采用这种方法。</p>
<p>从根本上说, <strong>所有元数据修改按顺序写到日志</strong>。执行特定任务的一组操作称为<strong>事务</strong>（transaction）。一旦这些<strong>修改写到这个日志</strong>，就可<strong>认为已经提交</strong>，系统调用就可<strong>返回到用户进程</strong>以便允许继续执行。同时，这些<strong>日志条目对真实文件系统结构进行重放</strong>。随着更改，通过指针更新表示哪些操作已经完成和哪些仍然没有完成。当<strong>整个提交事务已经完成，就可从日志文件中删除它</strong>（日志文件实际上是个环形缓冲区）。当环形缓冲区（circular buffer）写到空间末尾的时候，会从头继续，从而覆盖掉以前的旧值。此时应<strong>避免覆盖未保存的数据</strong>。日志可能是文件系统的一个单独的部分，甚至在单独的磁盘上。采用分开读&#x2F;写磁头可以减少磁头竞争和寻道时间，会更有效但也更复杂。</p>
<p>如果<strong>系统崩溃</strong>，日志文件可能包含零个或多个事务。它包含的任何事务虽然已经由操作系统<strong>提交了，但是还没有完成到文件系统</strong>，所以现在必须完成。唯一可能出现的<strong>问题是事务被中断</strong>(事务完成了一部分)，即在系统崩溃之前它还没有被提交(宣布完成)。对文件系统所做的<strong>任何修改必须撤销</strong>(回滚)，再次保持文件系统的一致性。</p>
<p>利用磁盘元数据更新日志的一个好处是，这些更新要快于磁盘数据结构的直接更新。原因是，顺序I&#x2F;O(<strong>日志更新可以是物理连续的</strong>)的性能要好于随机I&#x2F;O的。低效的同步随机元数据(<strong>磁盘元数据的位置可能是分散的</strong>)写入变成高效的同步顺序写到基于日志文件系统的记录区域。这些<strong>修改再通过随机写异步回放到适当数据结构</strong>。总的结果是，提高了面向元数据操作（如文件创建和文件删除）的性能。</p>
<h4 id="11-7-3-其他解决办法"><a href="#11-7-3-其他解决办法" class="headerlink" title="11-7-3 其他解决办法"></a>11-7-3 其他解决办法</h4><p>网络家电的WAFL文件系统和Solaris的ZFS文件系统，采用另一种一致性检查。它们从不采用新数据来覆盖块。相反，事务将所有数据和元数据更改写到新块。当事务完成时，指向这些块<strong>旧版的元数据结构被更新到指向这些新块</strong>。然后，文件系统可以删除旧的文件指针和旧的块，以便可以重用。如果<strong>保留旧的指针和块</strong>，则创建了<strong>快照</strong>（snap shot）。这个快照是在最后更新之前的文件系统的一个视图。</p>
<p>如果指针更新是原子的，则该解决方案应该不需要一致性检查。然而，<strong>WAFL文件系统确实有一个一致性检查程序</strong>，有些故障情况仍然可能导致元数据的损坏。</p>
<p>ZFS采用更为创新的方法来实现磁盘一致性，它提供所有元数据和数据块的<strong>校验和</strong>。这个解决方案（与RAID结合使用）确保数据始终正确。因此，ZFS没有一致性检程序。</p>
<h4 id="11-7-4-备份和恢复"><a href="#11-7-4-备份和恢复" class="headerlink" title="11-7-4 备份和恢复"></a>11-7-4 备份和恢复</h4><p>磁盘可能故障。为此，可以采用系统程序将磁盘数据<strong>备份</strong>（backup）到另一存储设备，如磁带或其他硬盘。单个文件或整个磁盘的恢复，只需要从备份中<strong>恢复</strong>（restore）数据就可以了。</p>
<p>为了最大限度地减少所需复制，可以利用每个文件的目录条目信息。只备份上次更改过的文件。一个计划可能如下：</p>
<ul>
<li>第1天：将所有磁盘文件复制到备份介质。这称为<strong>完全备份</strong>（full backup）。</li>
<li>第2天：将所有从<strong>第1天起更改的文件复制到备份介质</strong>。这称为<strong>增量备份</strong>(incremental backup)。</li>
<li>第3天：将所有从第2天起更改的文件复制到备份介质。</li>
<li>······</li>
<li>第N天：将所有从第N-1天起更改的文件复制到备份介质。再<strong>返回到第1天</strong>。</li>
</ul>
<p>种备份循环的一个额外优点是，对于在循环期间内意外删除的任何文件，只要从前一天的备份中恢复删除的文件。缺点是，更改的越多，增量备份就更多。</p>
<p>有时可能很久才发现损坏，为此可以定时完全备份。对于备份设备的使用应尽量少，以免备份设备损坏。</p>
<h3 id="11-8-NFS"><a href="#11-8-NFS" class="headerlink" title="11-8 NFS"></a>11-8 NFS</h3><p>网络文件系统</p>
<h4 id="11-8-1-概述"><a href="#11-8-1-概述" class="headerlink" title="11-8-1 概述"></a>11-8-1 概述</h4><p>NFS<strong>将一组互连的工作站视作一组具有独立文件系统的独立机器</strong>。目的是，允许透明（根据显式请求）共享这些文件系统。共享是基于客户机一服务器关系的。每台机器可能是，而且往往，既是客户机也是服务器。任何两台机器之间允许共享。为了确保机器独立，远程文件系统的<strong>共享只影响客户机而不是其他机器</strong>。</p>
<p>为了透明<strong>访问一台特定机器（如M1）的远程目录</strong>，这台机器的<strong>客户机必须首先执行安装</strong>（mount）操作。这个操作的语义是，将远程目录安装到本地文件系统的目录上。一旦完成了安装操作，安装目录<strong>看起来像本地文件系统的子树</strong>，并<strong>取代了本地目录的原来子树</strong>. <strong>本地目录</strong>就成为<strong>新安装目录的根的名称</strong>。</p>
<p>为了说明文件系统安装，考虑一下如图11-13所示的文件系统，其中三角形表示感兴趣的目录子树。图中有三台机器U、S1和S2的三个独立文件系统。这时，每台机器只可访问本地文件系统</p>
<center> <img src="./osimg/11-13.png"> </center>

<p>图11-14a显示了将S1：&#x2F;usr&#x2F;shared安装到U:&#x2F;usr&#x2F;local的效果。这个图说明了机器U的用户看到的文件系统。当完成安装后，可以通过前缀&#x2F;usr&#x2F;local&#x2F;dir1来访问目录dir1的任何文件。该<strong>机器的原来目录&#x2F;usr&#x2F;local不再可见</strong>。</p>
<center> <img src="./osimg/11-14.png"> </center>

<p>有的NFS实现也允许<strong>级联安装</strong>。也就是说，可以<strong>将一个文件系统安装到另一个远程安装的文件系统</strong>，而不是本地的。通过安装远程文件系统，客户<strong>不能访问以前文件系统碰巧安装的其他文件系统</strong>。因此，安装机制并<strong>不具有传递性</strong>。</p>
<p>图11-14b说明了级联安装。该图说明了安装S2：&#x2F;usr&#x2F;dir2到U:&#x2F;usr&#x2F;local&#x2F;dir1的结果，而&#x2F;usr&#x2F;local&#x2F;dir1远程安装了S1的目录。</p>
<center> <img src="./osimg/NFS安装.png"> </center>

<p>NFS设计目标之一是, <strong>支持由不同机器、操作系统和网络架构组成的异构环境</strong>. NFS规范与这些媒介独立无关。通过在两个与实现独立的<strong>接口之间采用基于外部数据表示（XDR）的RPC原语</strong>(不需要考虑大小端储存的区别)，可以<strong>实现这种独立性</strong>。因此，如果系统的异构机器和文件系统正确地连接到NFS，不同类型的文件系统可以本地和远程安装。</p>
<p>NFS规范区分<strong>两种服务</strong>：一是由<strong>安装机制提供的服务</strong>，二是真正<strong>远程文件访问服务</strong>. 因此，为了实现这些服务有两个单独的协议：安装协议和<strong>远程文件访问协议</strong>，即<strong>NFS协议</strong>（NFS protocol）。协议是<strong>用RPC来表示的</strong>，而这些RPC是用于实现透明远程文件访问的基础。</p>
<h4 id="11-8-2-安装协议"><a href="#11-8-2-安装协议" class="headerlink" title="11-8-2 安装协议"></a>11-8-2 安装协议</h4><p><strong>安装协议</strong>（mount protocol）在<strong>客户机和服务器之间建立初始逻辑连接</strong>。</p>
<p><strong>安装操作</strong>包括需要安装的<strong>远程目录的名称</strong>和存储它的<strong>服务器的名称</strong>。安装请求映射到相应的RPC，并且转发到特定服务器运行的安装服务程序。服务器维护一个<strong>输出列表</strong>（export list），用于<strong>列出可以安装的本地文件系统</strong>，以及<strong>允许安装它们的机器名称</strong>。为了简化维护输出表和安装表，可以采用<strong>分布式命名方案来存储</strong>(类似DNS服务)这些信息，以供客户使用。</p>
<p>服务器收到符合导出列表的安装请求时，它就返给客户机一个文件句柄，以作为主键来进一步访问已安装文件系统内的文件。</p>
<p>服务器还维<strong>护由客户机及对应当前安装目录组成的一个列表</strong>。该列表主要<strong>用于管理目的</strong>，例如，在服务器将要关机时<strong>通知所有客户</strong>。只有增加和删除这个列表内的条目，安装协议才能<strong>影响服务器状态</strong>。(这个列表实际的表示了当前的服务状态)</p>
<h4 id="11-8-3-NFS协议"><a href="#11-8-3-NFS协议" class="headerlink" title="11-8-3 NFS协议"></a>11-8-3 NFS协议</h4><p>NFS协议为远程文件提供了一组RPC操作。这些程序包括以下操作：</p>
<ul>
<li>搜索目录内的文件</li>
<li>读取一组目录条目</li>
<li>操作链接和目录</li>
<li>访问文件属性</li>
<li>读写文件</li>
</ul>
<p>只有在<strong>远程目录的句柄建立之后</strong>，才可以进行这些操作。</p>
<p><strong>打开与关闭操作的省略是故意的</strong>。NFS服务器的一个突出特点是<strong>无状态的</strong>。服务器并不维护客户机从一个访问到另一个访问的信息。因此，每个请求必须<strong>提供整套参数</strong>，包括唯一文件标识符和用于特定操作的文件内的绝对偏移。为此，文件操作必须是<strong>幂等的</strong>；也就是说, <strong>同一操作的多次执行与单次执行具有同样的效果</strong>。为了实现幂等，每个<strong>NFS请求都有一个序列号</strong>，以允许服务器<strong>确定一个请求是否是重复的或缺失的</strong>。(类似ACK)</p>
<p><strong>单个</strong>NFS写入程序调用确保是<strong>原子的</strong>，不会与其他写入同一文件的调用混合。然而，NFS协议并<strong>不提供并发控制机制</strong>。一个系统调用write()可能<strong>分成多个RPC写</strong>，因为<strong>每个NFS写或读的调用可以包含最多8KB的数据</strong>而<strong>UDP分组限制为1500字节</strong>. 多个用户的同时写可能导致<strong>数据混杂</strong>，这时需要加锁，但锁需要状态，所以建议采用NFS之外的机制，协调访问共享文件。</p>
<p>NFS通过VFS集成到操作系统。为了说明这种架构，下面跟踪对一个已打开远程文件的操作是如何进行的（参见图11-15）。</p>
<center> <img src="./osimg/NFS架构示意.png"> </center>

<p>客户端通过普通系统调用来启动操作。操作系统层将这个<strong>调用映射到适当vnode的VFS操作</strong>。VFS层识别文件为远程文件，并调用适当的NFS子程序。RPC调用发送到服务器的NFS服务层。这个调用重新进入远程系统的VFS层，而且后者发现它是本地的并且调用适当的文件系统操作。通过<strong>回溯这个路径，可以返回结果</strong>。这种架构的<strong>优点</strong>是，客户机和服务器是<strong>相同的</strong>；因此机器可以是客户机或服务器，或两个都是。服务器的实际服务是由内核线程执行的。</p>
<h4 id="11-8-4-路径名称转换"><a href="#11-8-4-路径名称转换" class="headerlink" title="11-8-4 路径名称转换"></a>11-8-4 路径名称转换</h4><p>NFS的<strong>路径名称转换</strong>（path-nametranslation），将路径名称，如&#x2F;usr&#x2F;local&#x2F;dir1&#x2F;file.txt解析成<strong>单独的目录条目或组件</strong>：usr、local和dir1。</p>
<p>路径名称转换包括：将路径分解成组件名称，并且<strong>为每对组件名(如local或file.txt)和目录vnode(对应的节点句柄)执行单独的NFS查找调用</strong>。一旦<strong>碰到安装点</strong>，每个组成部分的查找会<strong>发送一个单独RPC给服务器</strong>。不在碰到安装点查询完后直接终止的原因是可能存在多个安装点。</p>
<p>为了查找很快，客户机的路径名称转换的缓存<strong>保存远程目录名称的虚拟节点(vnode)<strong>，若缓存命中，则</strong>无需NFS查询</strong>，缓存命中时会<strong>检查服务器返回的属性</strong>，若不匹配则缓存的vnode失效。当服务器返回的属性与缓存内的属性不匹配时，目录缓存就要更新。</p>
<h4 id="11-8-5-远程操作"><a href="#11-8-5-远程操作" class="headerlink" title="11-8-5 远程操作"></a>11-8-5 远程操作</h4><p>除了文件的打开和关闭外，在常规UNIX文件操作系统调用和NFS协议RPC之间，几乎有一对一的对应关系。因此，远程文件操作可以直接转换对应的RPC。</p>
<p>但是，实际上，为了提高性能也<strong>采用了缓冲和缓存技术</strong>。在远程操作和RPC之间，不存在直接通信。相反，RPC获取文件块和文件属性，并且缓存在本地。以后的远程操作采用缓存数据，并遵守一致性约束。</p>
<p>有两个缓存: <strong>文件属性（索引节点信息）缓存</strong>和<strong>文件块缓存</strong>。当文件打开时，内核检查远程服务器，确定是否获取或重新验证缓存的属性。只有<strong>相应的缓存属性是最新的，才会使用缓存的文件块</strong>。每当服务器的新属性到达时，更新属性缓存。默认情况下，缓存属性在60秒后丢弃。</p>
<p>系统性能的调整<strong>难以实现NFS的一致性语义</strong>。在一台机器上创建的新文件，可能在别处30秒看不到。此外，某机器的文件写可能为或可能不为打开这个文件的其他机器所可见。文件的新的打开只能看到已经提交到服务器的修改. <strong>因此，NFS既不提供UNIX语义的严格模仿，也不提供Andrew会话语义</strong>（10.5.3.2节）。</p>
<h2 id="12-大容量存储结构"><a href="#12-大容量存储结构" class="headerlink" title="12 大容量存储结构"></a>12 大容量存储结构</h2><p>可以通过调度磁盘的I&#x2F;O次序来优化性能</p>
<h3 id="12-1-大容量存储结构概述"><a href="#12-1-大容量存储结构概述" class="headerlink" title="12-1 大容量存储结构概述"></a>12-1 大容量存储结构概述</h3><p>概述二级和三级(磁带&#x2F;CD)存储设备的物理结构</p>
<h4 id="12-1-1-磁盘"><a href="#12-1-1-磁盘" class="headerlink" title="12-1-1 磁盘"></a>12-1-1 磁盘</h4><p>磁盘或硬盘为现代计算机系统提供大量外存。在概念上磁盘比较简单（图12-1）。</p>
<center> <img src="./osimg/磁盘结构.png"> </center>

<p>简单讲，磁盘有以下几个关键部件：</p>
<ul>
<li><strong>盘片</strong>（platter）: 每个盘片（platter）为平的圆状，如同CD一样。普通盘片的直径为1.8～3.5英寸（1英寸&#x3D;2.54厘米）。盘片的两面都涂着磁质材料。通过在盘片上进行磁性记录可以保存信息</li>
<li><strong>读写磁头</strong>: 读写磁头“飞行”在一个盘片的表面上方。读取盘片上的信息</li>
<li><strong>磁臂</strong>（disk arm）: 磁头附着在磁臂（diskarm）上，磁臂将<strong>所有磁头</strong>作为一个整体而一起移动</li>
<li><strong>磁道</strong>（track）: 盘片的表面逻辑地分成圆形磁道</li>
<li><strong>扇区</strong>（sector）: 同一磁道再次细分为多个扇区</li>
<li><strong>柱面</strong>（cylinder）: <strong>同一磁臂位置的磁道集合</strong>形成了柱面</li>
</ul>
<p>使用磁盘时，驱动器电机高速旋转磁盘。大多数驱动器每秒旋转60～250次，按<strong>每分钟转数</strong>（Rotation Per Minute, <strong>RPM</strong>）来计。普通驱动器的转速为5400、7200、10000和15000RPM。</p>
<p>磁盘的速度取决于两部分：</p>
<ol>
<li><strong>传输速率</strong>（transfer rate）: 在驱动器和计算机之间的数据流的速率。</li>
<li><strong>定位时间</strong>（positioning time）或<strong>随机访问时间</strong>（random access time）<ul>
<li><strong>寻道时间</strong>（seek time）: <strong>移动磁臂到所要柱面</strong>的所需时间</li>
<li><strong>旋转延迟</strong>（rotational latency）: <strong>旋转磁臂到所要扇区</strong>的所需时间</li>
</ul>
</li>
</ol>
<p>寻道时间和旋转延迟通常为数毫秒。</p>
<p>磁头可能和盘片出现接触，这称为<strong>磁头碰撞</strong>，通常无法修复。</p>
<p>磁盘<strong>可以是可移动的</strong>，允许按需安装不同磁盘。可移动磁盘通常只有<strong>一个盘片</strong>，它保有在塑料盒内以防止不在驱动器内时被损坏。其他形式的<strong>可移动磁盘</strong>包括CD、DVD、蓝光光盘以及称为闪存驱动器（flash drive）的可移动闪存设备（这是一种固态驱动器）。</p>
<p><strong>磁盘驱动器</strong>通过称为<strong>I&#x2F;O总线</strong>（I&#x2F;O bus）的一组电缆<strong>连到计算机</strong>. 有多种可用总线，包括:</p>
<ul>
<li><strong>硬盘接口技术</strong>（Advanced Technology Attachment, <strong>ATA</strong>）</li>
<li><strong>串行ATA</strong>（Serial ATA, <strong>SATA</strong>）</li>
<li><strong>外部串行ATA</strong>（external Serial ATA, <strong>eSATA</strong>）</li>
<li><strong>通用串口总线</strong>（Universal Serial Bus, <strong>USB</strong>）</li>
<li><strong>光纤通道</strong>（Fiber Channel, <strong>FC</strong>）</li>
<li>······</li>
</ul>
<p>数据传输总线由称为<strong>控制器</strong>（controller）的专门电子处理器来进行。</p>
<p><strong>主机控制器</strong>（host controller）为总线的<strong>计算机端的控制器</strong></p>
<p><strong>磁盘控制器</strong>（disk controller）是<strong>磁盘驱动器内置的</strong>. </p>
<p>为了执行磁盘I&#x2F;O操作，计算机通过如9.7.3节所述的<a href="#9-7-3-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84io">内存映射I&#x2F;O端口</a>，发送一个命令到主机控制器。接着，主机控制器<strong>通过消息将该命令送给磁盘控制器</strong>；并且磁盘控制器操作磁盘驱动器硬件，以执行命令。磁盘控制器通常<strong>具有内置缓存</strong>。磁盘驱动器的数据传输，在<strong>缓存和磁盘表面之间</strong>进行；而到主机的数据传输，则按更快速度在<strong>缓存和主机控制器之间</strong>进行。</p>
<h4 id="12-1-2-固态硬盘"><a href="#12-1-2-固态硬盘" class="headerlink" title="12-1-2 固态硬盘"></a>12-1-2 固态硬盘</h4><p><strong>固态磁盘</strong>（Solid-State Disk, <strong>SSD</strong>）, 简单而言，SSD为非易失性存储，可用作硬盘。这种技术，有多个变形，从带有电池（以允许在电源故障时维护状态）的<strong>DRAM</strong>，到<strong>闪存</strong>技术，如单层单元（Single-LevelCell, <strong>SLC</strong>）或多层单元（MultiLevelCell, <strong>MLC</strong>）的芯片。</p>
<p>SSD具有与传统硬盘相同的特性，但是会更可靠，因为没有移动部件. 而且会更快，因为没有寻道时间或延迟(<strong>都没有磁头</strong>)。此外，其电源消耗更少。</p>
<p>因为SSD比磁盘驱动器要快得多，标准总线接口可能会对吞吐量造成重大限制。有些SSD设计成<strong>直接连到系统总线（例如，PCI）</strong>。</p>
<h4 id="12-1-3-磁带"><a href="#12-1-3-磁带" class="headerlink" title="12-1-3 磁带"></a>12-1-3 磁带</h4><p><strong>磁带</strong>（magnetic tape）曾经用作早期的外存媒介。虽然它是相对永久的，可以容纳大量的数据，但是与内存和磁盘相比，它的访问时间更长。另外，磁带随机访问要比磁盘随机访问慢千倍，所以磁带对于外存不是很有用。磁带主要用于备份不常使用的信息，也用作系统之间信息传输的媒介。</p>
<p>磁带绕在轴上，向前转或向后转并通过读写磁头。移到磁带的正确位置需要几分钟，但是<strong>一旦定位，可以按磁盘驱动器相似的速度来读写数据</strong>. </p>
<h5 id="磁盘传输速度"><a href="#磁盘传输速度" class="headerlink" title="磁盘传输速度"></a>磁盘传输速度</h5><p>正如计算的许多方面，公布的磁盘性能数字与现实的性能数字有所不同。例如，声称的<strong>传输速率总是低于有效传输速率</strong>（effective transfer rate）。传输速率可能是，磁头<strong>从磁介质读取比特的速率</strong>；但是这<strong>不同于块被传送到操作系统的速率</strong>。</p>
<h3 id="12-2-磁盘结构"><a href="#12-2-磁盘结构" class="headerlink" title="12-2 磁盘结构"></a>12-2 磁盘结构</h3><p>现代<strong>磁盘驱动器</strong>可以看作<strong>逻辑块（logical block）的一维数组</strong>，这里的逻辑块是最小的传输单位。逻辑块的大小通常为512字节.的磁盘可以通过<strong>低级格式化</strong>（low-level formatted）来选择不同的逻辑块大小，如1024字节，对于这个选项，可以参见12.5.1节。</p>
<p>一维逻辑块数组依次映射到磁盘扇区。扇区0是最外面柱面的第一个磁道的第一个扇区。这个映射是<strong>先按磁道内扇区顺序，再按柱面内磁道顺序，再按从外到内的柱面顺序来进行的</strong>。</p>
<p>这个映射理论上能够将逻辑块号转换为由磁盘内的柱面号、柱面内的磁道号、磁道内的扇区号所组成的老式磁盘地址. 但实际上有两个问题：</p>
<ul>
<li>多数磁盘都有一些<strong>缺陷扇区</strong>，因此映射必须用磁盘上的<strong>其他空闲扇区来替代这些缺陷扇区</strong></li>
<li>对于某些驱动器，每个<strong>磁道的扇区数并不是常量</strong></li>
</ul>
<p>此外</p>
<ul>
<li>采用<strong>恒定线速度</strong>（Constant Linear Velocity，CLV）的媒介(这里的线速度是指数据读取的线速度)，每个<strong>磁道的比特密度是均匀的</strong>。磁道距离磁盘中心越远，长度越长，从而也能容纳更多扇区。当<strong>从外部区域移到内部区域，每个轨道的扇区数量会降低</strong>。最外和最内能差40%的扇区数量。随着<strong>磁头由外磁道移到内磁道</strong>，驱动器<strong>增加旋转速度</strong>，以<strong>保持传输数据率的恒定</strong>。这种方法用于CD-ROM和DVD-ROM驱动器。</li>
<li>采用<strong>恒定角速度</strong>（Constant Angular Velocity，CAV）。内部磁道到外部磁道的<strong>比特密度不断降低</strong>，磁盘<strong>旋转速度可以保持不变以保持数据率不变</strong>。</li>
</ul>
<p>随着技术进步，磁道的扇区数不断增加，通常外部的磁道有几百万个上去，柱面的数量也有几万个</p>
<h3 id="12-3-磁盘链接"><a href="#12-3-磁盘链接" class="headerlink" title="12-3 磁盘链接"></a>12-3 磁盘链接</h3><p>计算机对磁盘的访问有两种方式：</p>
<ol>
<li>是通过<strong>I&#x2F;O端口</strong>（或<strong>主机连接存储</strong>（host-attached storage）），小系统常采用这种方式。</li>
<li>通过<strong>分布式文件系统的远程主机</strong>；这称为<strong>网络连接存储</strong>（network-attached storage）。</li>
</ol>
<h4 id="12-3-1-主机连接存储"><a href="#12-3-1-主机连接存储" class="headerlink" title="12-3-1 主机连接存储"></a>12-3-1 主机连接存储</h4><p>主机连接存储是通过<strong>本地I&#x2F;O端口来访问的存储</strong>。这些端口使用多种技术。</p>
<p>典型的台式PC采用I&#x2F;O总线架构，如<strong>IDE或ATA</strong>。这类架构允许每条I&#x2F;O总线<strong>最多支持两个驱动器</strong>。SATA为更新的、类似的、布线更加简化的一个协议。</p>
<p>高端工作站和服务器通常采用更复杂的I&#x2F;O架构，例如<strong>光纤通道</strong>（Fibre Channel，FC）。FC是一个<strong>高速的串行架构</strong>，运行在<strong>光纤或四芯铜线</strong>上。</p>
<p>它的两个变体分别为：</p>
<ul>
<li>大的交换结构，具有<strong>24位地址空间</strong>。是<strong>存储域网</strong>（Storage-Area Network, <strong>SAN</strong>）的基础. 大的地址空间使得很多设备都可以接入，灵活性好</li>
<li><strong>FC仲裁环路</strong>（FC Arbitrated Loop，FC-AL），可以<strong>寻址126个设备</strong>（驱动器和控制器）。</li>
</ul>
<h4 id="12-3-2-网络连接存储"><a href="#12-3-2-网络连接存储" class="headerlink" title="12-3-2 网络连接存储"></a>12-3-2 网络连接存储</h4><p>NAS iSCSI</p>
<p><strong>网络连接存储（NAS）设备</strong>是一种<strong>专用存储系统</strong>，可以通过数据网络来远程访问（图12-2）</p>
<center> <img src="./osimg/NAS.png"> </center>

<p>客户通过<strong>远程过程调用</strong>（RPC），如UNIX系统的<strong>NFS</strong>或Windows机器的<strong>CIFS</strong>，访问网络连接存储. RPC通过IP网络的TCP或UDP传输数据。</p>
<p><strong>Internet小型计算机系统接口</strong>（Internet SmallComputerSystemInterface，iSCSI）是”最新”的网络连接存储协议。在本质上，它采用IP网络协议来执行SCSI协议。从而，主机与存储之间的<strong>互连可能是网络，而不是SCSI电缆</strong>。因此，主机可以将存储当作好似直接连接的，即使存储远离主机。</p>
<h4 id="12-3-3-存储区域网络"><a href="#12-3-3-存储区域网络" class="headerlink" title="12-3-3 存储区域网络"></a>12-3-3 存储区域网络</h4><p>SAN</p>
<p><strong>网络连接存储(NAS)系统</strong>的一个<strong>缺点</strong>是，存储<strong>I&#x2F;O操作消耗数据网络的带宽</strong>，从而<strong>增加网络通信的延迟</strong>。对于大型客户机-服务器环境更明显。</p>
<p><strong>存储区域网络</strong>（Storage Area Network, <strong>SAN</strong>）为<strong>专用网络</strong>，采用<strong>存储协议</strong>而不是网络协议<strong>连接服务器和存储单元</strong>. <strong>存储I&#x2F;O不消耗网络带宽</strong>.</p>
<p>SAN的优势在于灵活性。多个主机和多个存储阵列可以连接到同一个SAN上, <strong>存储可以动态分配到主机</strong>。SAN交换机允许或禁止主机访问存储。</p>
<center> <img src="./osimg/SAN.png"> </center>

<p>虽然FC是最常见的SAN互连，但是iSCSI使用正在增加。另一个SAN互连是InfiniBand这种专用总线架构提供硬件和软件，以支持服务器和存储单元的高速互连网络。</p>
<h3 id="12-4-磁盘调度"><a href="#12-4-磁盘调度" class="headerlink" title="12-4 磁盘调度"></a>12-4 磁盘调度</h3><p>对于磁盘，访问时间包括两个主要部分：</p>
<ul>
<li><strong>寻道时间</strong>（seek time）是<strong>磁臂移动磁头</strong>到包含目标扇区的<strong>柱面</strong>的时间</li>
<li><strong>旋转延迟</strong>（rotational latency）是磁盘<strong>旋转目标扇区到磁头</strong>下的额外时间。</li>
</ul>
<p><strong>磁盘带宽</strong>（disk bandwidth）是<strong>传输字节的总数除以从服务请求开始到最后传递结束时的总时间</strong>。通过管理磁盘<strong>I&#x2F;O请求的处理次序</strong>，可以<strong>改善访问时间和带宽</strong>。</p>
<p>进程需要进行磁盘I&#x2F;O操作时，它就向操作系统发出一个<strong>系统调用</strong>。这个请求需要一些信息：</p>
<ul>
<li>这个操作是输入还是输出</li>
<li>传输的磁盘地址是什么(传输开始地址)</li>
<li>传输的内存地址是什么(穿书目标地址)</li>
<li>传输的扇区数是多少(数据的大小)</li>
</ul>
<h4 id="12-4-1-fcfs调度"><a href="#12-4-1-fcfs调度" class="headerlink" title="12-4-1 fcfs调度"></a>12-4-1 fcfs调度</h4><p>先来先服务（First-ComeFirstServed, <strong>FCFS</strong>）是最简单的磁盘调度算法，很公平但它通常并不提供最快的服务。</p>
<p>考虑一个磁盘队列，其I&#x2F;O请求块的柱面的顺序如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">98,183,37,122,14,124,65,67</span><br></pre></td></tr></table></figure>
<p>如果磁头开始位于柱面53，那么它首先从53移到98，接着再到183、37、122、14、124、65，最后到67，磁头移动柱面的总数为<strong>640</strong>。这种调度如图12-4所示。</p>
<center> <img src="./osimg/FCFS磁盘调度.png"> </center>

<p>很明显这种方法会移动很多<strong>重复的路程</strong>。</p>
<h4 id="12-4-2-sstf调度"><a href="#12-4-2-sstf调度" class="headerlink" title="12-4-2 sstf调度"></a>12-4-2 sstf调度</h4><p><strong>最短寻道时间优先</strong>（Shortest-Seek-Time-First, <strong>SSTF</strong>）算法要求<strong>优先处理靠近当前磁头位置的所有请求</strong>。</p>
<p>对于上面请求队列的示例，与开始磁头位置（53）的最近请求位于柱面65。一旦位于柱面65，下个最近请求位于柱面67。从那里，由于柱面37比98还要近，所以下次处理37。如此，会处理位于柱面14的请求，接着98，122，124，最后183（图12-5）。这种调度算法的磁头移动只有<strong>236</strong>个柱面</p>
<center> <img src="./osimg/SSTF磁盘调度.png"> </center>

<p>SSTF调度本质上是一种最短作业优先（SJF）调度；与SJF调度一样，它可能会<strong>导致一些请求的饥饿</strong>。假设来到的请求一直位于当前磁头附近，那位于远处的请求可能被延迟很久。</p>
<p><strong>而且SSTF算法并非最优的</strong>，对于这个例子，还可以做得更好：移动磁头从53到37（虽然37并不是最近的），再到14，再到65、67、98、122、124、183。这种策略的磁头移动的柱面总数为<strong>208</strong>。</p>
<h4 id="12-4-3-scan调度"><a href="#12-4-3-scan调度" class="headerlink" title="12-4-3 scan调度"></a>12-4-3 scan调度</h4><p><strong>扫描算法</strong>（SCAN algorithm），磁臂从磁盘的一端开始，向另一端移动；在<strong>移过每个柱面</strong>时，处理请求。当到达磁盘的另一端时，磁头移动方向反转，并继续处理。一直这样反复扫描所有柱面。SCAN算法有时称为<strong>电梯算法</strong>（elevator algorithm）因为磁头的行为就像大楼里面的电梯。</p>
<p>SCAN调度除了知道磁头的当前位置，还需要<strong>知道当前移动方向</strong>，这可以用一个位来简单的表示。</p>
<center> <img src="./osimg/SCAN磁盘调度.png"> </center>

<p>SCAN调度有个很明显的<strong>优化点</strong>，当磁头即将转向时，最先处理的是最近处理的柱面。这显然没有必要，我们可以不反转磁头，而是让<strong>磁头直接回到另一端再次扫描</strong>，因为那些地方的请求等待了最长时间。这就是<strong>C-SCAN调度</strong></p>
<h4 id="c-scan调度"><a href="#c-scan调度" class="headerlink" title="c-scan调度"></a>c-scan调度</h4><p><strong>循环扫描</strong>（Circular SCAN, <strong>C-SCAN</strong>）调度是SCAN的一个变种，以提供<strong>更均匀的等待时间</strong>。像SCAN一样，C-SCAN移动磁头从磁盘一端到磁盘另一端，并且处理行程上的请求。然而，当<strong>磁头到达另一端</strong>时，它<strong>立即返回到磁盘的开头</strong>，而并<strong>不处理任何回程上的请求</strong>.</p>
<center> <img src="./osimg/CSCAN调度.png"> </center>

<p>然而，这也有显然的优化点，我们不需要回到另一端，只需要回到最远的柱面就行了。这就是LOOK调度。</p>
<h4 id="look调度"><a href="#look调度" class="headerlink" title="look调度"></a>look调度</h4><p>SCAN和C-SCAN在磁盘的整个宽度内移动磁臂。实际上，这两种算法通常都不是按这种方式实施的。更<strong>常见的是，磁臂只需移到一个方向的最远请求为止</strong>, 这种模式的SCAN算法和C-SCAN算法分别称为LOOK和C-LOOK调度, 因为它们在向特定方向移动时<strong>查看</strong>是否会有请求。</p>
<center> <img src="./osimg/CLOOK.png"> </center>

<h4 id="12-4-6-磁盘调度算法的选择"><a href="#12-4-6-磁盘调度算法的选择" class="headerlink" title="12-4-6 磁盘调度算法的选择"></a>12-4-6 磁盘调度算法的选择</h4><p><strong>SSTF</strong>是常见的，并且具有自然的吸引力，因为它比FCFS具有更好的性能。</p>
<p><strong>SCAN和C-SCAN</strong>对于<strong>磁盘负荷较大</strong>的系表现更好，因为它们不太可能造成饥饿问题。</p>
<p>我们可以定义最佳的请求执行顺序来优化调度，但是计算最佳调度的所需时间可能得不到补偿。</p>
<p><strong>请求的数量和类型</strong>对调度的性能影响很大。例如，假设队列通常只有一个待处理请求，那只有唯一的选择，所有调度都和FCFS一样。</p>
<p><strong>文件分配方式</strong>可以大大地影响磁盘服务的请求。</p>
<ul>
<li>读取<strong>连续分配文件</strong>时，磁盘请求位置相近，磁头移动少</li>
<li>读取<strong>链接或索引的文件</strong>时，文件块可能<strong>分散</strong>在磁盘上，导致更多的磁头移动</li>
</ul>
<p><strong>目录和索引块的位置</strong>也很重要。因为每个文件必须打开才能使用，并且<strong>打开文件需要搜索目录结构</strong>，所以<strong>目录会被经常访问</strong>。若目录离文件块远的话，移动距离自然更长。目录和索引块的<strong>内存缓存</strong>也有助于<strong>降低磁臂移动距离</strong>，尤其对于读请求。</p>
<blockquote>
<p>磁盘调度和ssd<br>SSD，没有<strong>移动磁头</strong>，通常采用简单的FCFS策略。SSD的观测行为表示，读取服务时间是均匀的，但是由于闪存属性，写入服务时间并不是均匀的。有些SSD调度程序利用这个属性，并且<strong>仅合并相邻的写请求</strong>，按FCFS顺序来处理所有读取请求。</p>
</blockquote>
<p>由于这些复杂因素，磁盘调度算法应该作为操作系统的一个单独模块，以便按需替换。SSTF和LOOK调度可以用于默认调度算法。</p>
<p>这里描述的调度算法<strong>只考虑了寻道距离</strong>。对于现代磁盘，旋转延迟几乎与平均寻道时间一样大。但是操作系统很难调度旋转延迟，因为现代磁盘不透露逻辑块的物理地址。通过<strong>磁盘驱动器的控制器硬件内的磁盘调度算法</strong>，可以一定程度上改善。</p>
<p><strong>调度算法改善的延迟能提高I&#x2F;O性能</strong>，但这并不是唯一需求。不同服务可以有不同的有优先级顺序，例如, <strong>按需调页比应用程序I&#x2F;O具有更高的优先级</strong>，并且当缓存将要用尽可用页面时，写比读更重要。此外，可能需要<strong>保证一组磁盘写入的顺序</strong>，使得文件系统在系统崩溃时<strong>更加稳健</strong>。这需要在<strong>写入文件后及时更新文件系统元数据</strong>。因此，可能违反当前的调度算法。</p>
<h3 id="12-5-磁盘管理"><a href="#12-5-磁盘管理" class="headerlink" title="12-5 磁盘管理"></a>12-5 磁盘管理</h3><p>操作系统还负责磁盘管理的其他几个方面。这里讨论<strong>磁盘初始化、磁盘引导、坏块恢复</strong>等。</p>
<h4 id="12-5-1-磁盘格式化"><a href="#12-5-1-磁盘格式化" class="headerlink" title="12-5-1 磁盘格式化"></a>12-5-1 磁盘格式化</h4><p>没有格式化的磁盘只是一个磁性记录材料的盘子. <strong>低级格式化</strong>（low-levelf ormatting）或<strong>物理格式化</strong>（physical formatting）在磁盘可以<strong>存储数据之前</strong>，它必须<strong>分成扇区</strong>，以便磁盘控制器能够读写。</p>
<p><strong>低级格式化</strong>为每个扇区使用<strong>特殊的数据结构，填充磁盘</strong>。每个扇区的数据结构通常由头部、数据区域（通常为512字节大小）和尾部组成。头部和尾部包含了一些磁盘控制器的使用信息，如<strong>扇区号和纠错代码</strong>（Error-Correcting Code，ECC）。</p>
<p>纠错代码ECC在控制器通过正常I&#x2F;O<strong>写入一个扇区</strong>的数据时<strong>计算ECC值并更新</strong>，并且在<strong>读取重新计算</strong>。如果存储和计算的数值<strong>不一样</strong>，则表示<strong>扇区数据区已损坏，并且磁盘扇区可能已坏</strong>（12.5.3节）。ECC有足够的信息，以便在只有<strong>少数数据损坏</strong>时，控制器能够<strong>识别哪些位已经改变</strong>，并且计<strong>算它们的正确值</strong>应该是什么，然后报告可恢复的软错误。</p>
<p>用<strong>较大扇区来低级格式化磁盘</strong>，意味着每个磁道的扇区数会更少，但也意味着每个磁道的头部和尾部信息会更少, <strong>用户数据的可用空间会更多</strong>。但有的系统只能处理512字节的扇区大小(512为数据区大小，实际扇区大小可能大于512，由于头尾信息)。</p>
<p>在可以使用磁盘存储文件之前，操作系统仍然需要将<strong>自己的数据结构记录在磁盘上</strong>。这分为两步。</p>
<ol>
<li>将磁盘<strong>分为由柱面组成的多个分区</strong>（partition）。操作系统可以将每个分区作为一个单独磁盘</li>
<li>第二步是<strong>逻辑格式化</strong>（logical formatting），或<strong>创建文件系统</strong>。在这一步，操作系统<strong>将初始的文件系统数据结构存储到磁盘上</strong>。这些数据结构包括空闲和已分配的空间和一个初始为空的目录。</li>
</ol>
<p>为了提高效率，大多数操作系统将块组合在一起变成更大的块，经常称为<strong>簇</strong>（cluster）. <strong>磁盘I&#x2F;O按块完成，而文件系统I&#x2F;O按簇完成</strong>，有效确保了I&#x2F;O具有<strong>更多的顺序访问和更少的随机访问</strong>的特点。</p>
<p>有些操作系统允许特殊程序将磁盘分区作为逻辑块的一个大的有序数组，而<strong>没有任何文件系统数据结构</strong>。这个数组有时称为<strong>原始磁盘</strong>（raw disk），这个数组的I&#x2F;O称为<strong>原始I&#x2F;O</strong>（raw I&#x2F;O）。原始I&#x2F;O绕过所有文件系统服务，可以实现更高的效率，对于数据库等应用很好，但大多数还是更适合使用文件系统服务。</p>
<h4 id="12-5-2-引导块"><a href="#12-5-2-引导块" class="headerlink" title="12-5-2 引导块"></a>12-5-2 引导块</h4><p>为了开始运行计算机, 必须有一个初始程序来运行。这个初始<strong>自举</strong>（bootstrap）程序往往很简单。它<strong>初始化系统</strong>的所有部分，从CPU寄存器到设备控制器和内存，接着<strong>启动操作系统</strong>, 找到磁盘上的内核并加载到内存, 然后转到起始地址以便开始操作系统的执行。</p>
<p>大多数计算机的自举程序处在<strong>只读存储器</strong>（Read-OnlyMemory，ROM）中。因为它<strong>不需要初始化而且位于固定位置</strong>而且由于只读属性，不受病毒影响。但是这也导致它<strong>难以更新</strong>。</p>
<p>为此，大多数系统存储一个极小的自举程序在启动ROM中，它的作用是<strong>从磁盘上调入完整的引导程序</strong>。这样就可以自由更新了。完整的引导程序<strong>存储在磁盘固定位置上的“启动块”</strong>。具有启动分区的磁盘称为<strong>启动磁盘</strong>（boot disk）或<strong>系统磁盘</strong>（system disk）。</p>
<p>引导ROM内的代码指示磁盘控制器将引导块读到内存（这时<strong>不加载设备驱动程序</strong>），然后开始执行代码。完整的自举程序比引导ROM的自举程序更加复杂。它可以从非固定的位置加载系统。但它的体积一般还是很小。</p>
<p>以Windows为例，有一个分区为<strong>引导分区</strong>（boot partition），包含<strong>操作系统和设备驱动程序</strong>. Windows系统将引导代码存在<strong>磁盘的第一个扇区</strong>，它称为<strong>主引导记录</strong>（Master Boot Record, <strong>MBR</strong>）。引导首先运行驻留在系统ROM内存中的代码。这个代码指示系统<strong>从MBR中读取引导代码</strong>。除了包含引导代码，MBR包含：一个<strong>表</strong>（以列出磁盘分区）和一个<strong>标志</strong>（以指示从哪个分区引导系统），如图12-9所示。当系统<strong>找到引导分区</strong>，它读取<strong>分区的第一个扇区，称为引导扇区</strong>（boot sector），并继续余下的引导过程，这包括加载各种子系统和系统服务。</p>
<center> <img src="./osimg/12-9.png"> </center>

<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">启动过程</span><br><span class="line">ROM -&gt; MBR -&gt; 从表找到引导分区 -&gt; 读取分区的第一个扇区(引导扇区) -&gt; 继续引导</span><br></pre></td></tr></table></figure>

<h4 id="12-5-3-坏块"><a href="#12-5-3-坏块" class="headerlink" title="12-5-3 坏块"></a>12-5-3 坏块</h4><p>磁盘有部分扇区损坏很正常，出厂可能就要是坏的，这些坏掉的扇区就是<strong>坏块</strong>。</p>
<p>对于<strong>简单磁盘</strong>，如采用<strong>IDE控制器</strong>的磁盘，可以手动处理坏块.</p>
<ul>
<li>一种策略是，在<strong>格式化磁盘时</strong>扫描磁盘以便发现坏块。发现的任何坏块，标记为不可用，让<strong>文件系统不再分配它们</strong>。</li>
<li>若在<strong>正常操作时</strong>块变坏了，则必须人工运行特殊程序（如Linux命令badlocks），以便搜索坏块并锁定它们。坏块的<strong>数据通常不可用</strong></li>
</ul>
<p>更为复杂的磁盘在恢复坏块时更为智能。它的<strong>控制器维护磁盘内的坏块列表</strong>。这个列表在出厂低级格式化时初始化，并且在磁盘使用寿命内更新。低级格式化将一些块放在一边作为<strong>备用</strong>，这些备用块对系统不可见。控制器可以<strong>采用备用块来逻辑地替代坏块</strong>。这种方案称为<strong>扇区备用</strong>（sector sparing）或<strong>扇区转寄</strong>（sector forwarding）。</p>
<p>典型的坏扇区事务可能如下：</p>
<ul>
<li>操作系统尝试读取逻辑块87</li>
<li>控制器计算ECC，并且发现扇区是坏的。它向操作系统报告这一发现</li>
<li><strong>下次</strong>重启操作系统时，可以运行特殊命令，以告诉控制器通过备用块替代坏块</li>
<li>之后，每当系统试图访问逻辑块87时，这一请求转换成控制器的替代扇区的地址。</li>
</ul>
<p>注意，控制器的这种<strong>重定向</strong>可能会使操作系统的<strong>磁盘调度算法失效</strong>。因为系统并不认为这些块是坏的，因此算法决定的处理顺序会和实际访问不同。为了减小影响，最好分配在与<strong>原来相同的柱面</strong>。为此，大多数磁盘在<strong>格式化时为每个柱面保留了少量的备用块</strong>，还<strong>保留了一个备用柱面</strong>。当需要<strong>重新映射坏块</strong>时，控制器<strong>尽可能地使用同一柱面</strong>的备用扇区。</p>
<p>除了扇区备用，有些控制器可以采用<strong>扇区滑动</strong>（sectorslipping）来替换坏块。例如，假定逻辑块17变坏，并且第一个可用的备用块在扇区202之后。那么将17-201的所有块的请求映射到18-202(每个扇区移到下一个)。这之后不会再访问到17.</p>
<p>坏块的更换一般不是全自动的，因为坏块的数据通常会丢失。一些<strong>软错误</strong>(ECC错误之类的)可能<strong>触发一个进程</strong>，以便<strong>复制块数据和备份或滑动块</strong>。然而，不可恢复的<strong>硬错误</strong>（hard error）导致数据丢失。因此，任何使用坏块的文件必须修复（如从备份磁带中恢复），而且<strong>通常需要人工干预</strong>。</p>
<h3 id="12-6-交换空间管理"><a href="#12-6-交换空间管理" class="headerlink" title="12-6 交换空间管理"></a>12-6 交换空间管理</h3><p>虚拟内存以来磁盘或磁盘上的交换空间，但是磁盘比内存慢很多，所以交换空间的使用会<strong>显著降低性能</strong>。为此需要管理好交换空间的使用</p>
<h4 id="12-6-1-交换空间的使用"><a href="#12-6-1-交换空间的使用" class="headerlink" title="12-6-1 交换空间的使用"></a>12-6-1 交换空间的使用</h4><p>交换空间的使用<strong>取决于系统采用的内存管理算法</strong>。例如，实现<strong>交换</strong>的系统可以使用<strong>交换空间来保存整个进程映像，包括代码和数据段</strong>. <strong>分页</strong>系统可能<strong>只是存储换出内存的页面</strong>。</p>
<p>更大的交换空间肯定更好，因为内存的不足会迫使进程终止。所以交换空间大小的<strong>高估优于低估</strong>。</p>
<p>有的操作系统，如Linux，允许使用<strong>多个交换空间</strong>, 包括文件和专用交换分区. 这些交换空间通常<strong>放在不同的磁盘上</strong>，这样分页和交换的I&#x2F;O系统的<strong>负荷可以分散在各个系统I&#x2F;O的带宽上</strong>。</p>
<h4 id="12-6-2-交换空间位置"><a href="#12-6-2-交换空间位置" class="headerlink" title="12-6-2 交换空间位置"></a>12-6-2 交换空间位置</h4><p>交换空间位置有两种：</p>
<ol>
<li>可以<strong>位于普通文件系统</strong>之上: 如果<strong>交换空间</strong>只是文件系统内的一个<strong>大的文件</strong>，则可以采用普通文件系统程序来创建它、命名它以及分配它的空间。但是效率低, <strong>目录结构和磁盘分配数据结构的浏览需要时间和（可能）额外的磁盘访问</strong>。外部碎片可能由于在读写进程镜像时强制多次寻道，大大地增加了交换时间。尽管可以缓存在内存，但还是要承担文件系统的开销</li>
<li>可以是一个<strong>单独的磁盘分区</strong>：可以在单独的<strong>原始分区</strong>（raw partition）上创建交换空间。没有文件系统，也就没有目录结构访问和文件系统的开销。相反，通过单独的<strong>交换空间存储管理器</strong>，从原始分区上分配和取消分配块。可以针对<strong>效率优化</strong>而不那么注重存储，因为运行时交换空间会被<strong>高频访问</strong>，而<strong>存储内容并不会存在很久</strong>(只是跟进程运行时相关的数据). 因此<strong>内部碎片</strong>也会很快消失。</li>
</ol>
<p>有的系统给了两种策略，可根据需求(便利还是高效)选择。</p>
<h4 id="12-6-3-交换空间管理例子"><a href="#12-6-3-交换空间管理例子" class="headerlink" title="12-6-3 交换空间管理例子"></a>12-6-3 交换空间管理例子</h4><p>Solaris1 匿名内存</p>
<p>Linux 页槽4kb 交换映射</p>
<center> <img src="./osimg/Linux交换.png"> </center>

<p>P399</p>
<h3 id="12-7-raid结构"><a href="#12-7-raid结构" class="headerlink" title="12-7 raid结构"></a>12-7 raid结构</h3><p>因为<strong>磁盘操作可以并行进行</strong>，拥有大量磁盘时，有机会改善数据的读写速率和可靠性(信息可以存储在多个磁盘上以留出冗余)。多种<strong>磁盘组织技术</strong>统称为<strong>磁盘余阵列</strong>（Redundant Arrays ofI ndependent Disk, <strong>RAID</strong>）技术，通常用于处理性能与可靠性问题。</p>
<blockquote>
<p>RAID结构<br>RAID存储结构具有多种方式:</p>
<ul>
<li>系统可以将<strong>磁盘直接连到总线上</strong>，让<strong>操作系统或系统软件实现RAID功能</strong></li>
<li>可以通过<strong>硬件</strong>来实现这些磁盘的RAID，让<strong>智能主机控制器可以控制多个连接的磁盘</strong></li>
<li>使用<strong>存储阵列</strong>（storage array）或<strong>RAID阵列</strong>（RAID array）。RAID阵列是一个<strong>独立的单元</strong>，具有自已的控制器、高速缓存（通常）和磁盘；通过一个或更多个<strong>标准控制器（例如，FC）连到主机</strong>。这可以作为即插即用的单元了，它甚至用于拥有RAID软件层的系统</li>
</ul>
</blockquote>
<h4 id="12-7-1-通过冗余提高可靠性"><a href="#12-7-1-通过冗余提高可靠性" class="headerlink" title="12-7-1 通过冗余提高可靠性"></a>12-7-1 通过冗余提高可靠性</h4><p>来看看怎么<strong>分析RAID的可靠性</strong>。</p>
<p>N个磁盘内的某个磁盘故障的机会远远高于单个特定磁盘故障的机会。假设单个磁盘的<strong>平均故障时间</strong>（mean time to failure）为100 000小时，那么<strong>100个磁盘中的某个磁盘的平均故障时间为100 000&#x2F;100&#x3D;1000小时</strong>或41.66天，这并不长.</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">每小时的故障率为1/100 000</span><br><span class="line">那么100个磁盘(假设独立)的每小时故障率为100/100 000 （不应该是1-(1-1/100 000)^100吗，不过这好像不是平均？）</span><br><span class="line">因此平均故障时间为1000小时</span><br></pre></td></tr></table></figure>

<p>可靠性问题的解决是<strong>引入冗余</strong>（redundancy）；存储额外信息，即将一份数据存在多个磁盘上，既是一个损坏也可以通过其他恢复。</p>
<p>最为简单（但最昂贵）的引入冗余的方法是，重复每个磁盘。这种技术称为<strong>镜像</strong>（mirroring）。由于镜像，每个<strong>逻辑磁盘由两个物理磁盘</strong>组成，并且每次<strong>写入都在两个磁盘上进行</strong>。这称为<strong>镜像卷</strong>（mirrored volume）。</p>
<p><strong>镜像卷的平均故障时间</strong>（这里的故障是数据丢失）取决于两个因素。一个是，单个磁盘的<strong>平均故障时间</strong>。另一个是<strong>平均维修时间</strong>（mean time to repair），这是用于替换损坏磁盘并恢复其上数据的平均时间。假设磁盘故障独立(其实通常不独立)。</p>
<p>那么，如果单个磁盘的平均故障时间为100 000小时，并且平均修补时间为10小时，则镜像磁盘系统的<strong>平均数据丢失时间</strong>（mean time to data loss）为100 000²&#x2F;（2×10）&#x3D;500×10^6 小时或57000年。</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">假设当前一个磁盘损坏，那之后的十小时内，另一个磁盘损坏的概率为：</span><br><span class="line">10/100 000</span><br><span class="line">只有两个损坏才能损失数据</span><br></pre></td></tr></table></figure>

<p>电源故障是一个特别的关注点, 即使使用磁盘镜像，如果对两个磁盘写入同样的块，而在<strong>两块完全写入之前电源故障</strong>，则这两块<strong>可能处于不一致的状态</strong>。</p>
<p>这个问题的一种解决方法是，先写一个副本，再写下一个。<br>另一个是，为<strong>RAID阵列添加固态非易失性RAM</strong>（Nonvolatile RAM, <strong>NVRAM</strong>）的缓存。即使<strong>断电NVRAM仍然能将缓存的数据保存</strong>，下次磁盘通电就可写回。若NVRAM有某种错误避免和纠错功能如ECC，写入可以被视作完成。</p>
<h4 id="12-7-2-通过并行处理提高性能"><a href="#12-7-2-通过并行处理提高性能" class="headerlink" title="12-7-2 通过并行处理提高性能"></a>12-7-2 通过并行处理提高性能</h4><p>现在分析<strong>多个磁盘的并行访问如何改善性能</strong>。</p>
<p>通过<strong>磁盘镜像</strong>, <strong>读请求</strong>的处理速度可以<strong>加倍</strong>，因为读请求可以送到任一磁盘. <strong>每次读取的传输速率是与单个磁盘系统相同</strong>，但是每<strong>单位时间的读取次数翻了一番</strong>。</p>
<p>注意，这里加倍只是因为可以多个磁盘<strong>分摊读请求，单个文件的传输并没有加快</strong></p>
<p>采用多个磁盘，通过<strong>将数据分散在多个磁盘上</strong>，也可以<strong>改善传输率</strong>.</p>
<p>最简单形式是，数据分条（data striping）包括将<strong>每个字节分散在多个磁盘上</strong>；这种分条称为<strong>位级分条</strong>（bit-level striping）例如，如果有8个磁盘，则可以将每个字节的位i写到磁盘i上。这8个磁盘可作为单个磁盘使用，其扇区为正常扇区的8倍，更为重要的是它<strong>具有8倍的访问率</strong>. <strong>每个磁盘</strong>参与<strong>每个访问</strong>（读或写）；</p>
<p>注意，位级分条对<strong>单个文件的速度提升至n倍</strong>，但是<strong>单位时间的文件处理量和单个磁盘相同</strong></p>
<p>位级分条可以<strong>推广到其他磁盘数量</strong>，它或者是<strong>8的倍数或者8的因子</strong>。例如，如果采用4个磁盘阵列，则每个字节的<strong>位i和位4+i</strong>可存在<strong>磁盘i</strong>上。</p>
<p>此外，分条不必按位级来进行。对于<strong>块级分条</strong>（block-level striping），文件的<strong>块可以分散在多个磁盘上</strong>；对于n个磁盘，文件的块i可存在磁盘（i mod n）+ 1 上。其他分条级别，如<strong>单个扇区或单块扇区的字节，也是可能的</strong>。块级分条最常见</p>
<p><strong>分条实现了磁盘系统的并行化</strong>，有两个主要目标：</p>
<ul>
<li>通过负载平衡，增加了多个小访问（即页面访问）的吞吐量。（镜像分摊请求）</li>
<li>降低大访问的响应时间。（分条提高单个访问的完成速度）</li>
</ul>
<h4 id="12-7-3-raid级别"><a href="#12-7-3-raid级别" class="headerlink" title="12-7-3 raid级别"></a>12-7-3 raid级别</h4><p>镜像提供高可靠性，但是昂贵.<br>分条提供高数据传输率，但并<strong>未改善可靠性</strong>。</p>
<p>通过磁盘分条和“奇偶”位（下面将要讨论），在<strong>低代价</strong>下提供冗余可以有多种方案。这些方案有不同的性价折中，并分成不同的级别，称为<strong>RAID级别</strong>（RAID level）。</p>
<p>（图中，P表示纠错位，而C表示数据的第二副本）。</p>
<center> <img src="./osimg/RAID_LEVEL.png"> </center>

<ul>
<li>RAID 0 : 有块分条但没有见余（如镜像或奇偶位）的磁盘阵列, <strong>提供n倍的读取速率，减小响应延迟</strong></br><center> <img src="./osimg/raid0.png"> </center></li>
<li>RAID 1: 指磁盘镜像, <strong>提供同时处理n个读的能力，增大吞吐量</strong></br><center> <img src="./osimg/raid1.png"> </center></li>
<li>RAID 2: 称为<strong>内存方式的差错纠正（ECC）组织</strong>。内存系统长期以来实现了<strong>基于奇偶位的错误检测</strong>。内存系统内的<strong>每个字节</strong>都有一个<strong>关联的奇偶位</strong>，以<strong>记录字节中为1的个数是偶数（parity&#x3D;0）或是奇数(parity&#x3D;1)</strong>. 如果字节的1个位发生了损坏(0-&gt;1 或 1-&gt;0),字节的奇偶校验位改变, 检测到差错。差错<strong>纠正方案</strong>存储两个或多个额外位，并且当<strong>单个位出错</strong>时可以重建数据。</br>ECC方法通过将字节分散在磁盘上，可以直接用于磁盘阵列。例如，每个字节的第1位可以存在磁盘1上，第2位在磁盘2上，等等，直到第8位存在磁盘8上；而纠错位存在其他磁盘上。这个方案如图12-11c所示，其中标记为P的磁盘存储了差错纠正位。如果有<strong>一个磁盘故障了</strong>，则可<strong>从其他磁盘中读取字节的其余位</strong>和<strong>相关差错纠正位</strong>，以<strong>重构损坏的数据</strong>。请注意，对于4个磁盘的数据，RAID级别2只用了3个额外磁盘，而RAID级别1则需要4个额外磁盘。</br>关于为什么只用3个，和汉明码有关，介绍如下</br><center> <img src="./osimg/raid2汉明码.png"> </center></br><center> <img src="./osimg/raid2.png"> </center></li>
<li>RAID 3: RAID级别3或<strong>位交错奇偶校验结构</strong>，改进了级别2。考虑了如下事实：与内存系统不同，磁盘<strong>控制器能够检测到一个扇区是否正确读取</strong>，这样<strong>单个奇偶位可以用于差错检测和差错纠正</strong>. 如果一个扇区损坏了, 我们就知道它是哪个扇区；而且通过<strong>计算其他磁盘扇区的相应位的奇偶值，可以得出损坏的位是1还是0</strong>。如果<strong>剩余位的奇偶校验等于存储奇偶值</strong>(字节的全部1由剩余位提供)，则丢失位为0, 否则为1。 </br> 与RAID 2相比是<strong>完全的上位替代</strong>，需要的额外磁盘更少了，因此几乎只用RAID 3。</br>与RAID 1相比，RAID 3有两个优点。第一，多个普通磁盘只需个奇偶磁盘, <strong>降低了额外存储</strong>。第二，由于采用<strong>N路分散数据</strong>，字节的读写分布在多个磁盘上，所以<strong>单块读写</strong>的<strong>传输速度是RAID 1的N倍</strong>。从<strong>负面</strong>来说，由于<strong>每个磁盘都要参与每次I&#x2F;O请求</strong>，RAID 3的<strong>每秒I&#x2F;O次数将更少</strong>。</br>RAID 3的另一性能问题是，需要<strong>计算和写入奇偶校验位</strong>。这导致<strong>写入更慢</strong>。但是，许多<strong>RAID存储阵列的控制器</strong>带有专门计算奇偶校验位的硬件。这种控制器将奇偶校验位计算从CPU转移到阵列。这种阵列还有NVRAM缓存，以便在计算奇偶校验位时存储块，并且缓存从控制器到磁盘的写入。这几乎抵消了额外计算开销，使得其<strong>有缓存性能超过无缓存非奇偶校验的RAID</strong>。</br><center> <img src="./osimg/raid3.png"> </center></li>
<li>RAID 4: <strong>交错奇偶校验结构</strong>采用<strong>块级分条</strong>，这与RAID 0一样，此外在<strong>一个单独的磁盘上保存其他N个磁盘的块的奇偶校验块</strong>。<strong>每个块的读只访问一个磁盘</strong>，可以<strong>允许其他磁盘处理其他请求</strong>。因此，虽然<strong>每个访问的数据传输速率更慢</strong>，但是<strong>多个读访问可以并行</strong>处理，导致了<strong>更高的总体I&#x2F;O速率</strong>。大的读取传输速率很高，因为可以并行读取所有磁盘。大的写入也有很高传输速率，因为可以<strong>并行写入数据和奇偶校验</strong>。</br><strong>小的独立写入不能平行执行</strong>。操作系统写入的数据<strong>小于一块要求</strong>，读取块，修改新数据，并写回。奇偶校验块也必须更新。这称为<strong>读－改－写周期</strong>（read-modify-write cycle）。因此，单个写需要<strong>4次磁盘访问</strong>：两次读入<strong>两个旧块</strong>(数据块和校验块)，两次写入<strong>两个新块</strong>(数据块和校验块)。</br><center> <img src="./osimg/raid4.png"> </center></li>
<li>RAID 5: <strong>交错分布奇偶校验结构</strong>也是<strong>块状分条</strong>，不同于级别4：它将<strong>数据和奇偶校验分散在所有N+1个磁盘上</strong>，而不是用单独的磁盘存校验位。第n块的<strong>奇偶校验保存在磁盘（n mod 5）+ 1上；其他4个磁盘的第n块保存该奇偶块对应的真正数据</strong>。奇偶<strong>校验块不能保存同一磁盘的块的奇偶校验</strong>，因为磁盘故障会导致数据及奇偶校验的丢失，因此无法恢复损失。因此RAID 5比RAID 4更可靠，也成为了<strong>最常见的奇偶校验RAID系统</strong></br><center> <img src="./osimg/raid5.png"> </center></li>
<li>RAID 6: 称为<strong>P+Q冗余方案</strong>（P+Q redundancy scheme），与RAID级别5非常类似，但是<strong>存了额外余信息以防范多个磁盘故障</strong>。除了使用奇偶校验，可以使用差错纠正码，如Read-Solomon码。在图12-11g所示的方案中，每4位的数据<strong>使用了2位的冗余数据</strong>，而不是像级别5那样的一个奇偶位，这个系统可以<strong>容忍两个磁盘故障</strong>。</br><center> <img src="./osimg/raid6.png"> </center></li>
<li>RAID 0+1: 为RAID 0 和RAID 1的组合。RAID 0提供了性能，而RAID1提供了可靠性。性能比RAID 5高，但也更昂贵(存储翻倍)。对于RAID 0+1，一组<strong>磁盘分成条，每一条镜像到另一条</strong>。</br><center> <img src="./osimg/raid01.png"> </center></br><center> <img src="./osimg/RAID_01.png"> </center></li>
<li>RAID 1+0: 为RAID 1 和RAID 0的组合, 但是<strong>先镜像再块分条</strong>。他有相对于RAID 0+1的优点。例如，如果<strong>RAID0+1中的一个磁盘故障</strong>，那么<strong>整个条就不能访问</strong>，虽然所有其他条可用。对于RAID1+0，如果单个磁盘不可用，但其镜像仍然如所有其他磁盘一样可用</br><center> <img src="./osimg/raid10.png"> </center></br><center> <img src="./osimg/RAID_10.png"> </center></li>
</ul>
<p>RAID 10 &#x2F; 01 P403</p>
<p>RAID的实现也很多样，可以在多个层次上实现：</p>
<ul>
<li><strong>卷管理软件</strong>可以在<strong>内核或系统软件层中实现RAID</strong>。这时存储硬件可以提供最少的功能。奇偶校验RAID的软件实现相当慢，因此通常<strong>采用RAID 0、RAID 1或RAID 0+1</strong>。</li>
<li>可以采用<strong>主机总线适配器</strong>（HostBus-Adapter, <strong>HBA</strong>）硬件, 只有直接连到HBA的磁盘才能成为给定RAID集的一部分。成本低但不灵活。</li>
<li>RAID实现可以采用<strong>存储阵列硬件</strong>，一切由硬件提供。系统<strong>只需要在每个卷上实现文件系统</strong>。阵列可有多个连接可用，或可以是SAN的一部分，允许多个主机利用阵列功能。</li>
<li>RAID实现可以<strong>采用磁盘虚拟化设备的SAN互连层</strong>。在这种情况下，设备位于主机和存储之间。它接受来自服务器的命令，并管理访问存储。例如，通过将每块写到两个单独的存储设备来提供镜像。</li>
</ul>
<p>快照和复制机制也可以实现。</p>
<ul>
<li><strong>快照</strong>（snapshot）是在<strong>最后一次更新之前文件系统的视图</strong></li>
<li><strong>复制</strong>（replication）涉及不同站点之间的自动复制写入，以提供余和失败恢复。</li>
</ul>
<p>复制可以是同步或异步的。对于<strong>同步复制</strong>，在写入完成之前，必须在本地和远程的站点中写入每块。对于<strong>异步复制</strong>，写入是定期地按组来进行的。主站点故障，则<strong>异步复制可能导致数据丢失</strong>，但是它更快且没有距离限制。</p>
<p>大多数RAID实现的另一方面是<strong>热备份磁盘</strong>。热备份（hot spare）不是用于存储数据，但是<strong>配置成在磁盘故障时用作替换</strong>。可以<strong>快速重建</strong>RAID等级。</p>
<h4 id="12-7-4-raid级别选择"><a href="#12-7-4-raid级别选择" class="headerlink" title="12-7-4 raid级别选择"></a>12-7-4 raid级别选择</h4><p>一个考虑是<strong>重构性能</strong>。如果磁盘故障，则重建数据的所需时间可能很大。如果要求持续提供数据，如高性能或交互式数据库系统，那么这可能是个重要因素。此外，重建性能影响<strong>平均故障时间</strong>。</p>
<p>重建性能随着使用RAID级别而异. <strong>RAID级别1的重建最简单</strong>，因为可以从另一个磁盘来复制数据。对于<strong>其他级别</strong>，需要<strong>访问阵列内的所有其他磁盘</strong>，以便重建故障磁盘的数据。对于大磁盘集的RAID5重建，可能需要几个小时。</p>
<p>以下为常见的RAID选择：</p>
<ul>
<li>RAID级别0用于<strong>数据损失并不重要</strong>的<strong>高性能应用</strong></li>
<li>RAID级别1，对于需要<strong>高可靠性</strong>和<strong>快速恢复</strong>的应用</li>
<li>RAID0+1和RAID1+0用于<strong>性能和可靠性都重要的应用</strong>，例如小型数据库。</li>
<li>由于RAID1的高空间开销，RAID5通常是<strong>存储大量数据的首选</strong></li>
<li>RAID 6虽然更可靠，但是很少有支持他的RAID实现</li>
</ul>
<p>此外，确定保护位的数目也可以考虑，太多占用空间，太少可能需要经常重建。P405</p>
<h4 id="12-7-5-扩展"><a href="#12-7-5-扩展" class="headerlink" title="12-7-5 扩展"></a>12-7-5 扩展</h4><p>RAID分散的思想可用于很多其他领域来改进传输速率和吞吐量<br>P405</p>
<h4 id="12-7-6-raid的问题"><a href="#12-7-6-raid的问题" class="headerlink" title="12-7-6 raid的问题"></a>12-7-6 raid的问题</h4><p><strong>RAID防范物理媒介错误</strong>(磁盘自身)，但<strong>不是其他硬件和软件错误</strong>。与软件和硬件错误一样，系统数据潜在危险也有许多。例如，文件指针可能是错的，或文件结构内的指针可能是错的。</p>
<p>Solaris ZFS文件系统采用创新方法来解决, ZFS使用<strong>校验和</strong>(check sum)验证数据完整性. ZFS维护所有块（包括数据和元数据）的内部校验和. <strong>校验和与块的指针放在一起</strong>. 考虑一个信息节点（inode）（存储文件系统元数据的结构），带有数据指针。每个<strong>数据块的校验和位于inode内</strong>。如果数据有问题，则校验和会不正确，并且文件系统会知道它。类似地，指向<strong>inode的目录条目具有inode的校验和</strong>。</p>
<center> <img src="./osimg/ZFS_checksum.png"> </center>

<p>每次访问目录，这些校验和都被检查以维护系统正确性。</p>
<p>还有有关灵活性的问题在P406</p>
<p>InServ存储阵列<br>···</p>
<h3 id="12-8-稳定存储实现"><a href="#12-8-稳定存储实现" class="headerlink" title="12-8 稳定存储实现"></a>12-8 稳定存储实现</h3><p>第6章介绍了<strong>预写日志</strong>，它要求使用稳定存储。根据<strong>定义</strong>，位于<strong>稳定存储的数据永远不会丢失</strong>。为了实现这种存储，需要<strong>复制所需信息到多个具有独立故障模式的存储设备</strong>（通常为磁盘）。还<strong>需要协调更新写入</strong>，以保证更新过程中的故障不会让所有副本处于损坏状态，还<strong>保证即使恢复时出现另一故障，可以强制所有副本处于一致且正确的值</strong>。本节将讨论如何满足这些需求。</p>
<p>磁盘写入导致三种结果：</p>
<ul>
<li>成功完成：数据正确写到磁盘。</li>
<li>部分故障：在传输中出现故障，这样<strong>有些扇区写了新数据</strong>，而在故障发生时<strong>正在写的扇区可能已被破坏</strong>。</li>
<li>完全故障：在磁盘<strong>写入开始之前发生故障</strong>，因此磁盘上的<strong>以前数据值保持不变</strong></li>
</ul>
<p>无论何时写入块时发生故障，系统需要检测到，并调用恢复程序使得数据块恢复到一致状态。这<strong>需要系统为每个逻辑块维护两个物理块</strong>，并如下操作：</p>
<ul>
<li>将信息写到第一个物理块</li>
<li>第一次写入成功完成时，将同样信息写到第二个物理块</li>
<li>只有第二次写入成功完成，才可<strong>声明操作完成</strong>。</li>
</ul>
<p>故障恢复时，每对物理块都要检查。</p>
<ul>
<li>如果<strong>两块相同</strong>并且<strong>不存在可检测到的错误</strong>，则不需要进一步的动作。</li>
<li>如果<strong>一块含有可检测到的错误</strong>，则用<strong>另一块的值替换它</strong>的内容</li>
<li>如果两块<strong>都没有可检测到的错误</strong>，则<strong>用第二块的内容替换第一块</strong></li>
</ul>
<p>这个恢复程序<strong>确保稳定存储的写入要么完全成功要么没有任何变化</strong>。</p>
<p>也可以采用更多的副本来增加可靠性，但一般两个足够模拟稳定存储了</p>
<p>因为<strong>等待磁盘写入完成（同步I&#x2F;O）费时</strong>，许多存储陈列<strong>增加了NVRAM缓存</strong>。由于这种内存是<strong>非易失性</strong>的（通常它用电池作为该单元的后备电源），可以<strong>相信它能够存储存到磁盘的途中数据</strong>。因此，可以认为它是稳定存储的一部分。对<strong>它的写入比对磁盘的写入快得多</strong>，这样大大地<strong>提高了性能</strong>。</p>
<h2 id="13-i-o系统"><a href="#13-i-o系统" class="headerlink" title="13 i&#x2F;o系统"></a>13 i&#x2F;o系统</h2><p>I&#x2F;O系统的功能是管理并控制I&#x2F;O操作和I&#x2F;O设备。</p>
<h3 id="13-1-概述"><a href="#13-1-概述" class="headerlink" title="13-1 概述"></a>13-1 概述</h3><p>I&#x2F;O设备种类繁多且差异较大，因此需要不同的管理方案，这也导致<strong>I&#x2F;O控制和管理十分复杂</strong>。为此，设计<strong>I&#x2F;O子系统</strong>来分离控制，使得<strong>内核的其他部分不必涉及复杂的I&#x2F;O操作</strong>。</p>
<p>I&#x2F;O设备技术呈现两个冲突趋势：</p>
<ul>
<li>一方面，软件和硬件的<strong>接口标准化</strong>日益增长，有助于将改进升级设备集成到现有计算机和操作系统</li>
<li>另一方面，I&#x2F;O<strong>设备的种类也日益增多</strong>。而且设备间差异也很大，无法套用旧的方法。为此，需要软硬件结合来实现灵活的I&#x2F;O处理。</li>
</ul>
<p>I&#x2F;O设备的基本要素，如<strong>端口、总线及设备控制器</strong>，适用各种各样的I&#x2F;O设备。为<strong>封装</strong>各种设备的细节与特点，操作系统内核采用<strong>设备驱动程序模块</strong>，为I&#x2F;O子系统<strong>提供了统一的设备访问接口</strong>，就像系统调用为应用程序与操作系统之间提供了标准接口。</p>
<h3 id="13-2-i-o硬件"><a href="#13-2-i-o硬件" class="headerlink" title="13-2 i&#x2F;o硬件"></a>13-2 i&#x2F;o硬件</h3><p>计算机与设备的通信能通过电缆甚至空气发送消息。这些交互和通信有以下几个概念需要了解</p>
<h4 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h4><p>设备与计算机的<strong>通信</strong>通过一个<strong>连接点</strong>或<strong>端口</strong>（port），例如，串行端口。端口相当于传输的门。</p>
<h5 id="i-o端口寄存器"><a href="#i-o端口寄存器" class="headerlink" title="i&#x2F;o端口寄存器"></a>i&#x2F;o端口寄存器</h5><p>I&#x2F;O端口通常由<strong>四个寄存器组成</strong>，即状态、控制、数据输人和数据输出寄存器。</p>
<ul>
<li><strong>数据输入寄存器(向主机输入)<strong>（data-in register）被主机</strong>读出</strong>以获取数据</li>
<li><strong>数据输出寄存器(向设备输出)<strong>（data-out register）被主机</strong>写入</strong>以发送数据。</li>
<li><strong>状态寄存器</strong>（status register）包含一些<strong>主机可以读取的位</strong>，例如当前命令是否完成、数据输入寄存器中是否有数据可以读取、是否出现设备故障等。</li>
<li><strong>控制寄存器</strong>（control register）可<strong>由主机写入，以便启动命令或更改设备模式</strong>。例如，串口控制寄存器中的一位选择全工通信或单工通信，另一位控制启动奇偶校验检查，第三位设置字长为7或8位，其他位选择串口通信支持的速度等。</li>
</ul>
<p><strong>数据寄存器的大小通常为1～4字节</strong>。有些控制器有<strong>FIFO芯片</strong>，可以保留多个输人或输出字节，以便在数据寄存器大小的<strong>基础上扩展控制器的容量</strong>(排队)。</p>
<h4 id="总线-链接"><a href="#总线-链接" class="headerlink" title="总线(链接)"></a>总线(链接)</h4><p>若<strong>设备共享一组通用线路</strong>，则这种<strong>连接称为总线</strong>。总线（bus）是<strong>一组线路和通过线路传输信息的严格定义的一个协议</strong>。采用电子学术语来说，消息是通过施加线路的具有一定时序的电压模式来传递的。</p>
<p>如果设备A通过线路连到设备B，B又通过线路连到设备C，C通过端口连到计算机，则这种方式称为<strong>菊花链</strong>（daisy chain）。菊花链通常<strong>按照总线运行</strong>。</p>
<p><strong>总线</strong>在计算机体系结构中应用广泛，它们在信令方法、速度、吞吐量和连接方法等方面差异很大。以下为一个PC的总线结构</p>
<center> <img src="./osimg/PC.png"> </center>

<p>在图中, <strong>PCI总线</strong>（PCI bus）（常用PC系统总线）将<strong>处理器内存子系统连到快速设备</strong>. <strong>扩展总线</strong>（expansion bus）连接相<strong>对较慢的设备</strong>，如键盘和串口和USB端口。4个磁盘通过<strong>小型计算机系统接口</strong>（Small Computer System Interface，SCSI）总线<strong>连到SCSI控制器</strong>。</p>
<p>还有用于连接其他部分的总线，如<strong>PCI Express (PCIe)和HyperTransport</strong>。</p>
<p>总之，总线将计算机各部分连接起来并允许他们按规则传输信息。</p>
<h4 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h4><p><strong>控制器</strong>（controller）是<strong>可以操作端口、总线或设备</strong>的一组电子器件。其功能多样，有简单的也有复杂的。</p>
<p>简单的如<strong>串行端口控制器</strong>，它<strong>是计算机内的单个芯片</strong>（或芯片的一部分），用于<strong>控制串口线路的信号</strong>。复杂的有<strong>SCSI总线控制器</strong>，SCSI协议复杂，SCSI总线控制器通常<strong>为单独的电路板</strong>（或<strong>主机适配器</strong>（host adapter）），可以连到计算机。它通常<strong>包含处理器、微代码和一些专用内存</strong>，能够处理SCSI协议消息。部分设备自带处理器，比如磁盘，附在一边的线路板就是<strong>磁盘控制器</strong>。实现了<strong>串行高级技术连接SATA</strong>的磁盘就有这一部分，它<strong>有微码和处理器</strong>来处理许多任务，如坏簇映射、预取、缓冲和高速缓存。</p>
<p>关于处理器如何对控制器发出命令和数据以便完成I&#x2F;O传输。</p>
<p>简单答案是, <strong>控制器具有一个或多个寄存器，用于数据和控制信号</strong>。处理器通过<strong>读写这些寄存器的位模式</strong>来<strong>与控制器通信</strong>。</p>
<p>一种方式是，通过<strong>使用特殊I&#x2F;O指令针对I&#x2F;O端口地址传输一个字节或字</strong>。I&#x2F;O指令触发总线线路，选择适当设备，并<strong>将位移入或移出设备寄存器</strong>。以下为常用的I&#x2F;O端口地址</p>
<center> <img src="./osimg/IO端口地址.png"> </center>

<p>或者，设备控制器可以<strong>支持内存映射I&#x2F;O</strong>（memory-mapped I&#x2F;O）。在这种情况下，设备控制<strong>寄存器被映射到处理器的地址空间</strong>。处理器执行I&#x2F;O请求是<strong>通过标准数据传输指令读写映射到物理内存的设备控制器</strong>。</p>
<p>大部分系统两种都支持并使用。对于需要性能的，比如<strong>图形控制器</strong>，使用<strong>内存映射来快速写入</strong>并把内容输出到屏幕。但是内存映射也带来了潜在威胁，可能出现软件错误导致指针往不应该的位置写入数据，可能导致数据或设备损坏。</p>
<p>I&#x2F;O指令发向I&#x2F;O端口，之后再给到设备控制器寄存器，I&#x2F;O端口也有<a href="#io%E7%AB%AF%E5%8F%A3%E5%AF%84%E5%AD%98%E5%99%A8">寄存器</a>，CPU会查找端口的状态来决定行动，也会向数据寄存器发送字节。</p>
<h4 id="13-2-1-轮询"><a href="#13-2-1-轮询" class="headerlink" title="13-2-1 轮询"></a>13-2-1 轮询</h4><p>主机与控制器之间交互的完整协议可以很复杂，但基本握手概念则比较简单。主机需要通过端口来输出数据时，主机与控制器之间握手的协调如下：</p>
<p>(<strong>忙位在控制器的状态寄存器上，表示是否空闲(0). 控制器上的命令寄存器的命令就绪位，控制器上的命令寄存器的命令就绪位表示执行意愿，主机有命令希望执行时需要设置这个位</strong>)</p>
<ol>
<li>主机重复读取忙位，直到该位清零。</li>
<li>主机<strong>设置命令寄存器的写位</strong>，并写出一个字节到<strong>数据输出寄存器</strong>。</li>
<li>主机<strong>设置命令就绪位</strong>。</li>
<li>当控制器注意到命令就绪位已设置，则设置忙位。</li>
<li>控制器读取命令寄存器，并看到写命令。它从数据输出寄存器中读取一个字节，并向设备执行I&#x2F;O操作。</li>
<li>控制器清除命令就绪位, <strong>清除状态寄存器的故障位表示设备I&#x2F;O成功</strong>，清除忙位表示完成任务。</li>
</ol>
<p><strong>每个字节重复这个循环</strong>。在步骤1中，主机处于<strong>忙等待</strong>（busy-waiting）或<strong>轮询</strong>（polling）。在该循环中，一直读取状态寄存器，直到忙位被清除。要是等待的短还好说，时间长的话就要<strong>切换到别的任务更好</strong>。问题是怎么知道等多久改回来处理。隔得太久可能由于<strong>缓冲区溢出导致数据丢失</strong>。</p>
<p>对于许多计算机体系结构，轮询设备只要使用<strong>三个CPU指令周期</strong>就足够了：读取设备寄存器，逻辑AND以提取状态位，根据是否为0进行跳转。显然，基本轮询操作还是高效的。但是一直占着CPU不放也不好搞，这导致其他需要CPU进程的等待。</p>
<p>为此，可以使用<strong>中断</strong>来让<strong>设备准备好服务时通知处理器</strong>。这样就不需要忙等待了。</p>
<h4 id="13-2-2-中断"><a href="#13-2-2-中断" class="headerlink" title="13-2-2 中断"></a>13-2-2 中断</h4><p>基本中断机制的工作原理如下</p>
<p>CPU硬件有一条线，称作<strong>中断请求线</strong>（Interrupt-Request Line, <strong>IRL</strong>）；CPU在<strong>执行完每条指令后，都会检测IRL</strong>。发现控制器在IRL上发出了一个信号时，CPU<strong>执行状态保存</strong>并且<strong>跳到内存固定位置的中断处理程序</strong>。</p>
<p>中断处理程序<strong>确定中断原因，执行必要处理，执行状态恢复，并且执行返回中断指令以便CPU回到中断前的执行状态</strong>。以下为<strong>中断驱动的I&#x2F;O循环示意图</strong></p>
<center> <img src="./osimg/中断驱动的IO.png"> </center>

<p>这样的基本中断机制可以使得CPU响应异步事件。然而，对于现代操作系统，我们需要更为复杂的中断处理功能。</p>
<ul>
<li>在关键处理时，需要能够<strong>延迟中断处理</strong>。</li>
<li>要一种有效方式，以便<strong>分派中断到合适的中断处理程序</strong>，而无需首先轮询所有设备才能看到哪个引起了中断。</li>
<li>需要<strong>多级中断</strong>，以便操作系统能够<strong>区分高优先级或低优先级</strong>的中断，能够根据紧迫性的程度来响应。</li>
</ul>
<p>对于现代计算机硬件，这<strong>三个功能可由CPU与中断控制器硬件</strong>（interrupt-controller hardware）来提供。</p>
<h5 id="延迟中断处理"><a href="#延迟中断处理" class="headerlink" title="延迟中断处理"></a>延迟中断处理</h5><p>大多数CPU<strong>有两条中断请求线</strong>。一条是<strong>非屏蔽中断</strong>（nonmaskable interrupt），保留用于诸如不可恢复的内存错误等事件。另一条中断线是<strong>可屏蔽中断</strong>（maskable interrupt）的：在<strong>执行不得中断的关键指令序列之前，它可以由CPU关闭</strong>。可屏蔽中断可<strong>由设备控制器用来请求服务</strong>。</p>
<p>也就是说，非屏蔽中断线上的都是必须处理的重要事项，可屏蔽中断线的则是不需要即时处理的。若在进行原子操作时希望暂时禁用中断，则此时的中断为可屏蔽中断，若CPU关闭可屏蔽中断，那么这个中断永远不会处理。</p>
<h5 id="高效分配中断"><a href="#高效分配中断" class="headerlink" title="高效分配中断"></a>高效分配中断</h5><p>中断机制接受一个<strong>地址</strong>（address），根据这个数字<strong>从一个小集合可以选择一个特定中断处理程序</strong>。这个<strong>地址</strong>称为中断向量（interrupt vector）的<strong>表中的一个偏移量</strong>。</p>
<p>中断向量包含了专门的中断处理程序的内存地址，目的是让单个中断处理不再需要搜索所有可能中断。</p>
<p>然而，实际上，计算机设备（以及相应的中断处理程序）常常多<strong>于中断向量内的地址</strong>。解决这个问题的常见方法是<strong>采用中断链</strong>（interrupt chaining）技术。中断向量内的每个元素指向中断处理程序列表的头，有中断时<strong>在列表上依次执行直到找到合适的</strong>。这是在空间和时间开销上的折中。</p>
<center> <img src="./osimg/奔腾向量表.png"> </center>

<h5 id="多级中断"><a href="#多级中断" class="headerlink" title="多级中断"></a>多级中断</h5><p>中断机制还实现了一个<strong>中断优先级</strong>（interrupt prioritylevel）系统。这些级别能使CPU<strong>延迟处理低优先级中断而不屏蔽所有中断</strong>，并且可以让<strong>高优先级中断抢占执行低优先级中断</strong>。</p>
<p>此外，系统与中断机制的交互有多种方式。</p>
<p>在<strong>启动时</strong>，操作系统<strong>探测硬件总线</strong>以便确定存在哪些设备，并且在<strong>中断向量中安装相应中断处理程序</strong>。在<strong>I&#x2F;O期间</strong>，各种设备控制器在<strong>准备好服务时触发中断</strong>。这些中断表示，输出已经完成，或输入数据可用，或<strong>故障已检测</strong>到。</p>
<p>中断机制也<strong>用于处理各种异常</strong>（exception），例如除以0, 非法内存访问以及在用户模式下执行特权指令。</p>
<p>触发中断的事件有一个共同特点：这些事件导致操作系统执行紧急的自包含的程序。简单说，就是要<strong>操作系统用系统内置程序帮自己处理事件</strong>。</p>
<p>对于可以保存少量处理器的状态并且调用内核的特权程序的高效硬件和软件机制来说，中断还有其他用途。</p>
<p>例如，许多操作系统<strong>采用中断机制来进行虚拟内存分页</strong>。页面错误是引发中断的异常。中断挂起当前进程，并且转到内核的页面错误处理程序。这个<strong>处理程序保存进程状态</strong>，将中断进程加到等待队列，执行页面缓存管理，调度I&#x2F;O操作以获取页面，调度进程恢复执行，然后从中断返回。</p>
<p>另一个例子是<strong>系统调用的实现</strong>。通常，程序使用库调用来执行系统调用。<strong>库程序检查应用程序给出的参数，构建数据结构以传递参数到内核</strong>，然后<strong>执行一个特殊指令</strong>（称为<strong>软中断</strong>（software interrupt）或者<strong>陷阱</strong>（trap））。这个指令<strong>有一参数，用于标识所需的内核服务</strong>。当进程执行陷阱指令时，<strong>中断硬件保存用户代码的状态</strong>，切换到内核模式，分派到实现请求服务的内核程序。陷阱所<strong>赋予的中断优先级低于设备所赋予的中断优先级</strong>；因为应用程序执行系统调用与在FIFO队列溢出并失去数据之前的处理设备控制器相比，后者更为紧迫。</p>
<p>中断也可用来<strong>管理内核的控制流</strong>。例如，考虑一个处理示例，以便<strong>完成磁盘读取</strong>。一个步骤是，复制内核空间的数据到用户缓冲，这个步骤耗时但不紧急，因此优先级低。另一个步骤是，启动下一个等待这个磁盘驱动器的I&#x2F;O。这个步骤具有更高优先级, 因为磁盘的高效需要尽快执行I&#x2F;O。</p>
<p>因此, <strong>两个中断处理程序</strong>实现内核代码，以便完成磁盘读取。高优先级处理程序记录I&#x2F;O状态，清除设备中断，启动下一个待处理的I&#x2F;O，并且<strong>引发低优先级中断</strong>(复制)以便完成任务。</p>
<p>这样通过优先级实现磁盘读取。</p>
<p>多线程系统特别适合优先级中断，并且<strong>确保中断处理的优先级高于内核后台处理和用户程序</strong>。</p>
<p>中断大量用于时间敏感的处理，所以高性能系统要求高效的中断处理.</p>
<h4 id="13-2-3-直接内存访问"><a href="#13-2-3-直接内存访问" class="headerlink" title="13-2-3 直接内存访问"></a>13-2-3 直接内存访问</h4><p>对于<strong>执行大量传输</strong>的设备，例如磁盘驱动器，如果通过昂贵的通用处理器来<strong>观察状态位并且按字节来发送数据到控制器寄存器</strong>（称为<strong>程序控制I&#x2F;O</strong>（Programmed I&#x2F;O, <strong>PIO</strong>）），则似乎浪费了。</p>
<p>为了<strong>避免因PIO而增加CPU负担</strong>(按字节传输大量数据太蠢了)，将一部分<strong>任务交给一个专用的处理器</strong>（称为<strong>直接内存访问</strong>（Direct-MemoryAccess, <strong>DMA</strong>）控制器）。</p>
<p>在启动DMA传输时，主机将<strong>DMA命令块写到内存</strong>。该块包含：</p>
<ul>
<li>传输来源地址的指针</li>
<li>传输目标地址的指针</li>
<li>传输的<strong>字节数</strong></li>
</ul>
<p>CPU将这个<strong>命令块的地址写到DMA控制器</strong>，然后<strong>继续其他工作</strong>。DMA控制器<strong>继续直接操作内存总线</strong>，将地址放到总线，在<strong>没有主CPU的帮助</strong>的情况下执行传输。这样就能把传输字节的工作从CPU转交给DMA控制器。</p>
<p><strong>设备控制器与DMA控制器</strong>同样<strong>需要握手来确认状态</strong>，这通过一对称为<strong>DMA请求</strong>（DMA-request）和<strong>DMA确认</strong>（DMA-acknowledge）的<strong>线路</strong>来进行。数据需要传输时，设备<strong>控制器发送信号到DMA请求线路</strong>。这个信号使得<strong>DMA控制器占用内存总线</strong>，发送所需地址到内存地址总线，并<strong>发送信号到DMA确认线路</strong>。当<strong>设备控制器收到DMA确认信号</strong>时，它就<strong>传输数据到内存</strong>，并且<strong>清除DMA请求信号</strong>。</p>
<p>当<strong>完成</strong>整个传输时，DMA控制器<strong>中断CPU</strong>。当DMA控制器占用内存总线时，CPU被<strong>暂时阻止访问内存</strong>(DMA请求)，但是<strong>仍然可以访问主缓存</strong>或<strong>辅助缓存</strong>内的数据项。这种<strong>周期窃取</strong>整体利大于弊。</p>
<p>还有的采用<strong>直接虚拟内存访问</strong>（Direct Virtual-Memory Access, <strong>DVMA</strong>），这<strong>需要虚拟到物理地址的转换</strong>。DVMA可以直接实现两个内存映射设备之间的传输，而<strong>无需CPU的干涉或采用内存</strong>(不占用内存总线！！！)。但是需要MMU来映射，可以通过I&#x2F;O子系统交换数据而不需要内存。</p>
<center> <img src="./osimg/DMA.png"> </center>

<p>对于<strong>保护模式内核</strong>，操作系统通常<strong>阻止进程对设备直接发送命令</strong>. 取而代之的是，操作系统<strong>导出一些函数</strong>，以便具有<strong>足够特权的进程</strong>可以<strong>利用这些函数来访问低层硬件的底层操作</strong>。若内核无内存保护，进程可以直接访问设备控制器而没有内核通信、上下文切换之类的开销，但代价是安全性的损失。</p>
<h4 id="13-2-4-i-o硬件小结"><a href="#13-2-4-i-o硬件小结" class="headerlink" title="13-2-4 i&#x2F;o硬件小结"></a>13-2-4 i&#x2F;o硬件小结</h4><p>系统I&#x2F;O的相关概念有：</p>
<ul>
<li>总线</li>
<li>控制器</li>
<li>I&#x2F;O端口及其寄存器</li>
<li>主机与设备控制器之间的握手关系，DMA控制器也会和设备控制器握手</li>
<li>轮询检测或中断的握手执行</li>
<li>大量传输任务交给DMA控制器</li>
</ul>
<h4 id="应用程序i-o接口"><a href="#应用程序i-o接口" class="headerlink" title="应用程序i&#x2F;o接口"></a>应用程序i&#x2F;o接口</h4><p>与其他复杂软件工程问题一样，这里的方法<strong>涉及抽象、封装与软件分层</strong>。具体来说，可以从各种各样I&#x2F;O设备中<strong>抽象一些通用类型</strong>。每种通用类型可以<strong>通过一组标准函数（即接口（interface））来访问</strong>。这些<strong>差异被封装到内核模块</strong>（称为<strong>设备驱动程序</strong>）；这些设备驱动程序，一方面可以<strong>定制以适应各种设备</strong>，另一方面也<strong>提供一组标准接口</strong>。图13-6说明了内核中的I&#x2F;O相关部分是如何按软件层来组织的。</p>
<center> <img src="./osimg/内核IO结构.png"> </center>

<p>其中，<strong>设备驱动程序层</strong>的作用是为内核I&#x2F;O子系统<strong>隐藏设备控制器之间的差异</strong>。I&#x2F;O子系统与硬件的<strong>分离</strong>简化了操作系统开发人员的工作。这也有利于硬件制造商。他们或者设计新的设备以与现有主机控制器接口（如SATA）兼容，或者编写设备驱动程序以将新的硬件连到流行的操作系统。这样就不用等操作系统提供标准驱动了。</p>
<p>对于设备硬件制造商，每种操作系统都<strong>有自己的设备驱动接口标准</strong>。每个给定设备可能带有多个设备驱动程序，例如Windows、Linux、AIX和Mac OS X的驱动程序。如图13-7所示，设备在许多方面都有很大差异。</p>
<center> <img src="./osimg/IO设备的差异和特点.png"> </center>

<p>具体解释一下：</p>
<ul>
<li><strong>字符流或块</strong>：字符流设备逐个字节来传输，而块设备以字节块为单位来传输。</li>
<li><strong>顺序访问或随机访问</strong>：顺序访问设备按设备确定的固定顺序来传输数据，而随机访问设备的用户可以指示设备寻找到数据存储的任意位置。</li>
<li><strong>同步或异步</strong>：同步设备按预计的响应时间来执行数据传输，并与系统的其他方面相协调。异步设备呈现不规则或不可预测的响应时间，并不与其他计算机事件相协调。</li>
<li><strong>共享或专用</strong>：共享设备可以被多个进程或线程并发使用，而专用设备则不能。</li>
<li><strong>操作速度</strong>：设备的速度范围从每秒数字节到每秒数G字节。</li>
<li><strong>读写、只读、只写</strong>：有的设备能执行输入也能执行输出，而其他的只支持单向数据传输。</li>
</ul>
<p>这些差异都对应用程序隐藏了，程序只要调用对应类提供的函数就好了，系统设计者要想的可就多了。</p>
<p>大多数操作系统也有一个<strong>逃逸</strong>（escape）或<strong>后门</strong>（backdoor），以便<strong>应用程序透明传递任何命令到设备控制器</strong>. 对于UNIX，这个系统调用是**ioctl()**（I&#x2F;O control）, 使应用程序访问设备驱动程序可以实现的任何功能.</p>
<p>系统调用ioctl()有三个参数。第一个是文件描述符，它通过引用驱动程序管理的硬件设备来连接应用程序与设备驱动程序。第二个是整数，用于选择设备驱动程序实现的一个命令。第三个是内存中的数据结构的一个指针，这使得应用程序和驱动程序传输任何必要的控制信息或数据。</p>
<h4 id="13-3-1-块与字符设备"><a href="#13-3-1-块与字符设备" class="headerlink" title="13-3-1 块与字符设备"></a>13-3-1 块与字符设备</h4><p><strong>块设备接口</strong>（block-device interface）为<strong>磁盘驱动器</strong>和<strong>其他基于块设备的访问</strong>。程序通常通过文件系统接口访问这样的设备，通过read(), write(), seek()一类的操作达成目的，而不必在意底层硬件差异。</p>
<p>操作系统和特殊程序(数据库), 可能<strong>偏爱将块设备作为简单的线性的块数组来访问</strong>，这种访问模式有时称为<strong>原始I&#x2F;O</strong>（raw I&#x2F;O）。</p>
<p>此时，若<strong>应用程序自带缓冲以及域和锁的实现</strong>，可能在<strong>使用文件系统</strong>时会冲突或者导致性能下降(应用和系统的双缓冲)。因此，原始设备访问将设备<strong>控制直接交给应用程序</strong>，无需通过操作系统。但是，没有操作系统服务能在这个设备上执行。为此，折中的<strong>允许一种文件操作模式，以便禁止缓冲和锁定</strong>。在UNIX中称为<strong>直接I&#x2F;O</strong>（direct I&#x2F;O）。</p>
<p>内存映射文件的访问可以在块设备驱动程序之上。内存映射接口提供通过内存的字节数组来访问磁盘存储，而不提供读和写操作(直接指针修改，不需要调用read和write)。映射文件到内存的系统调用返回包含文件副本的虚拟内存的一个地址。只有需要访问内存映像，才会执行实际数据传输。传输采用与按需分页虚拟内存访问相同的机制来处理，内存映射I&#x2F;O高效。同时也让访问变得和内存读写一样简单。</p>
<p><strong>字符流接口</strong>（character-stream interface）访问的一个设备例子是键盘。这个接口的基本系统调用能<strong>使应用程序get()或put()字符</strong>。这样能提供<strong>按行访问</strong>，并且具有<strong>缓冲和编辑功能</strong>，删除只需要在字符流中删去即可。</p>
<p>这种访问方式很方便用于输入设备，如键盘、鼠标、modem，这些设备自发提供输入数据，也就是说，应用程序无法预计这些输入。这种访问方式也适用于输出设备，如打印机、声卡，这些非常符合线性流字节的概念。</p>
<h4 id="13-3-2-网络设备"><a href="#13-3-2-网络设备" class="headerlink" title="13-3-2 网络设备"></a>13-3-2 网络设备</h4><p>网络I&#x2F;O比较特别，许多操作系统（包括UNIX和Windows）的这个<strong>接口为网络套接字</strong>（socket）接口。</p>
<p>想想墙上的电源插座：任何电器都可以插入。同样，套接字接口的系统调用能<strong>使应用程序创建一个套接字</strong>，连接本地套接字到远程地址（将本地应用程序与由远程应用程序创建的套接字相连）.</p>
<p>也能<strong>监听要与本地套接字相连的远程应用程序</strong>，通过连接发送和接收数据。</p>
<p>为了支持实现服务器，套接字接口也提供<strong>函数select（），以便管理一组套接字</strong>。调用select()可以得知，哪个套接字已有接收数据需要处理，哪个套接字已有空间可以接收数据以便发送。采用select（）可以消除轮询和忙等（否则，这是网络I&#x2F;O所需的）。这些函数封装网络的基本功能，从而大大加快分布式应用程序的开发，以便利用底层网络硬件和协议栈。</p>
<p>但select()只返回状态，之后还需要传输，因此会有性能下降。</p>
<h4 id="13-3-3-时钟与定时器"><a href="#13-3-3-时钟与定时器" class="headerlink" title="13-3-3 时钟与定时器"></a>13-3-3 时钟与定时器</h4><p>大多数计算机都有<strong>硬件时钟和定时器</strong>，以便提供三种基本功能：</p>
<ul>
<li>获取当前时间</li>
<li>获取经过时间</li>
<li>设置定时器，以便在T时触发操作X</li>
</ul>
<p>大量用于操作系统和时间敏感的应用程序。不过，实现这些函数的系统调用<strong>不属于操作系统标准</strong>。</p>
<p><strong>测量经过时间和触发操作的硬件</strong>称为<strong>可编程间隔定时器</strong>（programmable interval timer）。它可以设置成等待一定的时间，然后触发中断；它可以设成做一次或多次（以便产生<strong>周期中断</strong>）。</p>
<p>调度程序采用这种机制产生中断，以便<strong>抢占时间片用完的进程</strong>。磁盘I&#x2F;O子系统采用它，定期刷新脏的缓存缓冲到磁盘；网络子系统采用它，定时取消由于网络拥塞或故障而太慢的一些操作。</p>
<p>操作系统采用<strong>模拟虚拟时钟</strong>，支持比定时器硬件信道数量更多的定时器请求. (增多支持进程的数量) 为此，内核（或定时器设备驱动程序）<strong>维护一个列表</strong>，这是内核程序和用户<strong>请求所需的、并且按时间排序的中断列表</strong>。顺序执行并触发中断。</p>
<p>许多计算机的硬件时钟生成的中断率为每秒18～60次。这种频率相对<strong>粗糙</strong>，因为现代计算机每秒可以执行数亿条指令。</p>
<p>对于大多数计算机, <strong>硬件时钟是由高频计数器来构造的</strong>。高精度的时钟从设备寄存器读取计数器的值，这种时钟<strong>不产生中断</strong>，但是它能<strong>提供时间间隔的准确测量</strong>。</p>
<h4 id="13-3-4-非阻塞与异步i-o"><a href="#13-3-4-非阻塞与异步i-o" class="headerlink" title="13-3-4 非阻塞与异步i&#x2F;o"></a>13-3-4 非阻塞与异步i&#x2F;o</h4><p>对于<strong>阻塞的I&#x2F;O</strong>, 应用程序的执行被挂起。应用程序会从操作系统的运行队列移到等待队列。当系统调用完成后，应用程序被移回到运行队列，符合恢复执行。当它恢复执行时，它会收到系统调用的返回值。</p>
<p>不过，I&#x2F;O设备执行的<strong>物理动作常常是异步的</strong>，执行时间也是可变的或不可预计的. 然而，大多数操作系统为应用程序接口采用阻塞系统调用，因为阻塞应用代码比非阻塞应用代码更加容易理解。</p>
<p><strong>非阻塞I&#x2F;O不同与异步I&#x2F;O</strong>，前者可以<strong>等待很短的时间</strong>(一般可设置，设置为inf则退化为阻塞I&#x2F;O)并<strong>返回立即可用的数据</strong>，而<strong>异步I&#x2F;O立即返回</strong>并在将<strong>来完成全部传输并通知应用程序</strong>。</p>
<p>但差异也不大，因此非阻塞I&#x2F;O有时可以用异步I&#x2F;O代替。</p>
<p>有些用户级进程还是<strong>需要非阻塞I&#x2F;O的</strong>，一个例子是用户接口，用来接收键盘和鼠标输人，同时处理数据并显示到屏幕。另一个例子是视频应用程序，用来从磁盘文件上读取帧，同时解压并显示输出到显示器。</p>
<p>以下为两种I&#x2F;O的区别示意图</p>
<center> <img src="./osimg/13-8.png"> </center>

<h4 id="13-3-5-向量i-o"><a href="#13-3-5-向量i-o" class="headerlink" title="13-3-5 向量i&#x2F;o"></a>13-3-5 向量i&#x2F;o</h4><p><strong>向量I&#x2F;O</strong>（Vectored I&#x2F;O）允许系统调用，来执行<strong>涉及多个位置的多个I&#x2F;O操作</strong>. 这种将多个位置的调用统一起来的<strong>分散收集</strong>（scatter-gather）方法由于各种原因还是有用的。</p>
<p>多个单独缓冲区可以<strong>通过一个系统调用来传输</strong>它们的内容, <strong>避免上下文切换和系统调用消耗</strong>。没有向量I&#x2F;O，数据可能首先需要按正确顺序传输到较大的缓冲区，然后发送，因此效率低下. 此外，有些版本的分散收集<strong>提供原子性</strong>，确保所有I&#x2F;O都能无间断地完成.</p>
<h3 id="13-4-i-o子系统"><a href="#13-4-i-o子系统" class="headerlink" title="13-4 i&#x2F;o子系统"></a>13-4 i&#x2F;o子系统</h3><p>内核提供与I&#x2F;O相关的许多服务. 许多服务，如调度、缓冲、缓存、假脱机、设备预留及错误处理，由<strong>内核I&#x2F;O子系统提供</strong>；I&#x2F;O子系统<strong>也负责保护自己</strong>免受错误进程和恶意用户的侵扰。</p>
<h4 id="13-4-1-i-o调度"><a href="#13-4-1-i-o调度" class="headerlink" title="13-4-1 i&#x2F;o调度"></a>13-4-1 i&#x2F;o调度</h4><p>可以通过<strong>改变I&#x2F;O执行的顺序</strong>来获得<strong>更好的I&#x2F;O性能</strong>。就像<a href="#12-4-%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6">磁盘调度</a>一样。调度可以<strong>改善系统整体性能</strong>，可以在<strong>进程间公平共享设备访问</strong>，可以<strong>减少I&#x2F;O完成所需的平均等待时间</strong>。</p>
<p>每个设备维护一个请求等待队列(<strong>设备队列</strong>)，来实现队列。当应用程序<strong>发出阻塞I&#x2F;O的系统调用</strong>时，该请求被添加到相应设备的队列。I&#x2F;O调度程序重新安排队列顺序，以便提高系统的总体效率和应用程序的平均响应时间。操作系统也可以试图公平，这样没有应用程序会得到特别差的服务；或者对那些延迟敏感的请求，可以给予比较优先的服务。</p>
<p>内核<strong>支持异步I&#x2F;O时</strong>，它必须能够同时<strong>跟踪许多I&#x2F;O请求</strong>。为此，操作系统可能会<strong>将等待队列附加到设备状态表</strong>（device-status table）。内核管理此表，其中每个条目对应每个I&#x2F;O设备。示意图如下</p>
<center> <img src="./osimg/设备状态表.png"> </center>

<p>调度I&#x2F;O操作是I&#x2F;O子系统提高计算机效率的一种方法。另一种方法是，通过缓冲、缓存和假脱机，使用内存或磁盘的存储空间。</p>
<h4 id="13-4-2-缓冲"><a href="#13-4-2-缓冲" class="headerlink" title="13-4-2 缓冲"></a>13-4-2 缓冲</h4><p><strong>缓冲区</strong>（buffer）是一块<strong>内存区域</strong>，用于<strong>保存</strong>在两个设备之间或在设备和应用程序之间<strong>传输的数据</strong>。</p>
<p>采用缓冲有三个理由：</p>
<ol>
<li>处理数据流的生产者与消费者之间的<strong>速度不匹配</strong><ul>
<li>例如，假如通过调制解调器正在接收一个文件，并且保存到硬盘。调制解调器大约比硬盘慢一千倍。这样，创建一个缓冲区在内存中，以便累积从调制解调器处接收的字节。当整个数据缓冲区填满时，就可以通过一次操作将缓冲区写到磁盘。</br>由于<strong>写入磁盘不是即时的</strong>而且<strong>调制解调器仍然需要一个空间继续存储额外的输入数据</strong>，所以采用<strong>两个缓冲区</strong>。在调制解调器<strong>填满第一个缓冲区后</strong>，就<strong>请求写入磁盘</strong>。接着开始<strong>填写第二个缓冲区</strong>，而这时第一个缓冲区正被写入磁盘。等到<strong>写满第二个缓冲区</strong>时，第一个缓冲区的磁盘<strong>写入也应完成</strong>；因此调制解调器可以<strong>切换到第一个缓冲区</strong>，而磁盘可以<strong>写第二个缓冲区</strong></br> 双缓冲（double buffering）解耦数据的生产者与消费者，因此<strong>放松两者之间的时序要求</strong>。</br> <center> <img src="./osimg/传输速率差异.png"> </center></li>
</ul>
</li>
<li>协调<strong>传输大小不一数据</strong>的设备. <ul>
<li>缓冲区大量<strong>用于消息的分段和重组</strong>。在发送端，一个大的消息<strong>分成若干小的网络分组</strong>。这些网络分组通过网络传输，而接收端将它们放在<strong>重组缓冲区内，以便生成完整的源数据映像</strong>。</li>
</ul>
</li>
<li>支持应用程序I&#x2F;O的<strong>复制语义</strong>.<ul>
<li>为了<strong>保证写入的内容一定是调用时写入的内容</strong>，需要保证写入内容不被更改。操作系统保证复制语义的种简单方式是，系统调用write()在返回到应用程序之前, <strong>复制应用程序缓冲区到内核缓冲区</strong>。磁盘<strong>写入通过内核缓冲区</strong>来执行，以便应用程序缓冲区的后续更改没有影响</li>
</ul>
</li>
</ol>
<h4 id="13-4-3-缓存"><a href="#13-4-3-缓存" class="headerlink" title="13-4-3 缓存"></a>13-4-3 缓存</h4><p><strong>缓存</strong>（cache）是<strong>保存数据副本的高速内存区域</strong>。访问缓存副本比访问原版更加有效。</p>
<p><strong>缓冲和缓存的区别</strong>是，缓冲可以保存数据项的<strong>唯一的现有副本</strong>，而根据定义缓存<strong>只是提供了</strong>一个位于其他地方的数据项的<strong>更快存储副本</strong>。</p>
<p>虽然有区别，但是有时一个内存区域可以用于两个目的。例如，为了保留复制语义和有效调度<strong>磁盘I&#x2F;O</strong>，操作系统采<strong>用内存中的缓冲区来保存磁盘数据</strong>。这些<strong>缓冲区也用作缓存</strong>，以便提高文件的I&#x2F;O效率；这些文件可被多个程序共享，或者快速地写入和重读。当内核收到文件I&#x2F;O请求时，内核首先访问缓冲区缓存。<strong>磁盘写入</strong>在数秒内<strong>会累积到缓冲缓存</strong>，以汇集大量传输来允许高效写入调度。</p>
<h4 id="13-4-4-假脱机与设备保留"><a href="#13-4-4-假脱机与设备保留" class="headerlink" title="13-4-4 假脱机与设备保留"></a>13-4-4 假脱机与设备保留</h4><p><strong>假脱机</strong>（spool）是<strong>保存设备输出的缓冲区</strong>，这些设备，如打印机, <strong>不能接收交叉的数据流</strong>。虽然打印机只能一次打印一个任务，但是多个应用程序可能希望并发打印输出，而不能让它们的输出混合在一起.</p>
<p>操作系统通过<strong>拦截所有打印输出</strong>，来解决这一问题。应用<strong>程序的输出先是假脱机到一个单独的磁盘文件</strong>。当应用程序<strong>完成打印</strong>时，假脱机系统<strong>排序相应的假脱机文件，以便输出到打印机</strong>。对于有些操作系统，假脱机由<strong>系统守护进程</strong>来管理；对于其他，它由<strong>内核线程</strong>来处理.</p>
<p>因此，假脱机<strong>是一种协调并发输出的办法</strong>。此外还可以要求互斥的设备访问，但这要避免死锁。</p>
<h4 id="13-4-5-错误处理"><a href="#13-4-5-错误处理" class="headerlink" title="13-4-5 错误处理"></a>13-4-5 错误处理</h4><p>I&#x2F;O设备多样，I&#x2F;O错误也多样。故障可能是由于<strong>暂时原因，如网络超载</strong>；或<strong>于“永久”原因，如磁盘控制器变得有缺陷</strong>。暂时的故障可以重试，永久故障则不太可能恢复。</p>
<p>作为<strong>一般规则</strong>，I&#x2F;O系统调用通常<strong>返回一位的调用状态信息</strong>，以表示成功或失败。对于UNIX操作系统，名为errno的一个额外整型变量用于返回错误代码（约有100个），以便指出失败的大概性质（例如，参数超过范围、坏指针、文件未打开等）。</p>
<p>有的硬件可以提供很<strong>详细的错误信息</strong>，虽然目前的<strong>许多操作系统并不将这些信息传递给应用程序</strong>。例如，SCSI协议报告SCSI设备故障的详细级别分为三个: <strong>感应键</strong>（sense key），用于标识故障的一般性质，如硬件错误或非法请求; <strong>额外感应代码</strong>（additional sense code），用于表示故障类型，如错误命令参数或自检失败; <strong>额外感应代码修饰词</strong>（additional sense-code qualifier），用于给出更详细信息，如哪个命令参数出错或哪个硬件子系统自检失. 许多<strong>SCSI设备维护一个出错日志信息的内部页面以便主机查询</strong>，不过这一功能实际<strong>很少使用</strong>。</p>
<h4 id="i-o保护"><a href="#i-o保护" class="headerlink" title="i&#x2F;o保护"></a>i&#x2F;o保护</h4><p>用户的非法I&#x2F;O指令可能危害系统和数据的安全。</p>
<p>为了<strong>防止用户执行非法I&#x2F;O</strong>，我们<strong>定义所有I&#x2F;O指令为特权指令</strong>。因此，用户进程<strong>只能通过系统调用来操作I&#x2F;O</strong>。操作系统在监控模式下检查请求是否合法。</p>
<center> <img src="./osimg/系统调用监控IO.png"> </center>

<p>此外, <strong>内存保护系统保护任何内存映射和I&#x2F;O端口内存位置</strong>，以便<strong>阻止用户访问</strong>. </p>
<p>注意，内核<strong>不能简单地拒绝所有用户访问</strong>。例如，大多数图形游戏和视频编辑与播放软件需要<strong>直接访问内存映射图形控制器的内存</strong>，以便加速图形性能。这种情况下，内核可能提供一种锁定机制，允许图形内存的一部分（代表一个屏幕窗口）一次分配给一个进程.</p>
<h4 id="13-4-7-内核数据结构"><a href="#13-4-7-内核数据结构" class="headerlink" title="13-4-7 内核数据结构"></a>13-4-7 内核数据结构</h4><p><strong>内核</strong>需要<strong>保存I&#x2F;O组件使用的状态信息</strong>。它通过各种<strong>内核数据结构（如11.1节的打开文件表结构）来完成</strong>。</p>
<p>UNIX通过面向对象技术采用统一结构来封装了各种I&#x2F;O组建的需求。打开文件记录，如图13-12所示，包括一个分派表，该表含有对应于文件类型的适当程序的指针。</p>
<center> <img src="./osimg/UNIX_IO内核结构.png"> </center>

<p>有些操作系统更为广泛地使用了面向对象方法。例如, <strong>Windows采用消息传递来实现I&#x2F;O</strong>。I&#x2F;O请求转成消息，通过内核发到I&#x2F;O管理器，再交到设备驱动程序以便更改消息内容。</p>
<p>对于输出，消息包括要写的数据。对于输人，消息包括接收数据的缓冲。消息传递方法，与采用共享数据结构的程序调用技术相比，可能<strong>增加开销</strong>，但是它<strong>简化了I&#x2F;O系统的结构和设计，并增加了灵活性</strong>。</p>
<h4 id="13-4-8-内核i-o子系统小结"><a href="#13-4-8-内核i-o子系统小结" class="headerlink" title="13-4-8 内核i&#x2F;o子系统小结"></a>13-4-8 内核i&#x2F;o子系统小结</h4><p>总之，I&#x2F;O子系统<strong>协调大量的服务组合</strong>，以便用于应用程序和其他内核部件。I&#x2F;O子系统监督这些程序：</p>
<ul>
<li>文件和设备的命名空间的管理</li>
<li>文件和设备的访问控制</li>
<li>操作控制（例如，调制解调器不能使用seek()）</li>
<li>文件系统的空间分配</li>
<li>设备分配</li>
<li>缓冲、缓存和假脱机</li>
<li>I&#x2F;O调度</li>
<li>设备状态监控、错误处理和故障恢复</li>
<li>设备驱动程序的配置和初始化</li>
</ul>
<p><strong>I&#x2F;O子系统的上层通过设备驱动程序提供的统一接口来访问设备</strong>。</p>
<p>意思是你用的read(), write()之类的操作其实是驱动程序定义的。</p>
<h3 id="13-5-i-o请求转成硬件操作"><a href="#13-5-i-o请求转成硬件操作" class="headerlink" title="13-5 i&#x2F;o请求转成硬件操作"></a>13-5 i&#x2F;o请求转成硬件操作</h3><p>P428</p>
<p>考虑如何<strong>建立从文件名称到磁盘控制器的连接</strong>（硬件端口地址或内存映射控制器寄存器）</p>
<p>一种方法由MS-DOS（相对简单的操作系统）采用。MS-DOS<strong>文件名称的第一部分，在冒号之前，表示特定硬件设备的字符串</strong>。例如，C:是主硬盘的每个文件名称的第一部分。C:表示主硬盘的事实是内置于操作系统中的; <strong>C:通过设备表映射到特定的端口地址</strong>。由于冒号分隔符，设备名称空间不同于文件系统名称空间。</p>
<p>相反，如果<strong>设备名称空间集成到常规文件系统名称空间</strong>，如UNIX，则<strong>自动提供常规文件系统服务</strong>。如果文件系统提供对所有文件名称进行所有权和访问控制，则设备就有所有权和访问控制。由于文件保存在设备上，这种接口提供对I&#x2F;O系统的两级访问。名称可以用来访问设备本身，或者用来访问存储在设备上的文件。(<strong>文件和设备融合，属性相交</strong>)</p>
<p>UNIX通过常规文件系统名称空间来表示设备名称。UNIX路径名称<strong>没有明确区分设备部分</strong>。事实上，路径名称中没有设备名称的部分。</p>
<p>UNIX有一个<strong>安装表</strong>（mount table），以便<strong>将路径名称的前缀与特定设备名称关联</strong>。为了解析路径名，UNIX检查安装表内的名称，以<strong>查找最长的匹配前缀</strong>；安装表内的<strong>相应条目给出了设备名称</strong>。</p>
<p>这个<strong>设备名称在文件系统名称空间内也有名称</strong>。当UNIX在<strong>文件系统目录结构</strong>中<strong>查找此名称</strong>时，它查找到的不是inode号，而是**设备号(主，次)**（（major，minor&gt;）。</p>
<p><strong>主设备号</strong>表示处理这种设备I&#x2F;O的<strong>设备驱动程序</strong>. <strong>次设备号</strong>传到设备驱动程序，以<strong>索引设备表</strong>。设备表的<strong>相应条目给出设备控制器的端口地址或内存映射地址</strong>。</p>
<p>这种请求是通用的，因此加载新的驱动程序无需重新编译内核。系统在启动时也会自动检测硬件并加载相关驱动。</p>
<p>接下来描述阻塞读请求的典型生命周期，如图13-13所示。该图<strong>说明了I&#x2F;O操作需要很多步骤，这也消耗大量的CPU时间</strong>。</p>
<center> <img src="./osimg/阻塞IO的生命周期.png"> </center>

<center> <img src="./osimg/13-13.png"> </center>

<h3 id="13-6-流"><a href="#13-6-流" class="headerlink" title="13-6 流"></a>13-6 流</h3><p>UNIX System V有一个有趣的机制，称为<strong>流</strong>（stream），以便能<strong>使应用程序自动组合驱动程序代码流水线</strong>。流是在<strong>设备驱动程序和用户级进程之间</strong>的<strong>全双工连接</strong>。</p>
<p>包括与用户进程相连的<strong>流头</strong>（stream head）、控制设备的<strong>驱动程序端</strong>（driver end）、位于两者之间的<strong>若干个流模块</strong>（stream module）。每个这些组件包含一对队列：读队列和写队列。图13-14显示了一个流结构。</p>
<center> <img src="./osimg/流.png"> </center>

<p>每个流模块包含一对队列：读队列和写队列</p>
<p><strong>模块提供流处理的功能</strong>；它们通过使用系统调用<strong>ioctl()推送到流</strong>。例如，进程通过流可以打开串口设备，并且<strong>可以增加一个模块来处理输入编辑</strong>。</p>
<p>模块间队列可能支持<strong>流控制</strong>（flow control），以防止部分模块队列满而无法处理。流控制根据情况<strong>在模块内缓存一部分消息</strong>而且没有缓存时不接受消息，以<strong>保证全部模块的队列稳定</strong>。</p>
<p>用户进程采用系统调用write（）或putmsg（），来写入数据到设备。系统调用<strong>write（）写入原始数据</strong>到流，而**putmsg（）允许用户进程指定消息(有结构)**。不管用户进程采用何种系统调用，流头复制数据到消息，并传到下一模块的队列。这种消息复制一直持续，直到消息到达驱动程序结尾，最终到达设备。类似地，用户进程采用系统调用read（）和getmsg（），来从流头读取数据。如果采用read（），则流头从相邻队列得到消息，并将普通数据（非结构化字节流）返给进程。如果采用getmsg（），则将消息返给进程。</p>
<p><strong>流I&#x2F;O是异步的</strong>（或非阻塞的），除非用户进程与流头直接通信。当对流写入时，假设下一个队列<strong>使用流控制，用户进程会阻塞</strong>，直到有空间可复制消息。同样，当<strong>从流读取时，用户进程会阻塞</strong>，直到数据可用。（灵活阻塞）</p>
<p>驱动程序末端，与流头和模块一样，有读和写队列。然而, <strong>驱动程序末端必须响应中断</strong>，例如当帧已准备好以便网络读取时，就会触发中断。与<strong>流头不一样</strong>. 驱动程序末端必须处理所有传入数据。驱动程序<strong>也必须支持流控制</strong>。然而，如果设备<strong>缓冲已满，那么设备通常取消传入消息</strong>。</p>
<p>驱动程序端必须相应设备需求，因此无法阻塞。</p>
<p>使用流的好处是，它<strong>提供了一个模块化和递增的框架方式</strong>，来编写设备驱动程序和网络协议。模块可以用于不同的流和不同的设备。此外，流<strong>不是将字符设备作为非结构化字节流来处理</strong>，允许支持模块之间的消息边界和控制信息。</p>
<h3 id="13-7-性能"><a href="#13-7-性能" class="headerlink" title="13-7 性能"></a>13-7 性能</h3><p>虽然现代计算机每秒能够处理数以千计的中断，但是<strong>中断处理仍然是相对昂贵的任务</strong>。每个<strong>中断导致系统执行状态改变，执行中断处理，再恢复状态</strong>。如果忙等所需的计算机周期并不多，则程序控制I&#x2F;O比中断驱动I&#x2F;O更为有效。I&#x2F;O完成通常会解锁进程，导致完整的上下文切换开销。(<strong>程序控制I&#x2F;O可能优于中断驱动I&#x2F;O</strong>)</p>
<p>网络流量也能导致高的上下文切换速率。如下图</p>
<p><strong>上下文切换只在操作系统调度或改变了执行进程时才出现。系统调用不一定会导致上下文切换，但如果遇到阻塞则可能被调度导致进程切换。也说明内核态到用户态不一定有上下文切换</strong></p>
<center> <img src="./osimg/网络带来的上下文切换.png"> </center>

<p>其他系统采用<strong>单独的前端处理器</strong>（front-end processor），以便在终端I&#x2F;O<strong>降低主CPU的中断负担</strong>。例如, <strong>终端集中器</strong>（terminal concentrator）可以将数百个<strong>远程终端多路复用到大型计算机的一个端口</strong>. <strong>I&#x2F;O通道</strong>（I&#x2F;O channel）是大型机和其他高端系统的<strong>专用CPU</strong>。I&#x2F;O通道任务<strong>为主CPU承担I&#x2F;O工作</strong>。这个想法是，通道保持数据顺利传输，而主CPU仍可自由处理数据。就像DMA控制器一样。</p>
<p>由此看出，为了<strong>改善I&#x2F;O效率</strong>，可以采用多种方法：</p>
<ul>
<li>减少上下文切换的次数</li>
<li>减少设备和应用程序之间传递数据时的内存数据的<strong>复制次数</strong></li>
<li>过大传输、智能控制器、轮询（如果忙等可以最小化）, <strong>减少中断频率</strong></li>
<li>通过DMA智能控制器和通道来<strong>为主CPU承担简单数据复制</strong>，增加并发</li>
<li>将<strong>处理原语移到硬件</strong>，允许控制器操作与CPU和总线操作并发</li>
<li>平衡CPU、内存子系统、总线和I&#x2F;O的性能, 任意短板都引起其他的空闲，导致低利用率</li>
</ul>
<p>硬件层面的改变主要是想让CPU与I&#x2F;O处理分离，减少宝贵的CPU占有。</p>
<p><strong>I&#x2F;O功能到底应在哪里实现呢</strong>？是设备硬件，还是设备驱动程序，或是应用软件？有时，我们观察如图13-16所示的进展。</p>
<center> <img src="./osimg/设备功能_IO实现位置.png"> </center>
 
<h2 id="14-系统保护"><a href="#14-系统保护" class="headerlink" title="14 系统保护"></a>14 系统保护</h2><h3 id="14-1-保护目标"><a href="#14-1-保护目标" class="headerlink" title="14-1 保护目标"></a>14-1 保护目标</h3><p>我们需要<strong>提供保护的原因</strong>有很多。<br>最显而易见的是，需要<strong>防止用户有意地、恶意地违反访问限制</strong>。然而，更为重要的是需要<strong>确保系统的活动程序组件按照规定策略来使用系统资源</strong>。这种要求是可靠系统所必需的。</p>
<p>通过<strong>检测组件子系统之间接口的潜在错误</strong>，保护可以提高可靠性，也能避免故障子系统影响其他健康子系统。面向保护的系统提供手段，以便<strong>区分授权和未经授权的使用</strong>。</p>
<p>保护也涉及<strong>策略与机制的分离</strong>。策略可能随着地点或时间的不同而不同。在最坏情况下，每次策略的改变都可能要求底层机制的改变。使用通用机制能够避免这种情况。为此，机制提供手段，策略根据具体情况下的选择手段达成目标。</p>
<h3 id="14-2-保护原则"><a href="#14-2-保护原则" class="headerlink" title="14-2 保护原则"></a>14-2 保护原则</h3><p>通常，整个项目如操作系统设计，可以采用一个指导原则。经过时间检验的重要的保护指导原则是<strong>最低特权原则</strong>（principle of least privilege），它规定了程序、用户甚至系统<strong>只能拥有足够特权以便执行任务</strong>。</p>
<p>也就是只给足够完成任务的权限，多的不允许。</p>
<p>考虑一个带有密钥的保安员的比喻。如果这个密钥允许保安员进人他所守卫的公共区域，则滥用钥匙造成的危害最小。然而，如果密钥允许访问所有区域，则密钥的丢失、偷窃、误用、复制或其他等会带来更大危害。</p>
<p>遵循最低特权原则的操作系统实现它的特征、程序、系统调用和数据结构，以便<strong>组件的故障或妥协做到最小伤害并且允许最小伤害</strong>。即可以有故障和错误，但不能带来致命影响。</p>
<p>这样的操作系统也<strong>提供系统调用和服务</strong>，以便允许<strong>采用细粒度的访问控制</strong>来编写应用程序。在需要时给予权限。这些特权函数的审计也有利于跟踪行为来保证安全。</p>
<p>采用最低特权原则<strong>管理用户</strong>包括：为每个用户，仅按所需权限来创建单独账户。例如，需要在系统上安装磁带和备份文件的操作员，仅仅访问那些完成这个任务所需的命令和文件。有些系统通过<strong>基于角色的访问控制</strong>（Role-Based Access Control, <strong>RBAC</strong>），以便提供这种功能。</p>
<p>采用最低特权原则的计算机可以<strong>限于运行特定服务</strong>、通过<strong>特定服务访问特定远程主机</strong>以及<strong>在特定时间里做这些事</strong>。通常，通过启用或禁用每个服务和通过<strong>访问控制列表</strong>实现。</p>
<h3 id="14-3-保护域"><a href="#14-3-保护域" class="headerlink" title="14-3 保护域"></a>14-3 保护域</h3><p>计算机系统是<strong>进程和对象的一组集合</strong>。对象（object）分为<strong>硬件对象</strong>（hardware object）（如CPU、内存段、打印机、磁盘和磁带驱动器）和<strong>软件对象</strong>（software object）（如文件、程序和信号量）。每个<strong>对象都有一个唯一名称</strong>，以便区别它与系统内的所有其他对象；而且每个<strong>只能通过明确定义的、有意义的操作来访问</strong>。对象本质上属于抽象数据类型。可以<strong>执行的操作可能取决于对象</strong>。例如，CPU只能执行。内存段可以读和写，而CD-ROM或DVD-ROM只可以读。</p>
<p><strong>进程只应允许访问获得了授权的资源</strong>。此外，无论何时，进程只能<strong>访问为完成任务而获得的那些资源</strong>。</p>
<p>第二个要求，通常称为<strong>需要知道原则</strong>（need-to-know principle），可以<strong>有效限制出错进程造成的系统伤害</strong>。例如，当进程p调用过程A()时，该过程只应允许访问它自已的变量和传递给它的形式参数；它应当不能访问进程p的所有变量。</p>
<p>也就是只能访问提供给自己的对象以及相关的需要的资源(<strong>使用的和被使用的都知道现在的处境</strong>)。例如，编译器应该不能随意访问所有文件，而只应访问明确定义的、与编译有关的文件子集（如源文件、列表文件等）。相反，编译器可能有私有文件以用于统计或优化的目的，进程p应当不能访问这些文件。</p>
<h4 id="14-3-1-域结构"><a href="#14-3-1-域结构" class="headerlink" title="14-3-1 域结构"></a>14-3-1 域结构</h4><p>为了实施刚才描述的方案, <strong>进程在保护域（protection domain）内执行</strong>，该保护域<strong>指定了进程可以访问的资源</strong>。</p>
<p>每个域定义了: <strong>一组对象</strong>和<strong>可以对每个对象调用的操作类型</strong>。对对象执行操作的能力为<strong>访问权限</strong>（access right）。</p>
<p>每个<strong>域为访问权限的一组集合</strong>，每个权限为一个有序对&lt; object-name，rights-set &gt;。例如，如果域D有访问权限&lt; 文件F，{读，写} &gt;则域D内的执行进程可以读和写文件F。然而，它不能对文件F执行任何其他操作。</p>
<center> <img src="./osimg/保护域图例.png" > </center>

<p>如果<strong>进程可用的资源集合</strong>在进程的<strong>生命周期中是固定的</strong>，则进程和域的<strong>关联可以是静态的</strong>（static），否则就是<strong>动态的</strong>（dynamic）。</p>
<p>如果<strong>进程和域之间的关联是固定的(静态的)<strong>，而且我们想要</strong>坚持需要知道原则</strong>，则<strong>必须</strong>有一个可用机制来<strong>修改域的内容</strong>。</p>
<p>这个<strong>原因源自这样的事实</strong>：进程的执行可以分为两个阶段，例如一个阶段需要读访问，而另一个阶段需要写访问。如果域是静态的，则必须定义域来包括读和写的访问。然而，这种安排为两个阶段提供了过多的权限，因为只需写权限的阶段还拥有读权限. </p>
<p>如果<strong>关联是动态的</strong>，则可以采用一种机制来<strong>允许域切换</strong>（domain switching），以便能够让进程从一个域切换到另一个域. 同时也可以支持域修改。</p>
<p>域的定义和划分可以有多种：</p>
<ul>
<li><strong>每个用户可以是个域</strong>: 这种情况下，可以<strong>访问的对象集合取决于用户身份</strong>. 用户改变时发生域切换。</li>
<li><strong>每个进程可以是一个域</strong>。在这种情况下，可以<strong>访问的对象集合取决于进程身份</strong>。当一个进程发送消息到另一个进程，然后等待响应时，发生域切换。</li>
<li><strong>每个过程可以是一个域</strong>。在这种情况下，可以访<strong>问的对象集合对应于过程内定义的局部变量</strong>。当进行过程调用时，发生域切换。</li>
</ul>
<p>操作系统常见的监控-用户模式就是两个域，进程位于用户模式不能执行特权指令，进行系统调用后切换到监控模式，在系统的监控下执行特权指令。</p>
<p>当然两个域还不够，因为用户间也需要保护。</p>
<h4 id="14-3-2-unix例子"><a href="#14-3-2-unix例子" class="headerlink" title="14-3-2 unix例子"></a>14-3-2 unix例子</h4><p>对于UNIX操作系统, <strong>域与用户关联。切换域对应于暂时更改用户身份</strong>。这种更改<strong>通过文件系统来实现</strong>。每个<strong>文件都关联着所有者身份和域位</strong>（称为<strong>setuid位</strong>（setuid bit））。当<strong>setuid位打开</strong>，并且用户执行文件时，<strong>userID设置为文件所有者的身份</strong>(userID为当前ID)。然而，当该位关闭时，不会更改userID。</p>
<p>例如，当用户A（即userID为A的用户）开始执行属于B的一个文件时，如果此时B的关联域位是关闭的，则该进程的userID会被设置成A；如果它的setuid位是打开的，则该进程的userID会被设置成文件的所有者：B。这些改动在退出时恢复。</p>
<p>这种方法的<strong>一个问题是</strong>，如果用户试图采用userID root和设置用户身份打开来创建文件，则该用户可以成为root，并执行系统上的所有一切。</p>
<p>其他操作系统的<strong>替代方法</strong>是，将<strong>特权程序放到特殊目录</strong>。当<strong>运行这个目录的任意个程序时</strong>，操作系统设计成<strong>更改它的ID为root或目录所有者的用户身份</strong>。这样就不会受到恶意创建所有者为root和setbit打开的文件的威胁。但是这降低了灵活性，userID基本和目录关联了。</p>
<p>系统<strong>只要简单地不允许更改userID，就会变得更具约束力</strong>，也更加安全。在这种情况下，必须<strong>采用特殊技术以便允许用户访问特权功能</strong>。例如，<strong>守护进程</strong>（daemon process）可以在<strong>引导时启动</strong>，并按特殊userID来运行。用户运行一个单独的程序，当需要采用这些功能时就<strong>发送请求到守护进程</strong>。</p>
<h4 id="14-3-3-multics例子"><a href="#14-3-3-multics例子" class="headerlink" title="14-3-3 multics例子"></a>14-3-3 multics例子</h4><p>对于MULTICS系统，保护<strong>域组织成分层的环形结构</strong>。每个<strong>环对应一个单独的域</strong>（图14-2）。</p>
<center> <img src="./osimg/MULTICS系统.png" > </center>

<p>这些环用从0~7的数字来编号。设Di和Dj为任意的两个域环。如果<strong>j &lt; i，则Di是Dj的一个子集</strong>。也就是说，执行在Dj中的进程比执行在Di中的进程，拥有更多特权。执行在<strong>D0中的进程拥有最多特权</strong>.</p>
<p>MULTICS具有<strong>分段地址空间</strong>；每个段是一个文件，而<strong>每个段关联着一个环</strong>。段描述包含个条目，以标识环编号。此外，它(段描述)包括三个访问位，以控制读、写和执行。</p>
<p><strong>每个进程关联一个计数器current-ring-number</strong>（当前环编号），用于标识进程正在执行的环。当进程<strong>执行在环i中时，它不可以访问与环j关联的段</strong>（j &lt; i）。可以访问与环k关联的段（k ≥ i）。然而, <strong>访问类型由与段关联的访问位来限制</strong>(具体的读写和执行权力得看段描述的访问控制位)。</p>
<p>切换环的要求和流程如下</p>
<center> <img src="./osimg/MULTICS域切换.png" > </center>

<p>环结构的<strong>主要缺点</strong>是，他<strong>不允许执行需要知道原则</strong>。特别地，如果一个对象必须在域Dj中访问而在域Di中不可以访问，则必须有j &lt; i。但是，这个要求意味着，Di中可访问的每个段也是在Dj中可以访问的。</p>
<p>问题来自于环之间都是子集的关系，有时我们不希望在有更高权限的还保有一些低权限时能执行的操作。</p>
<h3 id="14-4-保护矩阵"><a href="#14-4-保护矩阵" class="headerlink" title="14-4 保护矩阵"></a>14-4 保护矩阵</h3><p>我们的通用保护模型可以抽象为一个矩阵，称为<strong>访问矩阵</strong>（access matrix）。访问<strong>矩阵的行表示域，列表示对象</strong>。每个矩阵<strong>条目包括访问权限的一个集合</strong>。因为列明确定义对象，我们可以从访问权限中省略对象名称. <strong>访问条目access（i，j）定义了执行在域Di中的进程可以针对对象Oj调用的操作集合</strong>。</p>
<center> <img src="./osimg/访问矩阵.png" > </center>

<p><strong>访问矩阵方案</strong>为我们提供一种<strong>机制</strong>，以指定各种策略. 更具体地说，我们必须确保，执行在域Di中的进程只能访问行i指定的对象，并且只能由访问矩阵条目所允许的操作集合。</p>
<p>访问矩阵可以<strong>实现保护相关的策略决策</strong>。这些策略决策涉及，条目（i，j）应当包括哪些权限。我们还必须<strong>决定每个进程执行的域</strong>。这条最后策略<strong>通常由操作系统来决定</strong>。</p>
<p><strong>用户通常决定访问矩阵条目的内容</strong>。当用户创建新对象Oi时，增加列Oi到访问矩阵，而列Oi具有创建者指定的适当初始化条目。列Oi中的权限也可以根据需要设置。</p>
<p>访问矩阵<strong>实现修改和增删</strong>很简单，修改现有条目直接对(i，j)操作即可。</p>
<p>访问矩阵的<strong>域切换</strong>也很方便，为矩阵新增一个域转移区域即可<strong>访问域转移区域的(i,j)，若有切换的权限，则可以从i切换到j</strong>。</p>
<p>一个示例的矩阵如下</p>
<center> <img src="./osimg/访问矩阵带转移.png" > </center>

<p>此外，访问<strong>矩阵条目内容的受控更改需要三个附加操作</strong>：</p>
<ul>
<li>复制（copy）</li>
<li>所有者（owner）</li>
<li>控制（control）</li>
</ul>
<p>下面，我们分析这些操作。</p>
<p><strong>复制</strong>访问矩阵的一个域（或行）的访问权限到另外一个的能力，通过访问权限后面附加的星号“*”来标记。复制权限<strong>允许在列（即对象）内，复制访问权限</strong>。例子如图</p>
<center> <img src="./osimg/访问矩阵权限复制.png" > </center>

<p>这种复制有两种扩展：</p>
<ul>
<li><strong>权限迁移</strong>：权限从access（i，j）复制到access（k，j），然后权限从access（i,j）中<strong>删除</strong>。</li>
<li><strong>限制复制权限的传播</strong>：当权限R_star从access（i,j）复制到access（k，j），只是创建了权限R（而不是R_star）。执行在域Dk中的进程不能进一步复制权限R。</li>
</ul>
<p>我们还需一种机制，以便<strong>增加新的权限和取消某些权限</strong>, <strong>所有者权限控制这些操作</strong>。如果access（i,j）包括所有者权限，则执行在域Di中的进程可以增加和删除列j的任何条目的<strong>任何权限</strong>. </p>
<p>例如，在图14-6a中，域D1为F1的所有者，并且可以增加和删除列F1的任何有效权限。同样，域D2为F2和F3的所有者，因此可以增加和删除这两列的任何有效权限。因此，图14-6a的访问矩阵可以改成如图14-6b所示的访问矩阵。</p>
<center> <img src="./osimg/访问矩阵所有者权限.png" > </center>

<p><strong>所有者权限实现了对象权限的增删，即矩阵列内容的修改</strong>。</p>
<p>此外，还需要对行的修改。</p>
<p><strong>控制权限只能用于域对象(修改行)<strong>。如果</strong>access(i，j)包含控制权限</strong>，则执行在<strong>域Di内的进程可以删除行内的任何访问权限</strong>. 控制条目可以放在上文说的域转移区域。例子如下</p>
<center> <img src="./osimg/访问矩阵行修改_控制.png" > </center>

<p>复制与所有者权限为我们提供了一种机制，来限制访问权限的传播。但是，它们并没有提供适当工具，来防止信息的传播（或泄露）。保证对象最初持有信息不能移到执行环境之外的问题称为<strong>禁闭问题</strong>（confinementproblem）。这个问题<strong>一般是不可解的</strong>。</p>
<h3 id="14-5-访问矩阵的实现"><a href="#14-5-访问矩阵的实现" class="headerlink" title="14-5 访问矩阵的实现"></a>14-5 访问矩阵的实现</h3><p><strong>访问矩阵</strong>显然是带有很多空的<strong>稀疏矩阵</strong>，因此直接拿二位矩阵存不现实。尽管有可以<strong>表示稀疏矩阵的数据结构</strong>，但是<strong>由于使用保护功能，他们并不适用</strong>。</p>
<h4 id="14-5-1-全局表"><a href="#14-5-1-全局表" class="headerlink" title="14-5-1 全局表"></a>14-5-1 全局表</h4><p>访问矩阵的<strong>最简单实现采用一个全局表</strong>，它<strong>包括一组有序三元组</strong> &lt; domain，object，rights-set &gt;。当在域D内对对象O进行操作M时，就在全局表中查找三元组（D，O，R），M∈R。如果找到这个三元组，则操作允许继续；否则，就会引起一个异常或者错误。</p>
<p>缺点是，这种表通常很大，因此<strong>不能保存在内存中</strong>，所以需要额外的I&#x2F;O。通常采用虚拟内存技术管理这种表。</p>
<h4 id="14-5-2-对象的访问列表"><a href="#14-5-2-对象的访问列表" class="headerlink" title="14-5-2 对象的访问列表"></a>14-5-2 对象的访问列表</h4><p>访问矩阵的每个列，可以实现为一个对象的访问列表，为空的项目自然不需要添加. **每个对象的访问列表包括一组有序对&lt; domain，rights-set &gt;**，以定义具有非空访问权限集合的那些域。</p>
<p>这种方法可以轻松<strong>扩展</strong>，以便定义一个列表<strong>加上一个访问权限的默认集合</strong>. </p>
<p>在域D中尝试对对象O进行操作M时，先查找默认集合检查是否包含M，若不包含则在对象O的列表中查找&lt; D, M &gt;, M∈R. 若找到该项则允许访问，否则拒绝并报出异常。</p>
<h4 id="14-5-3-域的能力列表"><a href="#14-5-3-域的能力列表" class="headerlink" title="14-5-3 域的能力列表"></a>14-5-3 域的能力列表</h4><p><strong>能力由一组对象以及对象允许的操作组成，对象表示通常采用物理名称或地址</strong></p>
<p>域的<strong>能力列表</strong>（capability list）是一个列表，将每行与其域相关联. <strong>行的每个条目附上对象名即为能力</strong>.</p>
<p>当对对象O执行操作M时，进程执行操作M，从而指定对象O的能力（或指针）作为参数。能力的简单拥有（possession）意味着允许访问。</p>
<p>虽然能力列表与域相关联，但是执行在该域中的进程不能直接访问它。相反，<strong>能力列表本身是受保护的对象</strong>，由操作系统维护，而<strong>用户只能间接访问</strong>。这要求<strong>决不允许迁移能力到用户可以直接访问的任何地址空间</strong>。</p>
<p><strong>能力</strong>最初作为一种<strong>安全指针</strong>提出，以满足资源保护的需要。这种<strong>固有保护指针</strong>的想法提供了一种保护平台，以扩展到应用程序级别。</p>
<p>为了提供固有保护，必须<strong>区分能力和其他对象类型</strong>，并且通过运行更高级别程序的抽象机器来解释能力。通常采用以下两种途径来区分能力和其他数据：</p>
<ul>
<li>对象都有一个<strong>标签</strong>（tag），以<strong>表示它是能力还是可以访问的数据</strong>。标签本身<strong>不能由应用程序来直接访问</strong>，这可以通过硬件或固件支持。区分能力和其他对象只需一个位，但是<strong>通常采用多个位</strong>。这种扩展允许<strong>通过硬件标记对象类型</strong>，这样硬件<strong>通过标签可以区分整数、浮点数、指针、布尔值、字符、指令、能力和未初始化的值</strong>。</li>
<li>或者，将<strong>程序关联的地址空间分为两个部分</strong>。一部分包含<strong>程序的普通数据和指令</strong>，可由程序<strong>直接访问</strong>。另一部分包含<strong>能力列表</strong>，只能由<strong>操作系统来访问</strong>。<a href="#8-4-%E5%88%86%E6%AE%B5">分段</a>有助于支持这种形式。</li>
</ul>
<h4 id="14-5-4-锁-钥匙机制"><a href="#14-5-4-锁-钥匙机制" class="headerlink" title="14-5-4 锁-钥匙机制"></a>14-5-4 锁-钥匙机制</h4><p>锁-钥匙方案（lock-keyscheme）是<strong>访问列表和能力列表的折中</strong>。</p>
<p><strong>每个对象</strong>都有一个<strong>唯一的位模式列表</strong>，称为<strong>锁</strong>（lock）。类似地, <strong>每个域</strong>都有一个<strong>唯一的位模式列表</strong>，称为<strong>钥匙</strong>（key）。执行在域中的进程仅当该域具有匹配这个对象锁的一个钥匙时才可以访问一个对象。</p>
<p>锁就像对象的访问列表一样，给每个对象提供可行的域。<br>钥匙则像域的能力列表，给每个域访问对象的能力。此外, <strong>与能力列表一样，域钥匙列表必须通过操作系统代表域来管理</strong>。用户只能间接访问却不能修改。</p>
<h4 id="14-5-5-比较"><a href="#14-5-5-比较" class="headerlink" title="14-5-5 比较"></a>14-5-5 比较</h4><p><strong>全局表</strong>：</p>
<ul>
<li>优点：实现简单</li>
<li>缺点：体积太大，无法放在内存中导致需要额外的I&#x2F;O降低性能</li>
</ul>
<p><strong>对象的访问列表</strong>：</p>
<p>创建对象时就指定能访问他的域以及访问权限的集合</p>
<ul>
<li>优点：更加节省空间, 直接对应用户需求, <strong>易于撤销能力</strong></li>
<li>缺点：<ol>
<li>由于只包含对象对于域的关联，找到域关联的对象很困难，需要遍历所有对象的列表</li>
<li>访问对象时需要搜索域是否在访问列表且访问权限包含在集合内，对于大的表可能效率很低</li>
</ol>
</li>
</ul>
<p><strong>域的能力列表</strong></p>
<ul>
<li>优点：验证访问的效率高，尝试访问的进程必须有该域内的能力，系统只需验证能力有效性</li>
<li>缺点：<ol>
<li>不直接对应用户需求</li>
<li>撤销能力的效率低，由于只有域对对象的关联，想要关闭对象需要遍历所有域</li>
</ol>
</li>
</ul>
<p><strong>锁-钥匙机制</strong></p>
<ul>
<li>优点：有效且灵活，钥匙可以在域间传递，且撤销能力开销低，因为只要把对象的锁清空那么钥匙永远对应不上</li>
<li>缺点：我不知道，反正就是没人用</li>
</ul>
<p>大多数系统<strong>采用访问列表和能力的组合</strong>。当进程首先尝试访问对象时，搜索访问列表。如果访问被拒绝，则会发生异常状态。否则，将创建一个能力并添加到进程。以后引用使用这个能力，可以迅速表明访问是允许的。最后一次访问之后，能力就被销毁。</p>
<h3 id="14-6-访问控制"><a href="#14-6-访问控制" class="headerlink" title="14-6 访问控制"></a>14-6 访问控制</h3><p>通过<strong>基于角色访问控制</strong>（Role-Based Access Control, <strong>RBAC</strong>）来明确<strong>增加最低特权原则</strong>，Solaris 10提高了操作系统的保护。这种功能围绕特权。特权，为执行系统调用或采用系统调用选项（如打开一个文件以便写入）的权利。</p>
<p>权限可以分配给进程，以限制它们只能访问完成工作所必需的。权限和程序也可以分配<strong>角色</strong>（role）. <strong>用户可以分配角色或者根据角色密码来获取角色</strong>. 特权的这种实现降低了与超级用户和setuid程序有关的安全风险。</p>
<center> <img src="./osimg/角色控制访问.png" > </center>

<p>从上图可见，角色是权限的集合。用户和进程可以获取角色来得到特权。</p>
<p>请注意：这种功能类似于<a href="#14-4-%E4%BF%9D%E6%8A%A4%E7%9F%A9%E9%98%B5">访问矩阵</a>。本章结尾的习题会进一步探讨这种关系。</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">角色-&gt;域 | 权限-&gt;能力(对象 + 一系列许可的操作)</span><br></pre></td></tr></table></figure>

<h3 id="14-7-访问权限的撤回"><a href="#14-7-访问权限的撤回" class="headerlink" title="14-7 访问权限的撤回"></a>14-7 访问权限的撤回</h3><p><strong>动态保护系统</strong>中，可能<strong>有时需要撤回不同用户共享对象的访问权限</strong>。撤回可能引起各种问题：</p>
<ul>
<li><strong>立即与延迟撤回</strong>：延迟的话，能知道延迟多久吗？</li>
<li><strong>可选与一般</strong>(用户)：当撤回对象的访问权限时，是否影响拥有这个对象的访问权限的所有用户，还是可以选择部分用户撤回</li>
<li><strong>部分与总体</strong>(对象)：可以撤回与一个对象关联的部分权限，或者必须撤回这个对象的所有访问权限</li>
<li><strong>临时与永久撤回</strong></li>
</ul>
<p><strong>采用访问列表方案</strong>，撤回很<strong>容易</strong>。搜索访问列表以便查找需要撤回的任何访问权限，并从列表中删除它们。撤回是<strong>立即的，可以一般或可选、总体或部分、永久或临时</strong>。</p>
<p><strong>能力更难撤回</strong>。由于这些能力分布在整个系统中，我们必须在撤回之前先找到它们。实现<strong>撤回能力的方案</strong>包括以下内容：</p>
<ul>
<li><strong>重新获得</strong>: <strong>定期地</strong>从每个<strong>域中删除能力</strong>。如果进程想要使用一个能力，它可能<strong>发现这个能力已被删除。进程可能尝试重新获得能力</strong>。如果<strong>访问已被撤回，则进程将无法重新获得能力</strong>。(要区分删除与撤回?)</li>
<li><strong>后指针</strong>: 每个对象都有指针列表，指向与其关联的所有能力。当要求撤回时，可以跟随这些指针，根据必要改变能力. 它相当<strong>通用，但实现昂贵</strong></li>
<li><strong>间接</strong>: 能力<strong>间接或直接指向对象</strong>。每个<strong>能力指向全局表的唯一条目，进而指向对象</strong>。实现撤回包括: 搜索全局表来获取所需的条目，并删除。然后，当尝试访问时，发现能力指向非法的表条目。它<strong>不允许可选的撤回</strong>。(直接删除对象)</li>
<li><strong>钥匙</strong>: 钥匙是与能力关联的唯一的位模式。这个<strong>钥匙在创建能力时定义</strong>，并且<strong>不能被拥有这个能力的进程更改和检查</strong>。每个<strong>对象关联一个主钥</strong>（master key）；它可以通过操作set-key来定义或替换。当<strong>创建能力时，主钥的当前值与能力相关联</strong>。当行使能力时，比较其钥匙与主钥。如果它们匹配，则允许操作继续；否则，引起异常条件。撤回通过<strong>操作set-key采用新值来替换主钥，使得这个对象的所有以前能力失效</strong>。</br> 这种方案<strong>不允许可选择的撤回，因为每个对象只关联一个主钥</strong>。如果每个<strong>对象关联一个钥匙列表</strong>，则可以<strong>实现可选择的撤回</strong>. </br> 最后，可以将所有钥匙组成一个<strong>全局钥匙表</strong>。删除全局表内的匹配钥匙可以实现撤回。通过这种方案，多个对象可以关联一个钥匙，并且每个对象可以关联多个钥匙，从而提供<strong>最大的灵活性</strong>。</li>
</ul>
<h3 id="14-8-基于能力的系统"><a href="#14-8-基于能力的系统" class="headerlink" title="14-8 基于能力的系统"></a>14-8 基于能力的系统</h3><h4 id="14-8-1-hydra"><a href="#14-8-1-hydra" class="headerlink" title="14-8-1 hydra"></a>14-8-1 hydra</h4><p>P448</p>
<h4 id="14-8-2-剑桥cap系统"><a href="#14-8-2-剑桥cap系统" class="headerlink" title="14-8-2 剑桥cap系统"></a>14-8-2 剑桥cap系统</h4><p>P449</p>
<h3 id="14-9-基于语言的保护"><a href="#14-9-基于语言的保护" class="headerlink" title="14-9 基于语言的保护"></a>14-9 基于语言的保护</h3><p>应用程序童同样需要保护自己的程序不被恶意损坏或出现重大错误，因此应用程秀设计人员也需要考虑安全和保护。</p>
<h4 id="14-9-1-基于编译程序的实现"><a href="#14-9-1-基于编译程序的实现" class="headerlink" title="14-9-1 基于编译程序的实现"></a>14-9-1 基于编译程序的实现</h4><p>采用程序语言，指定系统<strong>共享资源的所需访问控制</strong>是<strong>资源的声明语句</strong></p>
<p>就像c++类内的protected, private和public等关键字</p>
<h4 id="14-9-2-java的保护"><a href="#14-9-2-java的保护" class="headerlink" title="14-9-2 java的保护"></a>14-9-2 java的保护</h4><p>P452</p>
<p>为了访问保护资源，引发请求的调用顺序的某<strong>个方法必须明确声明访问资源的权限</strong>。这样，这个<strong>方法负责请求</strong>；大概也会执行任何必要的检查，以确保请求的安全。当然，不是每个方法都允许声称特权；只有方法所属的类处于允许执行特权的保护域中时，它才能声称特权。</p>
<p>这种实现方法称为<strong>堆栈检测</strong>（stack inspection）。每个JVM线程都有一个关联堆栈，以包含正在进行的调用方法。当调用者可能不被信任时，方法执行doPrivileged（）块的访问请求，以便直接或间接执行保护资源的访问。doPrivileged（）是AccessController类的一个静态方法，可以通过方法run（）来调用。当进人doPrivileged块时，这个方法的堆栈帧会注明这一事实。然后，执行这个块的内容。当这个方法或它的调用方法随后请求保护资源的访问，调用checkPermissions（）用于堆栈检查，以确定是否允许请求。这种检查分析调用线程堆栈上的堆栈帧，从最近添加的帧开始，一直到最老的。如果先找到一个含有doPrivileged（）注释的栈帧，checkPermissions（）立即默默返回，允许访问。如果先找到一个（依据方法类的保护域）不允许的栈帧，checkPermissions（）抛出AccessControlException。如果栈检查在分析完堆栈之后，没有发现以上两种类型的栈帧，则是否允许访问取决于实现（例如，有些JVM实现可能允许访问，而其他实现可能不允许）。</p>
<center> <img src="./osimg/栈检查.png"> </center> 

<p>当然，由于需要执行堆栈检查，必须<strong>禁止程序修改自已栈桢的注释或其他方式的堆栈检查</strong>。这是Java和许多其他语言（包括C++）之间的一个最重要的差异。Java程序<strong>无法直接访问内存</strong>；它只能操作拥有引用的对象。</p>
<h2 id="15-系统安全"><a href="#15-系统安全" class="headerlink" title="15 系统安全"></a>15 系统安全</h2><h3 id="15-1-安全问题"><a href="#15-1-安全问题" class="headerlink" title="15-1 安全问题"></a>15-1 安全问题</h3><p>为了保护系统，必须从陪你过四个层次上采取安全措施：</p>
<ul>
<li>物理</li>
<li>人员</li>
<li>操作系统</li>
<li>网络</li>
</ul>
<h3 id="15-2-程序威胁"><a href="#15-2-程序威胁" class="headerlink" title="15-2 程序威胁"></a>15-2 程序威胁</h3><h4 id="15-2-1-特洛伊木马"><a href="#15-2-1-特洛伊木马" class="headerlink" title="15-2-1 特洛伊木马"></a>15-2-1 特洛伊木马</h4>]]></content>
      <tags>
        <tag>note</tag>
      </tags>
  </entry>
</search>
